{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11be5b66-64ab-4372-bde3-dcab5b36ea12",
   "metadata": {
    "id": "67a097ac-8d49-4481-ac5a-62838b3b7249",
    "tags": []
   },
   "source": [
    "# (공부) 스터디 자료\n",
    "> Batch normalization, covariate shift \n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 김하영\n",
    "- categories: [Study]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fdfc4c-fc31-47c3-8bea-e5d825c58cbe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed1b25-cda8-456d-b0ea-b7dd3f1a0c8f",
   "metadata": {},
   "source": [
    "**💡: 우리가 CAM 결과를 표준화시켜주는 이유는 회귀분석에서 잔차들의 가정을 만족하기 위함과 관련이 있을까?**\n",
    "\n",
    "- 회귀분석에서 가정을 만족시켜야 하는 이유는 신뢰구간 등을 합리적으로 구할 수 있게 도와준다, 혹은 다른 의미들이 있어서이다. 하지만..우리의 경우에는.. 질문과 같이 큰 의미가 있다고는 할 수 없다.\n",
    "\n",
    "- 우리가 사용한 hyper parmeter의 쓰임과 관련이 있는 개념을 알아보자는 취지에서 작성함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0c5af-e219-4a25-b1fb-b2f9e92b569d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96875f6a-b93d-48ff-9d8e-e05a6c6612c3",
   "metadata": {},
   "source": [
    "## Covariate shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab194c25-eec5-4683-931a-1d5b0f2a76cc",
   "metadata": {},
   "source": [
    "- 트레이닝 데이터의 분포가 테스트 데이터와 다른 상황을 말함.\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/ccLdcq/btqAslpP69M/x9qF6jV1ReiK7ePbmclqlK/img.png\" width=500 height=250 alt=\"shift\">  \n",
    "\n",
    "- internal covariate shift\n",
    "\n",
    "    - 우리는 CAM 결과를 이용한다. 이 때 CAM 결과는 픽셀의 중요도에 따라 양/음수의 구분없이 넓은 범위 내에서 값을 가진다. 우리는 이런 분산을 표준화 시켜주기 위해 hyper parameter를 생성해주었다.\n",
    "    \n",
    "    - internal covariate shift는 매개변수의 값의 변동이 심해진 현상을 말한다.\n",
    "    \n",
    "    - 우리의 상황 또한 원래 0~255 사이의 값을 가졌던 픽셀들(매개변수)들이 CNN을 거치며 값의 변동이 심해졌다라고 생각할 수 있겠다.\n",
    "    \n",
    "- 그럼 해결방법은 ?\n",
    "    - 분포를 동일하게 만들어주는 방법은 간단하다. 분포의 위치와 크기를 변경해주면 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394bf580-e7ec-4d15-85bb-8057ededd396",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c78ca3-ca3d-4026-a863-a8fb66e939af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7992a-e967-4b55-a425-5def2dd60d7e",
   "metadata": {},
   "source": [
    "- Batch normalization은 학습 과정에서 각 배치 단위 별로 데이터가 다양한 분포를 가지더라도 각 배치별로 평균과 분산을 이용해 정규화하는 것을 말한다.\n",
    "\n",
    "<img src=https://gaussian37.github.io/assets/img/dl/concept/batchnorm/4.png width=500 height=250 alt=\"batch\">  \n",
    "\n",
    "- 그림을 보면 batch 단위, layer에 따라서 입력 값의 분포가 다르지만, 정규화를 통해 분포를 zero mean gaussian 형태로 만들어준다. $\\to$ 평균 0, 표준편차는 1인 데이터 분포로 조정할 수 있다.\n",
    "\n",
    "- gradient의 편차가 크면 gradient가 큰 weight에서는 gradient exploding이, 작으면 vanishing 문제가 발생하는데, 이게 우리가 겪고 있는 문제였음. 우리는 중요도로 계속 분해를 해나가는데 이에 따라 값이 계속 작아지니 분명 그 다음 중요한 부분인데도 인식이 되지 않음.\n",
    "\n",
    "- 정규화를 진행하면 gradient 하강에 따른 weight의 반응이 같아지기 때문에 학습에 유리해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7c9fb-e18d-4fd5-ac25-4f5afd2e6d9b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41fb67-e330-4284-bdba-e305b21300fd",
   "metadata": {},
   "source": [
    "## Our method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8921dd-9474-4b90-b6f2-a05c46d34307",
   "metadata": {},
   "source": [
    "- 정리해보면, 우리는 CAM 픽셀들 간 분산이 커져서 이를 조정하여 분해해나갈 때 계속해서 특징이 발견될 수 있도록 하였다.\n",
    "\n",
    "- (1) 분산이 커지는 문제 는 Covariate shift 와,\n",
    "- (2) Input range를 조정 은 Batch noramalization과 관련이 있다고 할 수 있겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27a0aa-d298-4614-84ca-a474e289c8d3",
   "metadata": {},
   "source": [
    "- 하지만, \n",
    "\n",
    "- (1) Batch normalization 결과처럼 평균 0, 표준 편차 1인 분포로 조정되지 않는다는 점\n",
    "- (2) 여러 개의 parameter를 조정해야 한다는 Batch normalization과 다르게 우리는 꽤 간단히(하지만 찾는 과정이 어려운) 한 개 파라미터로 조정할 수 있었다는 점이 차이점이라고 생각된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6608790-d471-4f86-b36e-be6fc038bbd1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce9f48-d556-4740-ab77-59c286115816",
   "metadata": {},
   "source": [
    "ref : https://data-newbie.tistory.com/354  \n",
    "https://ko.d2l.ai/chapter_deep-learning-basics/environment.html  \n",
    "https://89douner.tistory.com/44  \n",
    "https://gaussian37.github.io/dl-concept-batchnorm/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
