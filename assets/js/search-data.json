{
  
    
        "post0": {
            "title": "(4주차) 3월28일",
            "content": ". import matplotlib.pyplot as plt import tensorflow as tf import numpy as np . import tensorflow.experimental.numpy as tnp . import matplotlib.pyplot as plt . tnp.experimental_enable_numpy_behavior() . &#48120;&#48516; . tf.GradientTape() &#49324;&#50857;&#48169;&#48277; . - 예제9: 카페 예제로 돌아오자. . x=tnp.array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) . 2022-03-28 19:21:12.403805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:12.424856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:12.425236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:12.425800: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-28 19:21:12.426165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:12.426536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:12.426887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:13.397834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:13.398221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:13.398573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-28 19:21:13.398922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12486 MB memory: -&gt; device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6 . tf.random.set_seed(43052) epsilon=tf.random.normal([10]) y=10.2 + 2.2*x + epsilon . y #잘 생성되었다. . &lt;tf.Tensor: shape=(10,), dtype=float64, numpy= array([55.4183651 , 58.19427589, 61.23082496, 62.31255873, 63.1070028 , 63.69569103, 67.24704918, 71.43650092, 73.10130336, 77.84988286])&gt; . beta0 = tf.Variable(9.0) beta1 = tf.Variable(2.0) . with tf.GradientTape(persistent=True) as tape: loss = sum((y-beta1*x-beta0)**2) . tape.gradient(loss, beta0), tape.gradient(loss, beta1) #loss의 미분값 . (&lt;tf.Tensor: shape=(), dtype=float32, numpy=-126.78691&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=-3208.8396&gt;) . - 🥸시험🥸 예제10: 카페 예제의 매트릭스 버전 . X=tnp.array([1]*10+[20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]).reshape(2,10).T X . &lt;tf.Tensor: shape=(10, 2), dtype=float64, numpy= array([[ 1. , 20.1], [ 1. , 22.2], [ 1. , 22.7], [ 1. , 23.3], [ 1. , 24.4], [ 1. , 25.1], [ 1. , 26.2], [ 1. , 27.3], [ 1. , 28.4], [ 1. , 30.4]])&gt; . beta = tnp.array([9.0,2.0]).reshape(2,1) beta . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[9.], [2.]])&gt; . beta_true = tnp.array([10.2,2.2]).reshape(2,1) y = X @ beta_true + epsilon.reshape(10,1) y . &lt;tf.Tensor: shape=(10, 1), dtype=float64, numpy= array([[55.4183651 ], [58.19427589], [61.23082496], [62.31255873], [63.1070028 ], [63.69569103], [67.24704918], [71.43650092], [73.10130336], [77.84988286]])&gt; . with tf.GradientTape(persistent=True) as tape: tape.watch(beta) #constant일 때, 꼭 확인 yhat = X@beta loss = (y-yhat).T @ (y-yhat) . tape.gradient(loss,beta) . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[ -126.78690968], [-3208.83947922]])&gt; . - 위의 이론적인 값을 확인하면 . -2 * X.T @ y + 2 * X.T @ X @ beta #loss . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[ -126.78690968], [-3208.83947922]])&gt; . - 🥸시험🥸 예제11: 위의 예제에서 이론적인 $ boldsymbol{ beta}$의 최적값을 찾아보고 (즉 $ boldsymbol{ hat beta}$을 찾고) 그 지점에서 loss의 미분값(=접선의 기울기)를 구하라. 결과가 $ bf{0}$인지 확인하라. (단 ${ bf 0}$은 길이가 2이고 각 원소가 0인 벡터) . $ boldsymbol{ beta}$의 최적값은 $({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ 이다. . beta_optimal = tf.linalg.inv(X.T @ X) @ X.T @ y beta_optimal . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[9.94457324], [2.21570461]])&gt; . with tf.GradientTape(persistent=True) as tape: tape.watch(beta_optimal) yhat = X@beta_optimal loss = (y-yhat).T @ (y-yhat) . tape.gradient(loss,beta_optimal) . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[-6.67910172e-12], [-1.67774636e-10]])&gt; . - beta_true에서의 기울기도 계산해보자. . with tf.GradientTape(persistent=True) as tape: tape.watch(beta_true) yhat = X@beta_true loss = (y-yhat).T @ (y-yhat) . tape.gradient(loss,beta_true) . &lt;tf.Tensor: shape=(2, 1), dtype=float64, numpy= array([[ -2.74690968], [-71.45947922]])&gt; . 현재에서는 true값보다 optimal에서 기울기가 더 작게 나타남. | 샘플 사이즈가 커질수록 tape.gradient(loss,beta_true) $ approx$ tape.gradient(loss,beta_optimal) | beta_true $ approx$ beta_optimal | . . &#44221;&#49324;&#54616;&#44053;&#48277; . &#52572;&#51201;&#54868;&#47928;&#51228; . - $loss=( frac{1}{2} beta-1)^2$를 최소하는 $ beta$를 컴퓨터를 활용하여 구하는 문제를 생각해보자. . 답은 $ beta=2$임을 알고 있다. | . &#48169;&#48277;1: grid search . &#50508;&#44256;&#47532;&#51608; . (1) $beta = [-10.00, -9.99, ... , 10.00]$와 같은 리스트를 만든다. . (2) (1)의 리스트의 각 원소에 해당하는 $loss$를 구한다. . (3) (2)에서 구한 $loss$를 제일 작게 만드는 $beta$를 찾는다. . &#44396;&#54788;&#53076;&#46300; . beta = np.linspace(-10,10,100) loss = (beta/2-1)**2 . 먼저 연습~ | . tnp.argmin([1,2,-3,3,4]) . &lt;tf.Tensor: shape=(), dtype=int64, numpy=2&gt; . tnp.argmin([1,2,3,-3,4]) . &lt;tf.Tensor: shape=(), dtype=int64, numpy=3&gt; . 대입하면 | . tnp.argmin(loss) . &lt;tf.Tensor: shape=(), dtype=int64, numpy=59&gt; . 비슷한 값끼리 비교하려면 | . (beta[59]/2-1)**2 #beta[59]가 최적이다 . 0.0016324864809713505 . (beta[60]/2-1)**2 . 0.0036730945821854847 . &#44536;&#47532;&#46300;&#49436;&#52824;&#51032; &#47928;&#51228;&#51216; . - 비판1: [-10,10]이외에 해가 존재하면? . 이 예제의 경우는 운좋게 [-10,10]에서 해가 존재했음 | 하지만 임의의 고정된 $x,y$에 대하여 $loss( beta)=(x beta-y)^2$ 의 형태의 해가 항상 [-10,10]에서 존재한다는 보장은 없음 | 해결책: 더 넓게 많은 범위를 탐색하자? $ to$ 무한대로 나아갈 수는 없기 때문에 해결책은 아니다.. | . - 비판2: 효율적이지 않음 . 알고리즘을 요약하면 결국 -10부터 10까지 작은 간격으로 조금씩 이동하며 loss를 조사하는 것이 grid search의 아이디어 | $ to$ 생각해보니까 $ beta=2$인 순간 $loss=( frac{1}{2} beta-1)^2=0$이 되어서 이것보다 작은 최소값은 존재하지 않는다(제곱은 항상 양수이어야 하므로) | $ to$ 따라서 $ beta=2$ 이후로는 탐색할 필요가 없다 | . &#48169;&#48277;2: gradient descent . &#50508;&#44256;&#47532;&#51608;! . (1) $beta = -5$ 로 셋팅한다. #초기값 세팅 . (-5/2-1)**2 . 12.25 . (2) $beta = -5$ 근처에서 조금씩 이동하여 $loss$를 조사한다. #미분 . (-4.99/2-1)**2 #오른쪽으로 0.01 이동 후 loss 조사 . 12.215025 . (-5.01/2-1)**2 #왼쪽으로 0.01 이동 후 loss 조사 . 12.285025 . (3) (2)의 결과를 잘 해석하고 더 유리한 쪽으로 이동한다. . (4) 위의 과정을 반복하고 어느 쪽으로 움직여도 이득이 없다면 멈춘다. . &#50508;&#44256;&#47532;&#51608; &#48516;&#49437; . - (2)-(3)의 과정은 $beta=-5$에서 미분계수를 구하고 미분계수가 양수이면 왼쪽으로, 음수이면 오른쪽으로 움직인다고 해석이 가능하다. 아래 그림을 보면 더 이해가 쉽다. . plt.plot(beta, loss) . [&lt;matplotlib.lines.Line2D at 0x7fd66026ac80&gt;] . &#50812;&#51901;/&#50724;&#47480;&#51901;&#51473;&#50640; &#50612;&#46356;&#47196; &#44040;&#51648; &#50612;&#46523;&#44172; &#54032;&#45800;&#54616;&#45716; &#44284;&#51221;&#51012; &#49688;&#49885;&#54868;? . - 아래와 같이 해석이 가능하다. . 오른쪽으로 0.01 간다 = beta_old에 0.01을 더함. (if, 미분계수가 음수이면) | 왼쪽으로 0.01 간다 = beta_old에 0.01을 빼야 함. (if, 미분계수가 양수이면) | . - 그렇다면 . $ beta_{new} = begin{cases} beta_{old} + 0.01, &amp;loss&#39;( beta_{old})&lt;0 beta_{old} - 0.01, &amp; loss&#39;( beta_{old})&gt;0 end{cases}$ . &#54841;&#49884; &#50508;&#44256;&#47532;&#51608;&#51012; &#51328; &#44060;&#49440;&#54624;&#49688; &#51080;&#51012;&#44620;? . - 항상 0.01 만큼만 움직여야 하는가? . plt.plot(beta, loss) . [&lt;matplotlib.lines.Line2D at 0x7fd66026ac80&gt;] . $ to$ 최적점에서 가까울수록 보폭이 작으면 좋겠다. $ to$ 음/양수에 따라서 방향을, 절댓값 크기에 따라 보폭 크기를 정하면 되겠다! . - $ beta=-10$ 일 경우의 접선의 기울기? $ beta=-4$ 일때 접선의 기울기? . $ beta=-10$일 때 기울기는 -6 | $ beta=-4$일 때 기울기는 -3 | . - 실제로 6,3씩 이동할 순 없으니 적당한 $ alpha$(예를 들면 $ alpha=0.01$)를 잡아서 곱한만큼 이동하자. . - 수식화하면 . $ beta_{new} = beta_{old} - alpha loss&#39;( beta_{old})$ | $ beta_{new} = beta_{old} - alpha left[ frac{ partial}{ partial beta} loss( beta) right]_{ beta = beta_{old}}$ | . - 위 식을 +로 하면 최대값을 찾을 수 있겠다. . - $ alpha$의 의미 . $ alpha$가 크면 크게 움직이고, 작으면 작게 움직인다. | $ alpha&gt;0$이어야 한다. | . &#44396;&#54788;&#53076;&#46300; . - iter 1 . $ beta = -10$이라고 하자. . beta = tf.Variable(-10.0) . with tf.GradientTape(persistent=True) as tape : loss = (beta/2-1)**2 . tape.gradient(loss, beta) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=-6.0&gt; . - $ beta = -10$에서 $0.01$만큼 움직이고 싶음. . alpha = 0.01/6 . beta.assign_sub(alpha * tape.gradient(loss, beta)) #원래 할당값에 ()안의 숫자를 빼주는 . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=float32, numpy=-9.99&gt; . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-9.99&gt; . - iter 2 . with tf.GradientTape(persistent=True) as tape : loss = (beta/2-1)**2 . beta.assign_sub(tape.gradient(loss,beta)*alpha) . &lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=float32, numpy=-9.980008&gt; . - for 문을 이용하자! . (강의용) . beta = tf.Variable(-10.0) . for k in range(10000): with tf.GradientTape(persistent=True) as tape: loss = (beta/2-1)**2 beta.assign_sub(tape.gradient(loss,beta)*alpha) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=1.997125&gt; . (시도1) . beta = tf.Variable(-10.0) . for k in range(100): with tf.GradientTape(persistent=True) as tape: loss = (beta/2-1)**2 beta.assign_sub(tape.gradient(loss,beta)*alpha) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-9.040152&gt; . (시도2) . beta = tf.Variable(-10.0) . for k in range(1000): with tf.GradientTape(persistent=True) as tape: loss = (beta/2-1)**2 beta.assign_sub(tape.gradient(loss,beta)*alpha) . beta . &lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=float32, numpy=-3.2133687&gt; . - 너무 느리다. $ to$ $ alpha$를 키워보자! . &#54617;&#49845;&#47456; (learning rate) . - $ alpha$에 따라서 함수의 수렴과정이 어떻게 달라지는지 시각화해보자. . [&#49884;&#44033;&#54868; &#53076;&#46300; &#50696;&#48708;&#54617;&#49845;] . plt.plot([1,2,3],[3,4,5], &#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd2bc92f220&gt;] . fig=plt.figure() #도화지가 만들어지고 fig라는 이름을 붙인다. . &lt;Figure size 432x288 with 0 Axes&gt; . ax = fig.add_subplot() #fig는 ax라는 물체를 만든다. . id(fig.axes[0]) #fig에 있는 것들을 보여주는 코드, 리스트형태 . 140542468107968 . id(ax) . 140542468107968 . 둘이 포함 관계에 있다는 것을 확인할 수 있음. | . pnts, = ax.plot([1,2,3],[4,5,6], &#39;or&#39;) pnts . &lt;matplotlib.lines.Line2D at 0x7fd2bc6dc4f0&gt; . ,를 붙이면 tuple이 된다. | . pnts.get_xdata() . array([1, 2, 3]) . pnts.get_ydata() . array([4, 5, 6]) . fig . pnts.set_ydata([5,5,5]) . pnts.get_ydata() . [5, 5, 5] . fig . - 응용 . def .",
            "url": "https://kimha02.github.io/ham/bigdata/2022/03/27/_03_28_(4%EC%A3%BC%EC%B0%A8)_3%EC%9B%9428%EC%9D%BC.html",
            "relUrl": "/bigdata/2022/03/27/_03_28_(4%EC%A3%BC%EC%B0%A8)_3%EC%9B%9428%EC%9D%BC.html",
            "date": " • Mar 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "(3주차) 3월21일",
            "content": ". imports . import tensorflow as tf import numpy as np . tf.config.experimental.list_physical_devices(&#39;GPU&#39;) . 2022-03-21 18:55:30.391830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-21 18:55:30.412866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-21 18:55:30.413250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero . [PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)] . 데이터과학 수업 참고하기 | . . &#51648;&#45212;&#44053;&#51032; &#48372;&#52649; . - max, min, sum, mean . a=tf.constant([1,2,3,4]) a . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt; . max(a) . &lt;tf.Tensor: shape=(), dtype=int32, numpy=4&gt; . mean(a) . NameError Traceback (most recent call last) Input In [9], in &lt;cell line: 2&gt;() 1 #mean은 안 된다. -&gt; 2 mean(a) NameError: name &#39;mean&#39; is not defined . tf.reduce_mean(a) #잘못구해졌다. . &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt; . a=tf.constant([1.0,2.0,3.0,4.0]) a . &lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)&gt; . tf.reduce_mean(a) #잘 구해진 모습, 하지만 그렇게 잘 쓰진 않음. tnp가 있으니까 . &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.5&gt; . concat, stack . - 예제: (2,3,4,5) stack (2,3,4,5) -&gt; (?,?,?,?,?) . a=tf.reshape(tf.constant(range(2*3*4*5)),(2,3,4,5)) b=-a . case 1 (1,2,3,4,5) stack (1,2,3,4,5) = (2,2,3,4,5) #axis=0 . tf.stack([a,b],axis=0).shape . TensorShape([2, 2, 3, 4, 5]) . case 2 (2,1,3,4,5) stack (2,1,3,4,5) = (2,2,3,4,5) #axis=1 . tf.stack([a,b],axis=1).shape . TensorShape([2, 2, 3, 4, 5]) . case 3 (2,3,1,4,5) stack (2,3,1,4,5) = (2,3,2,4,5) #axis=2 . tf.stack([a,b],axis=2).shape . TensorShape([2, 3, 2, 4, 5]) . case 4 (2,3,4,1,5) stack (2,3,4,1,5) = (2,2,4,2,5) #axis=3 . tf.stack([a,b],axis=3).shape . TensorShape([2, 3, 4, 2, 5]) . tf.stack([a,b],axis=-2).shape . TensorShape([2, 3, 4, 2, 5]) . case 5 (2,3,4,5,1) stack (2,3,4,5,1) = (2,3,4,5,2) #axis=4 . tf.stack([a,b],axis=4).shape . TensorShape([2, 3, 4, 5, 2]) . tf.stack([a,b],axis=-1).shape . TensorShape([2, 3, 4, 5, 2]) . - 예제: (2,3,4), (2,3,4), (2,3,4) . a=tf.reshape(tf.constant(range(2*3*4)),(2,3,4)) b=-a c=2*a . (예시1) (2,3,4), (2,3,4), (2,3,4) $ to$ (6,3,4) . tf.concat([a,b,c], axis=0).shape . TensorShape([6, 3, 4]) . (예시2) (2,3,4), (2,3,4), (2,3,4) $ to$ (2,9,4) . tf.concat([a,b,c], axis=1).shape . TensorShape([2, 9, 4]) . (예시3) (2,3,4), (2,3,4), (2,3,4) $ to$ (2,3,12) . tf.concat([a,b,c], axis=2).shape . TensorShape([2, 3, 12]) . (예시4) (2,3,4), (2,3,4), (2,3,4) $ to$ (3,2,3,4) . tf.stack([a,b,c], axis=0).shape . TensorShape([3, 2, 3, 4]) . (예시5) (2,3,4), (2,3,4), (2,3,4) $ to$ (2,3,3,4) . tf.stack([a,b,c], axis=1).shape . TensorShape([2, 3, 3, 4]) . (예시6) (2,3,4), (2,3,4), (2,3,4) $ to$ (2,3,3,4) . tf.stack([a,b,c], axis=2).shape . TensorShape([2, 3, 3, 4]) . tf.stack([a,b,c], axis=-2).shape . TensorShape([2, 3, 3, 4]) . (예시7) (2,3,4), (2,3,4), (2,3,4) $ to$ (2,3,4,3) . tf.stack([a,b,c], axis=3).shape . TensorShape([2, 3, 4, 3]) . tf.stack([a,b,c], axis=-1).shape . TensorShape([2, 3, 4, 3]) . concat과 stack의 차이점을 잘 알고 잇짜! | . - 예제: (2,3,4) (4,3,4) $ to$ (6,3,4) . a=tf.reshape(tf.constant(range(2*3*4)),(2,3,4)) b=tf.reshape(-tf.constant(range(4*3*4)),(4,3,4)) . tf.concat([a,b],axis=0).shape . TensorShape([6, 3, 4]) . tf.concat([a,b],axis=1).shape #dimension이 달라서 안된다. . InvalidArgumentError Traceback (most recent call last) Input In [50], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=1).shape File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat . tf.concat([a,b],axis=-1).shape #dimension이 달라서 안된다. . InvalidArgumentError Traceback (most recent call last) Input In [51], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b],axis=-1).shape File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat . - (2,2) @ (2,) 의 연산? . numpy . np.array([[1,0],[0,1]])@ np.array([77,-88]) . array([ 77, -88]) . np.array([77,-88]) @ np.array([[1,0],[0,1]]) . array([ 77, -88]) . 알아서 열/행벡터인지 인식하여 해준다? | . np.array([[1,0],[0,1]])@ np.array([77,-88]).reshape(2,1) . array([[ 77], [-88]]) . np.array([77,-88]).reshape(2,1) @ np.array([[1,0],[0,1]]) . ValueError Traceback (most recent call last) Input In [58], in &lt;cell line: 2&gt;() 1 #열벡터로 지정해서 한다면?_이 때는 사이즈를 명시해주니까 계산 에러남. -&gt; 2 np.array([77,-88]).reshape(2,1) @ np.array([[1,0],[0,1]]) ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)-&gt;(n?,m?) (size 2 is different from 1) . np.array([77,-88]).reshape(1,2) @ np.array([[1,0],[0,1]]) . array([[ 77, -88]]) . 넘파이에서 길이가 2인 벡터는 매트릭스 앞뒤로 곱해주면 알아서 해석이 되어 결과가 나옴. 하지만 결과는 1차원 유지. | 명시적으로 shape을 바꿔주면 결과도 shape에 맞춰서 나옴. 에러메세지도 나온다. | . tensorflow . 하지만 tf.constant는 알아서 계산은 안됨. | . I=tf.constant([[1.0,0.0],[0.0,1.0]]) x=tf.constant([77.0,-88.0]) . I@x . InvalidArgumentError Traceback (most recent call last) Input In [69], in &lt;cell line: 1&gt;() -&gt; 1 I@x File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: In[0] and In[1] has different ndims: [2,2] vs. [2] [Op:MatMul] . x@I . InvalidArgumentError Traceback (most recent call last) Input In [70], in &lt;cell line: 1&gt;() -&gt; 1 x@I File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: In[0] and In[1] has different ndims: [2] vs. [2,2] [Op:MatMul] . I @ tf.reshape(x,(2,1)) . &lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy= array([[ 77.], [-88.]], dtype=float32)&gt; . tf.reshape(x,(1,2)) @ I . &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 77., -88.]], dtype=float32)&gt; . tf.reshape(x,[1,2]) @ I . &lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 77., -88.]], dtype=float32)&gt; . tf.reshape(x,(2,1)) . &lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy= array([[ 77.], [-88.]], dtype=float32)&gt; . . tf.Variable . &#49440;&#50616; . - tf.Variable()로 선언 . tf.Variable([1,2,3,4]) . &lt;tf.Variable &#39;Variable:0&#39; shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt; . tf.Variable([1.0,2.0,3.0,4.0]) . &lt;tf.Variable &#39;Variable:0&#39; shape=(4,) dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)&gt; . - tf.constant() 선언후 변환 . _a=tf.Variable([1,2,3,4]) type(_a) #약간 우리가 이전에 쓰던 모양과 다르다. . tensorflow.python.ops.resource_variable_ops.ResourceVariable . tf.Variable(tf.constant([1,2,3,4])) . &lt;tf.Variable &#39;Variable:0&#39; shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt; . - np 등으로 선언후 변환 . tf.Variable(np.array([1,2,3,4])) . &lt;tf.Variable &#39;Variable:0&#39; shape=(4,) dtype=int64, numpy=array([1, 2, 3, 4])&gt; . ❓ : tf.Variable 이 가진 장점 . &#53440;&#51077; . type(tf.Variable([1,2,3,4])) . tensorflow.python.ops.resource_variable_ops.ResourceVariable . &#51064;&#45937;&#49905; . a=tf.Variable([1,2,3,4]) a . &lt;tf.Variable &#39;Variable:0&#39; shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt; . a[:2] . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)&gt; . type(a[:2]) #tf.constant와 같아졌다! . tensorflow.python.framework.ops.EagerTensor . &#50672;&#49328;&#44032;&#45733; . a=tf.Variable([1,2,3,4]) b=tf.Variable([-1,-2,-3,-4]) . a+b . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)&gt; . type(a+b) . tensorflow.python.framework.ops.EagerTensor . - 연산하는 순간 type이 바뀐다! . $ to$ tf.Variable&#46020; &#50416;&#44592; &#48520;&#54200;&#54632; . tf.Variable([1,2])+tf.Variable([3.14,3.14]) . InvalidArgumentError Traceback (most recent call last) Input In [99], in &lt;cell line: 2&gt;() 1 #다른 불편한 예제 -&gt; 2 tf.Variable([1,2])+tf.Variable([3.14,3.14]) File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:1078, in Variable._OverloadOperator.&lt;locals&gt;._run_op(a, *args, **kwargs) 1076 def _run_op(a, *args, **kwargs): 1077 # pylint: disable=protected-access -&gt; 1078 return tensor_oper(a.value(), *args, **kwargs) File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2] . tnp&#51032; &#51008;&#52509;&#46020; &#51068;&#48512;&#47564; &#44032;&#45733; . import tensorflow.experimental.numpy as tnp tnp.experimental_enable_numpy_behavior() . - 알아서 형 변환 . tf.Variable([1,2])+tf.Variable([3.14,3.14]) . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([4.1400001, 5.1400001])&gt; . - .reshape 메소드 . tf.constant([1,2,3,4]).reshape(2,2) #constant는 tnp를 키면 이렇게 된다 . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]], dtype=int32)&gt; . tf.Variable([1,2,3,4]).reshape(2,2) #이건 또 안 된다 . AttributeError Traceback (most recent call last) Input In [104], in &lt;cell line: 1&gt;() -&gt; 1 tf.Variable([1,2,3,4]).reshape(2,2) AttributeError: &#39;ResourceVariable&#39; object has no attribute &#39;reshape&#39; . &#45824;&#48512;&#48516;&#51032; &#46041;&#51089;&#51008; tf.constant&#46993; &#53360; &#52264;&#51060;&#47484; &#47784;&#47476;&#44192;&#51020; . - tf.concat . a=tf.Variable([[1,2],[3,4]]) #b=-a를 하면 Variable이 깨진다 b=tf.Variable([[-1,-2],[-3,-4]]) tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy= array([[ 1, 2], [ 3, 4], [-1, -2], [-3, -4]], dtype=int32)&gt; . - tf.stack . a=tf.Variable([[1,2],[3,4]]) b=tf.Variable([[-1,-2],[-3,-4]]) tf.stack([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy= array([[[ 1, 2], [ 3, 4]], [[-1, -2], [-3, -4]]], dtype=int32)&gt; . tnp의 장점이 Variable에서 100% 적용이 안되고, | 연산만 하면 자료형이 바뀐다... $ to$ Variable 단점 | . &#48320;&#49688;&#44050;&#48320;&#44221;&#44032;&#45733;(?) $ to$ &#51109;&#51216;? . 재할당 이해하기 : 1에 a라는 이름을 붙엿던 것을 456에 a라는 이름을 붙이는 것. 따라서 주소가 다름. | $ to$ 이런 것을 불변형이라고 함. 불변형을 쓰면 메모리 소모가 많음. 자원이 풍부해야 한다... (Ex.R) | 만약 주소가 같다면 편집이라고 함. 편집은 a를 1에서 456으로 바꾸는 것 | $ to$ 이런 것을 가변형이라고 함. | . parameter는 GPU, x는 CPU에 올려야 계산이 된다. 메모리를 아끼기 위함임(?) | . a=1 id(a) . 139639058841840 . a=456 id(a) . Variable을 보면.. | . a=tf.Variable([1,2,3,4]) id(a) . 139630864641872 . a.assign_add([-1,-2,-3,-4]) id(a) . 139630864641872 . 주소 값이 같다 | . . &#50836;&#50557; . - tf.Variable()로 만들어야 하는 뚜렷한 차이는 모르겠음. . - 애써 tf.Variable()로 만들어도 간단한 연산을 하면 그 결과는 tf.constant()로 만든 오브젝트와 동일해짐. (결국 GPU 메모리를 아끼기 위함이다..., to.(cpu)개념인가?) . . &#48120;&#48516; . 선형계산이기 때문에 GPU로 계산하면 정말 빠르다! 😊 | . &#47784;&#54000;&#48652; . - 예제: 컴퓨터를 이용하여 $x=2$에서 $y=3x^2$의 접선의 기울기를 구해보자. . (손풀이) . $ frac{dy}{dx}$=6x 이므로 $x=2$를 대입하면 $12$가 정답! . (컴퓨터를 이용한 풀이) . 단계 1 . x1=2 y1=3*x1**2 . x2=2+0.000000001 y2=3*x2**2 . (y2-y1)/(x2-x1) . 12.0 . 단계 2 : 함수로 만들자. . def f(x) : return 3*x**2 . f(3) . 27 . def d(f,x) : return (f(x+0.000000001)-f(x))/0.000000001 . d(f,2) . 12.000000992884452 . 단계 3 : 항상 선언하기는 좀 이상하다. . d(lambda x: 3*x**2, 2) . 12.000000992884452 . d(lambda x: x**2, 0) . 1e-09 . 단계 4 : 더 확장성 있게... . $$f(x,y)=x^2+3y$$ 를 x로만 편미분하고 싶을 때, . def f(x,y) : return (x**2 +3*y) . d(f,(2,3)) . TypeError Traceback (most recent call last) Input In [133], in &lt;cell line: 1&gt;() -&gt; 1 d(f,(2,3)) Input In [125], in d(f, x) 1 def d(f,x) : -&gt; 2 return (f(x+0.000000001)-f(x))/0.000000001 TypeError: can only concatenate tuple (not &#34;float&#34;) to tuple . tf.GradientTape() &#49324;&#50857;&#48169;&#48277; . - 예제1: $x=2$에서 $y=3x^2$의 도함수값을 구하라. . tf.GradientTape() #Gradient=기울기, Tape=기록할 수 있는 공간 . &lt;tensorflow.python.eager.backprop.GradientTape at 0x7efad2b45150&gt; . 0x7efe58153ac0 이거를 잘 기억하기! 정보가 여기에 위치하고 있다. . . x=tf.Variable(2.0) #미분하고 싶은 애를 Variable로 잡고, 기울기를 구하고 싶은 지점을 숫자로 써라-&gt;외우기 a=tf.constant(3.0) #계수인 3도 저장해놓자 mytape=tf.GradientTape() mytape.__enter__() #기록 시작 y=a*x**2 mytape.__exit__(None,None,None) #기록 끝 mytape.gradient(y,x) #y를 x로 미분하라. . &lt;tf.Tensor: shape=(), dtype=float32, numpy=12.0&gt; . - 예제2: 조금 다른예제 . x=tf.Variable(2.0) #미분하고 싶은 애를 Variable로 잡고, 기울기를 구하고 싶은 지점을 숫자로 써라-&gt;외우기 #a=tf.constant(3.0) #계수인 3도 저장해놓자 mytape=tf.GradientTape() mytape.__enter__() #기록 시작 a=x/2*3 ##a=(3/2)x y=a*x**2 ## y=ax^2=(3/2)x^3 mytape.__exit__(None,None,None) #기록 끝 mytape.gradient(y,x) #y를 x로 미분하라. . &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt; . $$a= frac{3}{2}x$$ $$y=ax^2= frac{3}{2}x^3$$ $$ frac{dy}{dx} = frac{3}{2} 3x^2$$ . 3/2*3*4 . 18.0 . - 테이프의 개념 ($ star$) . (상황) . 우리가 어려운 미분계산을 컴퓨터에게 부탁하는 상황임. (예를들면 $y=3x^2$) 컴퓨터에게 부탁을 하기 위해서는 연습장(=테이프)에 $y=3x^2$이라는 수식을 써서 보여줘야하는데 이때 컴퓨터에게 target이 무엇인지 그리고 무엇으로 미분하고 싶은 것인지를 명시해야함. . ✏️ (1) mytape = tf.GradientTape(): tf.GradientTape()는 컴퓨터에게 보여줄 연습장 만드는 명령어, 만들어진 연습장에 mytape라고 이름을 붙인다. . (2) mytape.__enter__(): 만들어진 공책을 연다.(= 기록할 수 있는 상태로 만든다) . (3) a=x/2*3; y=a*x**2: 컴퓨터에게 전달한 수식을 쓴다. . (4) mytape.__exit__(None,None,None): 공책을 닫는다. . (5) mytape.gradient(y,x): $y$를 $x$로 미분하라는 메모를 남기고 컴퓨터에게 전달한다. . - 예제3: 연습장을 언제 열고 닫을지 결정하는건 중요하다. . x=tf.Variable(2.0) #미분하고 싶은 애를 Variable로 잡고, 기울기를 구하고 싶은 지점을 숫자로 써라-&gt;외우기 a=x/2*3 ##a=(3/2)x, 계산결과만 보게 됨 mytape=tf.GradientTape() mytape.__enter__() #기록 시작 y=a*x**2 ## y=ax^2 mytape.__exit__(None,None,None) #기록 끝 mytape.gradient(y,x) #y를 x로 미분하라. . &lt;tf.Tensor: shape=(), dtype=float32, numpy=12.0&gt; . - 예제4: with문과 함께 쓰는 tf.GradientTape()_간략한 구문으로 매크로화 . x=tf.Variable(2.0) #미분하고 싶은 애를 Variable로 잡고, 기울기를 구하고 싶은 지점을 숫자로 써라-&gt;외우기 a=x/2*3 . with tf.GradientTape() as mytape : ## with문 시작 y=a*x**2 # 생략할 수 없는 부분만 ## with문 끝 . mytape.gradient(y,x) #y를 x로 미분하라. . &lt;tf.Tensor: shape=(), dtype=float32, numpy=12.0&gt; . ✏️ (문법 해설) . 아래와 같이 쓴다. . with expression(표현식) as myname(이름표를 달아줌) : ## with문 시작 : myname.__enter__() 내가 실행하고 싶은 것을 작성해준다 ## with문 끝 : myname.__exit__() . (1) expression 이 가장 먼저 실행된다. 이 결과로 오브젝트가 생성됨. 생성된 오브젝트는 myname이라고 이름 붙인다. 이 오브젝트는 .__enter__()와 .__exit__()를 숨겨진 기능으로 포함해야 한다. . (2) with문에 시작되면서 동시에 myname.__enter__()이 실행된다. . (3) 내가 실행하고 싶은 것들이 실행된다. . (4) with문에 종료되면서,myname.__exit__()이 실행된다. . - 예제5: 예제2를 with문과 함께 구현 . x=tf.Variable(2.0) with tf.GradientTape() as mytape : a=x/2*3 y=a*x**2 mytape.gradient(y,x) #y를 x로 미분하라. . &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt; . - 예제6: persistent = True . 관찰 1 . . x=tf.Variable(2.0) with tf.GradientTape() as mytape : a=x/2*3 y=a*x**2 . mytape.gradient(y,x) #2번째 실행하면 안된다. . RuntimeError Traceback (most recent call last) Input In [187], in &lt;cell line: 1&gt;() -&gt; 1 mytape.gradient(y,x) File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1032, in GradientTape.gradient(self, target, sources, output_gradients, unconnected_gradients) 1002 &#34;&#34;&#34;Computes the gradient using operations recorded in context of this tape. 1003 1004 Note: Unless you set `persistent=True` a GradientTape can only be used to (...) 1029 called with an unknown value. 1030 &#34;&#34;&#34; 1031 if self._tape is None: -&gt; 1032 raise RuntimeError(&#34;A non-persistent GradientTape can only be used to &#34; 1033 &#34;compute one set of gradients (or jacobians)&#34;) 1034 if self._recording: 1035 if not self._persistent: RuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians) . 컴퓨터는 한 번 쓴 연습장을 버림... 그래서 2번째는 실행이 안된다. 일단 버리지 말라고 하는 게 persistent=True | . 관찰 2 . x=tf.Variable(2.0) with tf.GradientTape(persistent=True) as mytape : a=x/2*3 y=a*x**2 . mytape.gradient(y,x) # 몇 번 실행해도 오류 없이 잘 된다~! . &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt; . - 예제7: watch . 관찰 1 . x=tf.Variable(2.0) with tf.GradientTape(persistent=True) as mytape : a=x/2*3 y=a*x**2 mytape.gradient(y,x) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt; . Variable을 constant로 바꿔보자 | . x=tf.constant(2.0) with tf.GradientTape(persistent=True) as mytape : a=x/2*3 y=a*x**2 . print(mytape.gradient(y,x)) #결과가 안 나온다. . None . 관찰 2 . x=tf.constant(2.0) with tf.GradientTape(persistent=True) as mytape : mytape.watch(x) a=x/2*3 y=a*x**2 . mytape.gradient(y,x) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt; . constant하고 watch를 해주면 Variable과 같은 결과가 나온다. | Variable로 표현된 오브젝트는 자동 감시(자동으로 watch 메소드 실행)한다. | constant는 수동 감시 한다. | . 어떤 연습장에서는 변수로, 어떤 연습장에서는 상수로 보고 싶을 때가 있다. | 이게 수동 감시가 필요한 이유! | . 관찰 3 . ??? 자동 감시 모드를 꺼도 되지 않나? | . x=tf.Variable(2.0) with tf.GradientTape(persistent=True, watch_accessed_variables=False) as mytape : a=x/2*3 y=a*x**2 . mytape.gradient(y,x) . 관찰 4 . 관찰해 -&gt; 관찰하지마 -&gt; 관찰해 | . x=tf.Variable(2.0) with tf.GradientTape(persistent=True, watch_accessed_variables=False) as mytape : mytape.watch(x) a=x/2*3 y=a*x**2 . mytape.gradient(y,x) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt; . 관찰 5 . 관찰해 -&gt; 관찰해 -&gt; 관찰해 | . x=tf.Variable(2.0) with tf.GradientTape(persistent=True) as mytape : mytape.watch(x) a=x/2*3 y=a*x**2 . mytape.gradient(y,x) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt; .",
            "url": "https://kimha02.github.io/ham/2022/03/27/_03_21_(3%EC%A3%BC%EC%B0%A8)_3%EC%9B%9421%EC%9D%BC.html",
            "relUrl": "/2022/03/27/_03_21_(3%EC%A3%BC%EC%B0%A8)_3%EC%9B%9421%EC%9D%BC.html",
            "date": " • Mar 27, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "(2주차) 3월14일",
            "content": "import tensorflow as tf import numpy as np . GPU 확인하기 | . tf.config.experimental.list_physical_devices(&#39;GPU&#39;) . 2022-03-14 19:05:01.108074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:05:01.137264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:05:01.137808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero . [PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)] . . tf.constant . &#50696;&#48708;&#54617;&#49845;: &#51473;&#52393;&#47532;&#49828;&#53944; . lst=[1,2] lst . [1, 2] . lst[0] . 1 . lst[-1] . 2 . lst=[[1,2],[3,4]] . lst[1] . [3, 4] . lst[1][0] . 3 . 행렬같이 접근할 수 있다. -&gt; 1차원이지만 2차원처럼 생각할 수 있다. | . print(lst[0][0]) #(1,1) . 열벡터 | . lst=[1],[2],[3],[4] lst . ([1], [2], [3], [4]) . np.array(lst).shape . (4, 1) . 행벡터 | . lst=[[1,2,3,4]] lst . [[1, 2, 3, 4]] . np.array(lst).shape . (1, 4) . &#49440;&#50616; . 스칼라 | . tf.constant(3.14) . 2022-03-14 19:25:59.940288: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-14 19:25:59.941215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:25:59.942112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:25:59.942934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:26:00.917651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:26:00.918070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:26:00.918447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:26:00.918816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14784 MB memory: -&gt; device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6 . &lt;tf.Tensor: shape=(), dtype=float32, numpy=3.14&gt; . tf.constant(3.14)+tf.constant(3.14) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=6.28&gt; . 벡터 | . tf.constant([1,2,3]) . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)&gt; . _vector=tf.constant([1,2,3]) . _vector[-1] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt; . _vector[0] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . 매트릭스 | . _matrix=tf.constant([[1,2],[3,4]]) _matrix . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]], dtype=int32)&gt; . 3차원 벡터(텐서) | . _tensor=tf.constant([[[1,2],[3,4]],[[1,2],[3,4]]]) _tensor . &lt;tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy= array([[[1, 2], [3, 4]], [[1, 2], [3, 4]]], dtype=int32)&gt; . &#53440;&#51077; . type(tf.constant([1,2])) . tensorflow.python.framework.ops.EagerTensor . &#51064;&#45937;&#49905; . _matrix=tf.constant([[1,2],[3,4]]) _matrix . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]], dtype=int32)&gt; . _matrix[0][0] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . _matrix[0] #행뽑기 . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)&gt; . _matrix[0,:] #행뽑기 . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)&gt; . _matrix[:,0] #열뽑기 . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3], dtype=int32)&gt; . tf.constant&#45716; &#48520;&#54200;&#54616;&#45796;. . - 불편한 점 . 모든 원소가 같은 데이터 타입을 가지고 있어야 함. | 원소 수령이 불가능함. | 묵시적 변환이 불가능함. | float + float 계산이 안 됨. | . 원소 수정이 불가능함 | . a=tf.constant([1,22,33]) a . &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 22, 33], dtype=int32)&gt; . a[0] . &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt; . a[0]=[11] #변경이 안된다 . TypeError Traceback (most recent call last) Input In [93], in &lt;cell line: 1&gt;() -&gt; 1 a[0]=[11] TypeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object does not support item assignment . . 1+3.14 . 4.140000000000001 . 타입이 다른 두 숫자의 계산이 가능해보인다. | 그런데 살펴보면... | . tf.constant(1)+tf.constant(3.14) #여기서는 int+float 안된다. . InvalidArgumentError Traceback (most recent call last) Input In [80], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant(1)+tf.constant(3.14) File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2] . tf.constant(1.00)+tf.constant(3.14) # float으로 바꿔주면 가능... . &lt;tf.Tensor: shape=(), dtype=float32, numpy=4.1400003&gt; . . tf.constant(1.00) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=1.0&gt; . tf.constant(3.14) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=3.14&gt; . tf.constant(1.00, dtype=tf.float64) . &lt;tf.Tensor: shape=(), dtype=float64, numpy=1.0&gt; . tf.constant(1.00, dtype=tf.float64)+tf.constant(3.14) #float 버전이 다르니까 계산이 안됨. . InvalidArgumentError Traceback (most recent call last) Input In [92], in &lt;cell line: 1&gt;() -&gt; 1 tf.constant(1.00, dtype=tf.float64)+tf.constant(3.14) File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:AddV2] . tf.constant $ to$ &#45336;&#54028;&#51060; . np.array(1)+np.array(3.14) . 4.140000000000001 . tf.constant(np.array([[1,2],[3,4]])) . &lt;tf.Tensor: shape=(2, 2), dtype=int64, numpy= array([[1, 2], [3, 4]])&gt; . 텐서를 넘파이로 바꾸는 법 | . np.array(tf.constant(1)) . array(1, dtype=int32) . a=tf.constant(3.14) type(a) . tensorflow.python.framework.ops.EagerTensor . a.numpy() . 3.14 . &#50672;&#49328; . - 더하기 . tf.constant([1,2])+tf.constant([3,4]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)&gt; . a=tf.constant([1,2]) b=tf.constant([3,4]) a+b . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)&gt; . tf.add(a,b) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)&gt; . tf.add([1,2],[5,6]) . &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([6, 8], dtype=int32)&gt; . - 곱하기 . a=tf.constant([[1,2],[3,4]]) b=tf.constant([[5,6],[7,8]]) a*b . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[ 5, 12], [21, 32]], dtype=int32)&gt; . tf.multiply(a,b) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[ 5, 12], [21, 32]], dtype=int32)&gt; . - 일반적인 매트릭스 곱 . a=tf.constant([[1,0],[0,1]]) #(2,2) b=tf.constant([[5],[7]]) #(2,1) a@b . &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[5], [7]], dtype=int32)&gt; . tf.matmul(a,b) . &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[5], [7]], dtype=int32)&gt; . - 역행렬 . a=tf.constant([[1,0],[0,2]]) a . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 0], [0, 2]], dtype=int32)&gt; . tf.linalg.inv(a) #1/2를 만들려면 int는 안되고 float으로 해야 한다는 오류... . InvalidArgumentError Traceback (most recent call last) Input In [125], in &lt;cell line: 1&gt;() -&gt; 1 tf.linalg.inv(a) File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/ops/gen_linalg_ops.py:1506, in matrix_inverse(input, adjoint, name) 1504 return _result 1505 except _core._NotOkStatusException as e: -&gt; 1506 _ops.raise_from_not_ok_status(e, name) 1507 except _core._FallbackException: 1508 pass File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: Value for attr &#39;T&#39; of int32 is not in the list of allowed values: double, float, half, complex64, complex128 ; NodeDef: {{node MatrixInverse}}; Op&lt;name=MatrixInverse; signature=input:T -&gt; output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]&gt; [Op:MatrixInverse] . a=tf.constant([[1.0,0.0],[0.0,2.0]]) tf.linalg.inv(a) . &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy= array([[1. , 0. ], [0. , 0.5]], dtype=float32)&gt; . - tf.linalg + tab 에서 몇 개 응용 . a=tf.constant([[1.0,2.0],[3.0,4.0]]) print(a) tf.linalg.det(a) . tf.Tensor( [[1. 2.] [3. 4.]], shape=(2, 2), dtype=float32) . &lt;tf.Tensor: shape=(), dtype=float32, numpy=-2.0&gt; . tf.linalg.trace(a) #대각 원소의 합 . &lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt; . &#54805;&#53468;&#48320;&#54872; . - 기본 : tf.reshape()를 이용 . a=tf.constant([1,2,3,4]) #그냥 길이가 4인 벡터 a . &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt; . tf.reshape(a, (4,1)) #4X1 매트릭스로 . &lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy= array([[1], [2], [3], [4]], dtype=int32)&gt; . tf.reshape(a, (2,2)) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]], dtype=int32)&gt; . tf.reshape(a, (2,2,1)) #3차원도 가능하다 . &lt;tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy= array([[[1], [2]], [[3], [4]]], dtype=int32)&gt; . - 다차원 . a=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12]) a . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype=int32)&gt; . tf.reshape(a,(2,2,3)) . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]], dtype=int32)&gt; . tf.reshape(a,(4,3)) . &lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy= array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]], dtype=int32)&gt; . - tf.resh : 알아서 짝을 찾아주면 안되나? 안되면 그냥 에러메세지를 띄워줘 . a=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12]) a . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype=int32)&gt; . tf.reshape(a,(4,-1)) #-1은 물음표 역할 . &lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy= array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]], dtype=int32)&gt; . tf.reshape(a,(2,2,-1)) . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]], dtype=int32)&gt; . b=tf.reshape(a,(2,2,-1)) b . &lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy= array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]], dtype=int32)&gt; . tf.reshape(b,-1) #그냥 벡터로 만들어줘 . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype=int32)&gt; . &#49440;&#50616;&#44256;&#44553; . - 다른 자료형(리스트, 넘파이 등)로 만들고 바꾸는 것도 좋음! . np.diag([1,2,3,4]) #대각행렬 . array([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 0], [0, 0, 0, 4]]) . tf.constant(np.diag([1,2,3,4])) #넘파이-&gt;텐서 . &lt;tf.Tensor: shape=(4, 4), dtype=int64, numpy= array([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 0], [0, 0, 0, 4]])&gt; . - tf.ones, tf.zeros . tf.zeros([3,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], dtype=float32)&gt; . tf.reshape(tf.constant([0]*9),(3,3)) . &lt;tf.Tensor: shape=(3, 3), dtype=int32, numpy= array([[0, 0, 0], [0, 0, 0], [0, 0, 0]], dtype=int32)&gt; . - range(10) . a=range(0,10) #그냥 range(0,10)은 아무 정보가 없다 list(a) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . a=range(0,12) tf.constant(a) . &lt;tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], dtype=int32)&gt; . list(range(5)) #0은 생략할 수 있음, 마지막 숫자는 빠진다. . [0, 1, 2, 3, 4] . list(range(1,5)) #1에서 시작하지만 여전히 5는 안들어감 . [1, 2, 3, 4] . list(range(1,20,3)) #3칸씩 빼고 . [1, 4, 7, 10, 13, 16, 19] . tf.constant(range(1,20,3)) #3칸씩 빼고 . &lt;tf.Tensor: shape=(7,), dtype=int32, numpy=array([ 1, 4, 7, 10, 13, 16, 19], dtype=int32)&gt; . - tf.linspace . tf.linspace(0,1,10) #0~1까지 10개 뽑기, 여기선 1이 포함된다. . &lt;tf.Tensor: shape=(10,), dtype=float64, numpy= array([0. , 0.11111111, 0.22222222, 0.33333333, 0.44444444, 0.55555556, 0.66666667, 0.77777778, 0.88888889, 1. ])&gt; . tf.concat . a=tf.constant([[1],[2]]) b=tf.constant([[3],[4]]) a,b . (&lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[1], [2]], dtype=int32)&gt;, &lt;tf.Tensor: shape=(2, 1), dtype=int32, numpy= array([[3], [4]], dtype=int32)&gt;) . - (2,1) concat (2,1) =&gt; (4,1) . 첫번째 축이 바뀌었음. =&gt; axis=0 | . tf.concat([a,b],axis=0) #axis입력 필수 . &lt;tf.Tensor: shape=(4, 1), dtype=int32, numpy= array([[1], [2], [3], [4]], dtype=int32)&gt; . - (2,1) concat (2,1) =&gt; (2,2) . 두번째 축이 바뀌었음. =&gt; axis=1 | . tf.concat([a,b],axis=1) #axis입력 필수 . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 3], [2, 4]], dtype=int32)&gt; . - (1,2) concat (1,2) =&gt; (2,2) . 첫번째가 바뀌니까 axis=0 | . a=tf.constant([[1,2]]) b=tf.constant([[3,4]]) . tf.concat([a,b],axis=0) . &lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy= array([[1, 2], [3, 4]], dtype=int32)&gt; . - (1,2) concat (1,2) =&gt; (1,4) . 첫번째가 바뀌니까 axis=1 | . a=tf.constant([[1,2]]) b=tf.constant([[3,4]]) . tf.concat([a,b],axis=1) . &lt;tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[1, 2, 3, 4]], dtype=int32)&gt; . - 차원을 늘려보자! - (2,3,4,5) concat (2,3,4,5) =&gt; (4,3,4,5) . 첫번째 -&gt; axis=0 | . a=tf.reshape(tf.constant(range(120)), (2,3,4,5)) b=-a . tf.concat([a,b],axis=0).shape . TensorShape([4, 3, 4, 5]) . - (2,3,4,5) concat (2,3,4,5) =&gt; (2,6,4,5) . 두번째 -&gt; axis=1 | . a=tf.reshape(tf.constant(range(120)), (2,3,4,5)) b=-a . tf.concat([a,b],axis=1).shape . TensorShape([2, 6, 4, 5]) . - (2,3,4,5) concat (2,3,4,5) =&gt; (2,3,8,5) . 세번째 -&gt; axis=2 | . a=tf.reshape(tf.constant(range(120)), (2,3,4,5)) b=-a . tf.concat([a,b],axis=2).shape . TensorShape([2, 3, 8, 5]) . - (2,3,4,5) concat (2,3,4,5) =&gt; (2,3,4,10) . 네번째 -&gt; axis=3, -1 | . a=tf.reshape(tf.constant(range(120)), (2,3,4,5)) b=-a . tf.concat([a,b], axis=-1).shape . TensorShape([2, 3, 4, 10]) . tf.concat([a,b], axis=3).shape . TensorShape([2, 3, 4, 10]) . - 차원을 줄여보자! - (4,) concat (4,) =&gt; (8,) . 첫번째 축이 변하는게 맞나? | axis=0 이 잘 실행됨. | . a=tf.constant([1,2,3,4]) b=-a a,b . (&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;, &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)&gt;) . tf.concat([a,b],axis=0).shape . TensorShape([8]) . - 1이 생략된건가? - (4,) concat (4,) =&gt; (4,2) . 두번째 축 =&gt; axis=2 ==&gt; 안된다. 왜냐하면 1이 생략된 것이 아니라 그냥 1차원이기 때문에 | . a=tf.constant([1,2,3,4]) b=-a a,b . (&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;, &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)&gt;) . tf.concat([a,b], axis=1).shape . InvalidArgumentError Traceback (most recent call last) Input In [239], in &lt;cell line: 1&gt;() -&gt; 1 tf.concat([a,b], axis=1).shape File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs) 151 except Exception as e: 152 filtered_tb = _process_traceback_frames(e.__traceback__) --&gt; 153 raise e.with_traceback(filtered_tb) from None 154 finally: 155 del filtered_tb File ~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107, in raise_from_not_ok_status(e, name) 7105 def raise_from_not_ok_status(e, name): 7106 e.message += (&#34; name: &#34; + name if name is not None else &#34;&#34;) -&gt; 7107 raise core._status_to_exception(e) from None InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat . tf.stack . - 위에서 못한 거 stack으로 가능! . a=tf.constant([1,2,3,4]) b=-a a,b . (&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)&gt;, &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)&gt;) . tf.stack([a,b]) #근데 2X4 매트릭스다. 왜냐면 디폴트가 axis=0여서 . &lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy= array([[ 1, 2, 3, 4], [-1, -2, -3, -4]], dtype=int32)&gt; . tf.stack([a,b], axis=1) . &lt;tf.Tensor: shape=(4, 2), dtype=int32, numpy= array([[ 1, -1], [ 2, -2], [ 3, -3], [ 4, -4]], dtype=int32)&gt; . concat은 매트릭스를 합치면 매트릭스가 나온다. 벡터를 합쳐서 매트릭스 안 됨. | 하지만 stack은 벡터 합쳐서 매트릭스가 가능함. | . tnp . tnp = tensorflow+numpy . - 텐서 만들기가 너무 힘듦. . np.diag([1,2,3]).reshape(-1) . array([1, 0, 0, 0, 2, 0, 0, 0, 3]) . tnp &#49324;&#50857;&#48169;&#48277; (&#48520;&#47564;&#54644;&#44208;&#48169;&#48277;) . import tensorflow.experimental.numpy as tnp . tnp.experimental_enable_numpy_behavior() #동작을 위한 모드를 키는? . type(tnp.array([1,2,3])) . tensorflow.python.framework.ops.EagerTensor . - int와 float을 더할 수 있음. . tnp.array([1,2,3])+tnp.array([1.0,2.0,3.0]) . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])&gt; . tnp.array(1)+tnp.array([1.0,2.0,3.0]) #브로드캐스팅 다름(차원이 달라도 계산 가능) . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 3., 4.])&gt; . tf.constant([1,2,3])+tf.constant([1.0,2.0,3.0]) #원래 안되던 것도 모드를 키면 넘파이처럼 동작함 . &lt;tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])&gt; . tnp.diag([1,2,3]) . &lt;tf.Tensor: shape=(3, 3), dtype=int64, numpy= array([[1, 0, 0], [0, 2, 0], [0, 0, 3]])&gt; . a=tnp.diag([1,2,3]) type(a) #텐서 그대로 나옴 . tensorflow.python.framework.ops.EagerTensor . a.min() #최소값 찾기 . &lt;tf.Tensor: shape=(), dtype=int64, numpy=0&gt; . a.reshape(-1) . &lt;tf.Tensor: shape=(9,), dtype=int64, numpy=array([1, 0, 0, 0, 2, 0, 0, 0, 3])&gt; . a=tf.constant([1,2,3]) a.reshape(3,1) . &lt;tf.Tensor: shape=(3, 1), dtype=int32, numpy= array([[1], [2], [3]], dtype=int32)&gt; . &#49440;&#50616;, &#49440;&#50616;&#44256;&#44553; . np.random.randn(5) #정규분포에서 뽑기 . array([ 0.449788 , 1.9891379 , -0.47806401, 1.23461833, -0.64734895]) . tnp.random.randn(5) . &lt;tf.Tensor: shape=(5,), dtype=float64, numpy=array([-0.20001553, 0.93705984, -0.64863757, 1.26619036, -0.23964021])&gt; . &#53440;&#51077; . type(tnp.random.randn(5)) . tensorflow.python.framework.ops.EagerTensor . tf.contant&#47196; &#47564;&#46308;&#50612;&#46020; &#47560;&#52824; &#45336;&#54028;&#51060;&#51064;&#46319; &#50416;&#45716; &#44592;&#45733;&#46308; . [장점들] . - 묵시적 형변환이 가능 -&gt; int + float 계산 가능! . - method의 종류가 아주 많아졌다는 것! -&gt; .을 찍어 실행하는 것들 . a=tnp.array([[1,2,3,4]]) a.T . &lt;tf.Tensor: shape=(4, 1), dtype=int64, numpy= array([[1], [2], [3], [4]])&gt; . &#44536;&#47111;&#51648;&#47564; np.array&#45716; &#50500;&#45784; . a=tf.constant([1,2,3]) . a.reshape(3,1) . &lt;tf.Tensor: shape=(3, 1), dtype=int32, numpy= array([[1], [2], [3]], dtype=int32)&gt; . 여기까지는 잘 실행된다. | 하지만 | . a[0]=11 . TypeError Traceback (most recent call last) Input In [276], in &lt;cell line: 1&gt;() -&gt; 1 a[0]=11 TypeError: &#39;tensorflow.python.framework.ops.EagerTensor&#39; object does not support item assignment . 값 바꾸기는 여전히 안 됨. | .",
            "url": "https://kimha02.github.io/ham/bigdata/2022/03/27/_03_14_(2%EC%A3%BC%EC%B0%A8)_3%EC%9B%9414%EC%9D%BC.html",
            "relUrl": "/bigdata/2022/03/27/_03_14_(2%EC%A3%BC%EC%B0%A8)_3%EC%9B%9414%EC%9D%BC.html",
            "date": " • Mar 27, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "(1주차) 3월7일",
            "content": "&#47196;&#46300;&#47605; . - 오늘수업할내용: 단순선형회귀 . - 단순선형회귀를 배우는 이유? . 우리가 배우고싶은것: 심층신경망(DNN) $ to$ 합성곱신경망(CNN) $ to$ 적대적생성신경망(GAN) | 심층신경망을 바로 이해하기 어려움 | 다음의 과정으로 이해해야함: (선형대수학 $ to$) 회귀분석 $ to$ 로지스틱회귀분석 $ to$ 심층신경망 | . &#49440;&#54805;&#54924;&#44480; . - 상황극 . 나는 동네에 커피점을 하나 차렸음. | 장사를 하다보니까 날이 더울수록 아이스아메리카노의 판매량이 증가한다는 사실을 깨달았다. | 일기예보는 미리 나와있으니까 그 정보를 잘 이용하면 &#39;온도 -&gt; 아이스아메리카노 판매량 예측&#39; 이 가능할것 같다. (내가 앞으로 얼마나 벌지 예측가능) | . - 가짜자료 생성 . . !pip install matplotlib . Collecting matplotlib Downloading matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB) |████████████████████████████████| 11.9 MB 10.3 MB/s eta 0:00:01 Requirement already satisfied: packaging&gt;=20.0 in /home/khy/anaconda3/envs/py310/lib/python3.10/site-packages (from matplotlib) (21.3) Requirement already satisfied: pyparsing&gt;=2.2.1 in /home/khy/anaconda3/envs/py310/lib/python3.10/site-packages (from matplotlib) (3.0.7) Collecting cycler&gt;=0.10 Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB) Collecting pillow&gt;=6.2.0 Downloading Pillow-9.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB) |████████████████████████████████| 4.3 MB 48.3 MB/s eta 0:00:01 Requirement already satisfied: numpy&gt;=1.17 in /home/khy/anaconda3/envs/py310/lib/python3.10/site-packages (from matplotlib) (1.22.3) Collecting kiwisolver&gt;=1.0.1 Downloading kiwisolver-1.3.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB) |████████████████████████████████| 1.6 MB 140.8 MB/s eta 0:00:01 Requirement already satisfied: python-dateutil&gt;=2.7 in /home/khy/anaconda3/envs/py310/lib/python3.10/site-packages (from matplotlib) (2.8.2) Collecting fonttools&gt;=4.22.0 Downloading fonttools-4.30.0-py3-none-any.whl (898 kB) |████████████████████████████████| 898 kB 136.9 MB/s eta 0:00:01 Requirement already satisfied: six&gt;=1.5 in /home/khy/anaconda3/envs/py310/lib/python3.10/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0) Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib Successfully installed cycler-0.11.0 fonttools-4.30.0 kiwisolver-1.3.2 matplotlib-3.5.1 pillow-9.0.1 . import matplotlib.pyplot as plt import tensorflow as tf . tf.__version__ . &#39;2.8.0&#39; . tf.test.is_gpu_available() . WARNING:tensorflow:From /tmp/ipykernel_4092859/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.config.list_physical_devices(&#39;GPU&#39;)` instead. . 2022-03-14 19:07:04.285513: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. . True . 2022-03-14 19:07:04.286377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:07:04.287264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:07:04.288045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:07:05.247104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:07:05.247526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:07:05.247913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:07:05.248292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 15225 MB memory: -&gt; device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6 . tf.config.list_physical_devices(&#39;GPU&#39;) . 2022-03-14 19:06:47.307952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:06:47.328154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2022-03-14 19:06:47.328566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero . [PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)] . 온도 ${ bf x}$가 아래와 같다고 하자. . x=tf.constant([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) # 기온 x . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4], dtype=float32)&gt; . constant :상수 값을 생성 . 아이스아메리카노의 판매량 ${ bf y}$이 아래와 같다고 하자. (판매량은 정수로 나오겠지만 편의상 소수점도 가능하다고 생각하자) . $${ bf y} approx 10.2 +2.2 { bf x}$$ . 여기에서 10.2, 2.2 의 숫자는 제가 임의로 정한것임 | 식의의미: 온도가 0일때 10.2잔정도 팔림 + 온도가 1도 증가하면 2.2잔정도 더 팔림 | 물결의의미: 현실반영. 세상은 꼭 수식대로 정확하게 이루어지지 않음. | . tf.random.set_seed(43052) epsilon=tf.random.normal([10]) #오차 : 정규분포에서 랜덤하게 샘플 10개를 뽑음 y=10.2 + 2.2*x + epsilon y . &lt;tf.Tensor: shape=(10,), dtype=float32, numpy= array([55.418365, 58.194283, 61.230827, 62.312557, 63.107002, 63.69569 , 67.247055, 71.4365 , 73.1013 , 77.84988 ], dtype=float32)&gt; . - 우리는 아래와 같은 자료를 모았다고 생각하자. . tf.transpose(tf.concat([[x],[y]],0)) #concat : 데이터 합치기! . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[20.1 , 55.418365], [22.2 , 58.194283], [22.7 , 61.230827], [23.3 , 62.312557], [24.4 , 63.107002], [25.1 , 63.69569 ], [26.2 , 67.247055], [27.3 , 71.4365 ], [28.4 , 73.1013 ], [30.4 , 77.84988 ]], dtype=float32)&gt; . tf.transpose(tf.concat([[x],[y]],1)) #concat : 데이터 합치기! . &lt;tf.Tensor: shape=(20, 1), dtype=float32, numpy= array([[20.1 ], [22.2 ], [22.7 ], [23.3 ], [24.4 ], [25.1 ], [26.2 ], [27.3 ], [28.4 ], [30.4 ], [55.418365], [58.194283], [61.230827], [62.312557], [63.107002], [63.69569 ], [67.247055], [71.4365 ], [73.1013 ], [77.84988 ]], dtype=float32)&gt; . [x],[y]로 열을 구분해주지 않으면 한 개의 데이터처럼 합쳐진다. 0은 행, 열 구분이다. . - 그려보자. . plt.plot(x,y,&#39;.&#39;) # 파란점, 관측한 데이터 plt.plot(x,10.2 + 2.2*x, &#39;--&#39;) # 주황색점선, 세상의 법칙 . [&lt;matplotlib.lines.Line2D at 0x7f98d00a90d0&gt;] . - 우리의 목표: 파란색점 $ to$ 주황색점선을 추론 // 데이터를 바탕으로 세상의 법칙을 추론 . - 아이디어: 데이터를 보니까 $x$와 $y$가 선형의 관계에 있는듯 보인다. 즉 모든 $i=1,2, dots, 10$에 대하여 아래를 만족하는 적당한 a,b (혹은 $ beta_0, beta_1$) 가 존재할것 같다. . $y_{i} approx ax_{i}+b$ | $y_{i} approx beta_1 x_{i}+ beta_0$ | . - 어림짐작으로 $a,b$를 알아내보자. . 데이터를 살펴보자. . tf.transpose(tf.concat([[x],[y]],0)) . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[20.1 , 55.418365], [22.2 , 58.194283], [22.7 , 61.230827], [23.3 , 62.312557], [24.4 , 63.107002], [25.1 , 63.69569 ], [26.2 , 67.247055], [27.3 , 71.4365 ], [28.4 , 73.1013 ], [30.4 , 77.84988 ]], dtype=float32)&gt; . 적당히 왼쪽*2+15 = 오른쪽의 관계가 성립하는것 같다. . 따라서 $a=2, b=15$ 혹은 $ beta_0=15, beta_1=2$ 로 추론할 수 있겠다. . - 누군가가 $( beta_0, beta_1)=(14,2)$ 이라고 주장할 수 있다. (어차피 지금은 감각으로 추론하는 과정이니까) . - 새로운 주장으로 인해서 $( beta_0, beta_1)=(15,2)$ 로 볼 수도 있고 $( beta_0, beta_1)=(14,2)$ 로 볼 수도 있다. 이중에서 어떠한 추정치가 좋은지 판단할 수 있을까? . 후보1: $( beta_0, beta_1)=(15,2)$ | 후보2: $( beta_0, beta_1)=(14,2)$ | . - 가능한 $y_i approx beta_0 + beta_1 x_i$ 이 되도록 만드는 $( beta_0, beta_1)$ 이 좋을 것이다. $ to$ 후보 1,2를 비교해보자. . (관찰에 의한 비교) . 후보1에 대해서 $i=1,2$를 넣고 관찰하여 보자. . 20.1 * 2 + 15 , 55.418365 # i=1 . (55.2, 55.418365) . 22.2 * 2 + 15 , 58.194283 # i=2 . (59.4, 58.194283) . 후보2에 대하여 $i=1,2$를 넣고 관찰하여 보자. . 20.1 * 2 + 14 , 55.418365 # i=1 . (54.2, 55.418365) . 22.2 * 2 + 14 , 58.194283 # i=2 . (58.4, 58.194283) . $i=1$인 경우에는 후보1이 더 잘맞는것 같은데 $i=2$인 경우는 후보2가 더 잘맞는것 같다. . (좀 더 체계적인 비교) . $i=1,2,3, dots, 10$ 에서 후보1과 후보2중 어떤것이 더 좋은지 비교하는 체계적인 방법을 생각해보자. . 후보 1,2에 대하여 $ sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2$를 계산하여 비교해보자. . sum1=0 for i in range(10): sum1=sum1+(y[i]-15-2*x[i])**2 . sum2=0 for i in range(10): sum2=sum2+(y[i]-14-2*x[i])**2 . sum1,sum2 . (&lt;tf.Tensor: shape=(), dtype=float32, numpy=14.734169&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=31.521088&gt;) . 후보1이 더 $ sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2$의 값이 작다. . 후보1이 종합적으로 후보2에 비하여 좋다. 이 과정을 무한번 반복하면 최적의 추정치를 찾을 수 있다. . - 그런데 이 알고리즘은 현실적으로 구현이 불가능하다. (무한번 계산하기도 힘들고, 언제 멈출지도 애매함) . - 수학을 이용해서 좀 더 체계적으로 찾아보자. 결국 아래식을 가장 작게 만드는 $ beta_0, beta_1$을 찾으면 된다. . $ sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2$ . 그런데 결국 $ beta_0, beta_1$에 대한 이차식인데 이 식을 최소화하는 $ beta_0, beta_1$을 구하기 위해서는 아래를 연립하여 풀면된다. . $ begin{cases} frac{ partial}{ partial beta_0} sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2=0 frac{ partial}{ partial beta_1} sum_{i=1}^{10} (y_i - beta_0 - beta_1 x_i)^2=0 end{cases}$ . - 풀어보자. . $ begin{cases} sum_{i=1}^{10} -2(y_i - beta_0 - beta_1 x_i)=0 sum_{i=1}^{10} -2x_i(y_i - beta_0 - beta_1 x_i)=0 end{cases}$ . 정리하면 . $$ hat{ beta}_0= bar{y}- hat{ beta}_1 bar{x}$$ . $$ hat{ beta}_1= frac{S_{xy}}{S_{xx}}= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y})}{ sum_{i=1}^{n}(x_i- bar{x})^2}$$ . - 따라서 최적의 추정치 $( hat{ beta}_0, hat{ beta}_1)$를 이용한 추세선을 아래와 같이 계산할 수 있음. . Sxx= sum((x-sum(x)/10)**2) Sxx . &lt;tf.Tensor: shape=(), dtype=float32, numpy=87.848976&gt; . Sxy= sum((x-sum(x)/10)*(y-sum(y)/10)) Sxy . &lt;tf.Tensor: shape=(), dtype=float32, numpy=194.64737&gt; . beta1_estimated = Sxy/Sxx beta1_estimated . &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.2157044&gt; . beta0_estimated = sum(y)/10 - beta1_estimated * sum(x)/10 beta0_estimated . &lt;tf.Tensor: shape=(), dtype=float32, numpy=9.944572&gt; . plt.plot(x,y,&#39;.&#39;) plt.plot(x,beta0_estimated + beta1_estimated * x, &#39;--&#39;) # 주황색선: 세상의 법칙을 추정한선 plt.plot(x,10.2 + 2.2* x, &#39;--&#39;) # 초록색선: ture, 세상의법칙 . [&lt;matplotlib.lines.Line2D at 0x7f98a4483550&gt;] . . Note: 샘플수가 커질수록 주황색선은 점점 초록색선으로 가까워진다. . - 꽤 훌륭한 도구임. 그런데 약간의 단점이 존재한다. . (1) 공식이 좀 복잡함.. . (2) $x$가 여러개일 경우 확장이 어려움 . - 단점을 극복하기 위해서 우리가 지금까지 했던논의를 매트릭스로 바꾸어서 다시 써보자. . - 모형의 매트릭스화 . 우리의 모형은 아래와 같다. . $y_i = beta_0 + beta_1 x_i + epsilon_i, quad i=1,2, dots,10$ . 풀어서 쓰면 . $ begin{cases} y_1 = beta_0 + beta_1 x_1 + epsilon_1 y_2 = beta_0 + beta_1 x_2 + epsilon_2 dots y_{10} = beta_0 + beta_1 x_{10} + epsilon_{10} end{cases}$ . 아래와 같이 쓸 수 있다. . $ begin{bmatrix} y_1 y_2 dots y_{10} end{bmatrix} = begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots &amp; dots 1 &amp; x_{10} end{bmatrix} begin{bmatrix} beta_0 beta_1 end{bmatrix} + begin{bmatrix} epsilon_1 epsilon_2 dots epsilon_{10} end{bmatrix} $ . 벡터와 매트릭스 형태로 정리하면 . ${ bf y} = { bf X} { boldsymbol beta} + boldsymbol{ epsilon}$ . - 손실함수의 매트릭스화: 우리가 최소화 하려던 손실함수는 아래와 같다. . $loss= sum_{i=1}^{n}(y_i- beta_0- beta_1x_i)^2$ . 이것을 벡터표현으로 하면 아래와 같다. . $loss= sum_{i=1}^{n}(y_i- beta_0- beta_1x_i)^2=({ bf y}-{ bf X}{ boldsymbol beta})^ top({ bf y}-{ bf X}{ boldsymbol beta})$ . 풀어보면 . $loss=({ bf y}-{ bf X}{ boldsymbol beta})^ top({ bf y}-{ bf X}{ boldsymbol beta})={ bf y}^ top { bf y} - { bf y}^ top { bf X}{ boldsymbol beta} - { boldsymbol beta}^ top { bf X}^ top { bf y} + { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . - 미분하는 과정의 매트릭스화 . loss를 최소화하는 ${ boldsymbol beta}$를 구해야하므로 loss를 ${ boldsymbol beta}$로 미분한식을 0이라고 놓고 풀면 된다. . $ frac{ partial}{ partial boldsymbol{ beta}} loss = frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf y} - frac{ partial}{ partial boldsymbol{ beta}} { bf y}^ top { bf X}{ boldsymbol beta} - frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf y} + frac{ partial}{ partial boldsymbol{ beta}} { boldsymbol beta}^ top { bf X}^ top { bf X} { boldsymbol beta}$ . $= 0 - { bf X}^ top { bf y}- { bf X}^ top { bf y} + 2{ bf X}^ top { bf X}{ boldsymbol beta} $ . 따라서 $ frac{ partial}{ partial boldsymbol{ beta}}loss=0$을 풀면 아래와 같다. . $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ . - 공식도 매트릭스로 표현하면: $ boldsymbol{ hat beta}= ({ bf X}^ top { bf X})^{-1}{ bf X}^ top { bf y} $ &lt;-- 외우세요 . - 적용을 해보자. . (X를 만드는 방법1) . X=tf.transpose(tf.concat([[[1.0]*10],[x]],0)) # X . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[ 1. , 20.1], [ 1. , 22.2], [ 1. , 22.7], [ 1. , 23.3], [ 1. , 24.4], [ 1. , 25.1], [ 1. , 26.2], [ 1. , 27.3], [ 1. , 28.4], [ 1. , 30.4]], dtype=float32)&gt; . (X를 만드는 방법2) . from tensorflow.python.ops.numpy_ops import np_config np_config.enable_numpy_behavior() . tf.concat([[[1.0]*10],[x]],0) . &lt;tf.Tensor: shape=(2, 10), dtype=float32, numpy= array([[ 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ], [20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]], dtype=float32)&gt; . tf.concat([[[1.0]*10],[x]],1) . &lt;tf.Tensor: shape=(1, 20), dtype=float32, numpy= array([[ 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]], dtype=float32)&gt; . X=tf.concat([[[1.0]*10],[x]],0).T X . &lt;tf.Tensor: shape=(10, 2), dtype=float32, numpy= array([[ 1. , 20.1], [ 1. , 22.2], [ 1. , 22.7], [ 1. , 23.3], [ 1. , 24.4], [ 1. , 25.1], [ 1. , 26.2], [ 1. , 27.3], [ 1. , 28.4], [ 1. , 30.4]], dtype=float32)&gt; . tf.linalg.inv(X.T @ X) @ X.T @ y . &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([9.944702, 2.215706], dtype=float32)&gt; . @는 매트릭스 곱하기! 9.944702, 2.215706 이 결과가 $ hat{ beta}_0, hat{ beta}_1$ . - 잘 구해진다. . - 그런데.. . beta0_estimated,beta1_estimated . (&lt;tf.Tensor: shape=(), dtype=float32, numpy=9.94458&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.2157042&gt;) . 값이 좀 다르다..? . - 같은 값입니다! 신경쓰지 마세요! 텐서플로우가 좀 대충계산합니다. . - 좀 더 정확하게 계산하려면... tensorflow 안에 있는 numpy를 사용하면 된다. . import tensorflow.experimental.numpy as tnp . tnp.array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) . &lt;tf.Tensor: shape=(10,), dtype=float64, numpy=array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4])&gt; . 아까와 다르게 float64 타입인 것을 확인할 수 있다. 이 형태는 좀 더 정확한 계산이 가능하다. . x=tnp.array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) y=10.2 + 2.2*x + epsilon . beta1_estimated = sum((x-sum(x)/10)*(y-sum(y)/10)) / sum((x-sum(x)/10)**2) beta0_estimated = sum(y)/10 - beta1_estimated * sum(x)/10 . beta0_estimated, beta1_estimated . (&lt;tf.Tensor: shape=(), dtype=float64, numpy=9.944573294798559&gt;, &lt;tf.Tensor: shape=(), dtype=float64, numpy=2.2157046054834106&gt;) . X=tnp.concatenate([[tnp.array([1.0]*10)],[x]],0).T tf.linalg.inv(X.T @ X) @ X.T @ y . &lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([9.94457329, 2.21570461])&gt; . &#50526;&#51004;&#47196; &#54624;&#44163; . - 선형대수학의 미분이론.. . - 실습 (tensorflow에서 매트릭스를 자유롭게 다루비) .",
            "url": "https://kimha02.github.io/ham/bigdata/2022/03/07/(1%EC%A3%BC%EC%B0%A8)_3%EC%9B%947%EC%9D%BC.html",
            "relUrl": "/bigdata/2022/03/07/(1%EC%A3%BC%EC%B0%A8)_3%EC%9B%947%EC%9D%BC.html",
            "date": " • Mar 7, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "(논문) Review",
            "content": ". 2DPCA . 혼자 공부하는 머신러닝+딥러닝의 주성분 분석 참고하여 작성함. | . import numpy as np from sklearn.decomposition import PCA import matplotlib.pyplot as plt import cv2 import torch from fastai.vision.all import * from PIL import Image . img = plt.imread(&#39;original.png&#39;) plt.imshow(img) plt.show . &lt;function matplotlib.pyplot.show(close=None, block=None)&gt; . img.shape[0] . 470 . 2DSSA . .",
            "url": "https://kimha02.github.io/ham/study/2022/03/04/writing.html",
            "relUrl": "/study/2022/03/04/writing.html",
            "date": " • Mar 4, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "(논문) Proposed method",
            "content": ". 3. Proposed method . &#51089;&#51008; &#51064;&#53944;&#47196; . AI는 이미지를 분류할 때 사람이 통상적으로 사용하는 분류 기준을 이용하지 않기도 한다. 이 때 추가적인 결과를 제공한다면 이미지를 분류한 충분한 증거가 확보되어 AI의 결과를 보완할 수 있을 것이다. 우리는 CAM을 통해 이미지가 특정 클래스로 분류되는데 중요한 역할을 한 픽셀을 확인하고 이미지에서 분리한다. 그 후에 해당 픽셀을 마스킹(masking)한 이미지를 생성해 그 다음 중요도가 높은 픽셀을 CAM을 통해 확인하는 과정을 올바른 클래스로 분류해낼 때 까지 반복한다. . . 3.1 &#45936;&#51060;&#53552; &#49444;&#47749; . 본 논문에서는 모드 분해를 설명하기 위한 예제로 Cat/Dog(https://www.robots.ox.ac.uk/~vgg/data/pets/)을 사용한다. 37종의 고양이, 개로 이루어진 $7,349$개 이미지 데이터로 사이즈는 $512 times 512$로 통일한다. 따라서 입력 이미지(아래 사진)인 $ bf X$는 $512 times 512$ 매트릭스이며, 클래스의 집합 $y$로 분류된다. begin{align} { bf{X}} : { bf{ Lambda}} to { mathbb{R}^3} {of size} {512 times 512} end{align} begin{align} y= {cat, dog } end{align} . . 학습은 resnet34를 사용하고, 총 epoch 수는 5이다. 예제를 통해 우리는 사람이 고양이, 개를 분류할 때 직관적으로 사용되는 특징에 CAM이 반응하여 모드 분해로 이어질 수 있는지를 확인하고, 이런 특징들이 중요도에 따라 순차적으로 나타나는지를 보고자 한다. . . 3.2 CAM(class activation mapping) . CAM은 global average pooling을 사용하여 CNN에서 이미지를 분류하는데 중요한 역할을 한 픽셀을 시각화하는 class activation map을 생성하는 기법이다. (Zhou et al, 2016) . GAP는 마지막 convolutional layer에서 k개의 activation map을 출력한다. 이를 feature map : $f_k(x,y)$라고 한다. feature map은 먼저 이미지에서 시각적인 패턴을 나타낸 지도로, 이 때 활성화된 픽셀은 이미지가 가진 특징(energy)를 보여준다. 예제 이미지는 컬러 이미지이기 때문에 feature map의 형태는 $3 times 16 times 16$이다. 이 때 channel의 수가 $3$이기 때문에 $k=3$ 이다. $w^c_k$는 클래스 $c$에 k번째 feature map의 특징변수가 얼마나 중요한지를 보여주는 가중치이다. 클래스 $c$에 대한 CAM $M_c$는 k번째 Feature Map의 각 픽셀값을 가중합한 결과이다. (Zhou et al, 2016) . ${ bf{M}}_c(x,y) = sum_k w^c_k f_k(x,y)$ . k :Feture Map의 index x,y : Feature Map의 가로(x), 세로(y) 좌표 . 예제 이미지를 통해 생성된 CAM은 $16 times 16$ 매트릭스 형태이며, 각 activation map을 $ bf{M}$$_{0}$, $ bf{M}$$_{1}$으로 지정한다. 사용되는 이미지가 고양이이기 때문에 모드 분해에는 ${ bf{M}}_{0}$을 사용한다. . ${ bf{M}}_{0} = { bf{M}}_{0_{x,y}}= begin{pmatrix} a_{1,1} &amp; a_{1,2} &amp; cdots &amp; a_{1,y} a_{2,1} &amp; a_{2,2} &amp; cdots &amp; a_{2,y} vdots &amp; vdots &amp; ddots &amp; vdots a_{x,1} &amp; a_{x,2} &amp; cdots &amp; a_{x,y} end{pmatrix} , x in {1,2, dots,16 } , y in {1,2, dots,16 }$ . . ${ bf{M}}_{1} = { bf{M}}_{1_{k,l}}= begin{pmatrix} a_{1,1} &amp; a_{1,2} &amp; cdots &amp; a_{1,l} a_{2,1} &amp; a_{2,2} &amp; cdots &amp; a_{2,l} vdots &amp; vdots &amp; ddots &amp; vdots a_{k,1} &amp; a_{k,2} &amp; cdots &amp; a_{k,l} end{pmatrix} , k in {1,2, dots,16 } , l in {1,2, dots,16 }$ . . 3.3 &#44032;&#51473;&#52824;(mask) &#49373;&#49457; . 우리는 이미지에 가중치(mask)를 곱하여 중요도가 높은 픽셀이 마스킹(masking)된 이미지를 생성한다. 가중치를 수식으로 표현하면 아래와 같으며, CAM과 동일한 $16 times 16$ 매트릭스 형태이다. . $w(x,y) = exp left(- frac{1}{2 theta^2} times { bf{M}}_{0}(x,y) right)$ . 여기서 사용된 $ theta$는 CAM 픽셀들의 분산을 표준화시켜주기 위한 hyper parameter이다. $ theta$는 모드 분해가 진행됨에 따라 픽셀들의 분산들이 작아져 약해진 신호(Yang et al, 2004)를 보정하기 위해 값을 증가시킨다. . . 3.4 &#47784;&#46300; &#48516;&#54644; (mode decomposition) . 가중치 $w$와 $ bf{X}$ 간 아다마르곱을 통해 모드 분해를 진행한다. 이 때, $w$는 $ bf{X}$와 형태가 다르기 때문에 bilinear interpolation을 진행하여 $512 times 512$형태로 재조정한다. . 아다마르곱을 통해 생성된 ${ bf{X}}^{(1)}_{res}$는 중요도가 높은 픽셀이 마스킹(masking)된 이미지, 모드 1의 residual이 되며, 숫자 $1$은 모드 분해 횟수이다. . ${ bf{X}}^{(1)}_{res} = { bf{X}} odot w$ . 모드 1, 중요도가 높은 픽셀을 추출한 이미지는 $1-w$와 $ bf{X}$ 간 아다마르곱으로 생성한다. . ${ bf{X}}^{(1)} = { bf{X}} odot (1-w)$ . 참고 :${ bf {X}} approx { bf {X}}^{(1)}+{ bf X}^{(2)}+{ bf X}^{(3)} dots +{ bf X}^{(m)}$를 만족한다. 왜냐하면, ${ bf X}={ bf X}^{(1)}+{ bf X}^{(1)}_{res}$, ${ bf X}^{(1)}={ bf X}^{(2)}+{ bf X}^{(2)}_{res} dots$를 만족하기 때문이다. 이 때 $m$은 모드 생성 횟수이다. . 3.1~4의 과정을 $ bf{X}$를 올바른 클래스로 분류해내지 못할 때, 즉 accuracy $ leq 0.5$ 일 때까지 진행한다 (Samek et al, 2016). 따라서 모드 분해는 2개 이상의 결과를 도출하여 이미지 분류에 보다 다양한 증거를 제시한다. . 3.4.1 &#47784;&#46300; &#48516;&#54644; &#44208;&#44284; . 예제를 사용한 모드 분해 분석 결과, 3번의 모드 분해를 진행하였다. 먼저 1~3회 CAM 결과를 보면, 1차에서는 수염이 있는 고양이 얼굴 아래 부분, 2차에서는 눈이 있는 얼굴 윗 부분, 3차에서는 얼굴을 제외한 귀 부분의 픽셀이 활성화된 것을 확인할 수 있다. . 이를 바탕으로 모드 분해를 진행한 결과는 아래와 같다. 각 시차별 활성화된 픽셀이 모드로 분리되고, 분리된 모드가 마스킹된 모드 residual이 생성되어 다시 모드 분해를 진행해나가는 과정이다. . 예제에서 우리가 기대한 결과가 도출되었기 때문에 실제 의료 데이터를 이용하여 분석을 진행해보고자 한다. . . 4. &#49892;&#51228; &#45936;&#51060;&#53552; &#48516;&#49437; . 사용된 데이터는 폐렴/정상 2가지로 분류된 총 $5863$개의 chest X-ray 이미지 데이터이다(https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia). 사이즈는 $224 times 224$ 로 통일한다. 분석에 사용된 샘플 이미지는 정상으로 분류된 X-ray이미지이다. . 앞서 설명한 과정을 통해 분석을 진행하였다. 고양이, 개에 비해 특징이 적어 2차 분해 후 특징이 나타나는 폐 부분이 검게 마스킹되어 분해를 중지하였다. 모드 분해에 따른 accuracy는 아래와 같다. . No Accuracy . 0 | 0.9999 | . 1 | 0.9906 | . 2 | 0.00 | . CAM 결과를 보면, 1차에서는 X-ray의 중앙 부분, 폐와 척추 부분이 활성화되었고, 2차에서는 오른쪽 폐의 아래 부분이 활성화되었다. . 이를 바탕으로 모드 분해를 진행한 결과는 아래와 같다. . CAM을 진행함에 따라 X-ray에서 중요도가 높은 순으로 픽셀이 활성화되었고, 성공적으로 분해가 진행되었다. . . 5. Discussions (&#44208;&#44284; &#51221;&#47532; &#48143; &#49884;&#49324;&#51216;) . 우리는 Cat/Dog 데이터에서 모드 분해 아이디어 실현 가능성을 확인하고, 실제 의료 데이터인 Chest X-ray 분석을 통해 이미지를 중요도에 따라 분해해나갈 수 있었다. . 이렇게 한 개의 이미지를 중요도에 따라 여러 특징으로 분해해내는 기법은 여러 분야에서 사용이 확대될 수 있을 것으로 기대된다. 예를 들면, 건물 보수 필요성을 검토하기 위한 노후 건물 이미지 분석을 한다고 하자. 이 때 사람도 AI도 쉽게 발견할 수 있는 커다란 균열이 1차 결과로 제시되었다면, 모드 분해를 통해 크기는 작지만 여전히 건물 보수의 필요성을 보여줄 수 있는 작은 균열들을 추가 증거로 제시하여 보다 풍부한 자료를 통해 적절한 시기에 보수가 이루어질 수 있도록 의사결정을 내릴 수 있을 것이다. . 하지만 여전히 한계점은 존재한다. 본 논문에서 실제 의료 데이터를 사용하여 분석을 진행하였지만, 의료 분야 전문 지식이 부재하여 다양한 의료 데이터를 적용하고 분석 내용을 해석하는데 있어 한계점이 있다. 향후 연구에서는 의료 분야 전문가와 협업하여 실제 의료 이미지 데이터에 모드 분해를 접목할 수 있는지를 살펴보고, 다양한 의료 데이터를 분석하여 더욱 다양한 시사점을 제공할 수 있을 것으로 기대된다. . 다른 한계점으로는 hyper parameter 세팅이 있다. 현재 제안하는 방법론에서 hyper parameter $ theta$는 이미지에 따라 여러 차례 시뮬레이션을 통해 가장 적절한 값을 탐색해야 하는 불편함이 존재한다. 향후 연구에서는 해당 parameter를 더 빠르고 쉽게 찾아낼 수 있는 알고리즘을 구상해볼 수 있을 것이다. . . Reference . bibitem{Song2019} 송경두, 김명찬, 도신호. 딥러닝 알고리즘 개발과정을 통해 본 영상의학분야에서 딥러닝의 최신 경향. J Korean Soc Radiol 2019; 80(2): 202-12. . bibitem{Hwang2021} Hwang, Eui Jin, et al. &quot;Deep learning computer-aided detection system for pneumonia in febrile neutropenia patients: a diagnostic cohort study.&quot; BMC pulmonary medicine 21.1 (2021): 1-11. . bibitem{Topol2019} Topol, Eric J. &quot;High-performance medicine: the convergence of human and artificial intelligence.&quot; Nature medicine 25.1 (2019): 44-56. . bibitem{Ko2021} 고학수 외. 인공지능원론: 설명가능성을 중심으로. 박영사, 2021. . bibitem{Gun2019} Gunning, David, et al. &quot;XAI—Explainable artificial intelligence.&quot; Science Robotics 4.37 (2019): eaay7120. . bibitem{Pet2018} Petsiuk, Vitali, Abir Das, and Kate Saenko. &quot;Rise: Randomized input sampling for explanation of black-box models.&quot; arXiv preprint arXiv:1806.07421 (2018). . bibitem{Zhou2016} Zhou, Bolei, et al. &quot;Learning deep features for discriminative localization.&quot; Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. . bibitem{Samek2016} Samek, Wojciech, et al. &quot;Evaluating the visualization of what a deep neural network has learned.&quot; IEEE transactions on neural networks and learning systems 28.11 (2016): 2660-2673. . bibitem{Yang2004} Yang, Jian, et al. &quot;Two-dimensional PCA: a new approach to appearance-based face representation and recognition.&quot; IEEE transactions on pattern analysis and machine intelligence 26.1 (2004): 131-137. . bibitem{Rodriguez2010} Rodriguez-Aragon, Licesio J., and Anatoly Zhigljavsky. &quot;Singular spectrum analysis for image processing.&quot; Statistics and Its Interface 3.3 (2010): 419-426. .",
            "url": "https://kimha02.github.io/ham/study/2022/03/03/writing.html",
            "relUrl": "/study/2022/03/03/writing.html",
            "date": " • Mar 3, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "(논문) CAT/DOG_ver.3",
            "content": ". 💀 writing에 정리를 한 번에 해보려고 했으나.. 결과가 너무 좋지 않아서 만든 실험용 노트 . import . import torch from fastai.vision.all import * import cv2 . . data . path=untar_data(URLs.PETS)/&#39;images&#39; . path . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images&#39;) . files=get_image_files(path) . def label_func(f): if f[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) . . learn . lrnr=cnn_learner(dls,resnet34,metrics=error_rate) lrnr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.171144 | 0.016997 | 0.007442 | 00:33 | . epoch train_loss valid_loss error_rate time . 0 | 0.034690 | 0.017238 | 0.004060 | 00:40 | . . sample . 1st CNN and CAM . get_image_files(path)[113] . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Maine_Coon_61.jpg&#39;) . img = PILImage.create(get_image_files(path)[113]) img . x, = first(dls.test_dl([img])) #이미지 텐서화 . print(torch.min(dls.train.decode((x,))[0].squeeze())) print(torch.max(dls.train.decode((x,))[0].squeeze())) print(torch.min(x)) print(torch.max(x)) . TensorImage(0) TensorImage(251) TensorImage(-2.1179, device=&#39;cuda:0&#39;) TensorImage(2.1804, device=&#39;cuda:0&#39;) . x.shape . torch.Size([1, 3, 512, 512]) . net1=lrnr.model[0] net2=lrnr.model[1] . net2 = torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(), torch.nn.Linear(512,out_features=2,bias=False)) . net=torch.nn.Sequential(net1,net2) . lrnr2=Learner(dls,net,metrics=accuracy) . epoch수를 줄여본 결과 보다 결과가 개선된 모습 | . lrnr2.fine_tune(5) . epoch train_loss valid_loss accuracy time . 0 | 0.246964 | 1.751951 | 0.816644 | 00:40 | . epoch train_loss valid_loss accuracy time . 0 | 0.133740 | 0.179796 | 0.925575 | 00:40 | . 1 | 0.125002 | 0.145740 | 0.952639 | 00:40 | . 2 | 0.107054 | 0.585305 | 0.852503 | 00:40 | . 3 | 0.060203 | 0.052729 | 0.978349 | 00:40 | . 4 | 0.030338 | 0.048580 | 0.981055 | 00:40 | . dls.vocab . [&#39;cat&#39;, &#39;dog&#39;] . (고양이,강아지)라고 생각한 확률 | . a=net(x).tolist()[0][0] b=net(x).tolist()[0][1] np.exp(a)/(np.exp(a)+np.exp(b)), np.exp(b)/(np.exp(a)+np.exp(b)) . (0.9999999998182874, 1.8171263787640942e-10) . np.exp(a) . 41041.7438618806 . np.exp(b) . 7.457803541545435e-06 . net(x.to(&quot;cpu&quot;)).tolist()[0][0] . 10.622979164123535 . torch.mean(camimg[0]) . tensor(10.6228, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) . torch.sum(camimg[0])/(16*16) . tensor(10.6228, device=&#39;cuda:0&#39;, grad_fn=&lt;DivBackward0&gt;) . net(x.to(&quot;cpu&quot;)).tolist()[0][1] . -11.806629180908203 . CAM | . camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) . print(torch.min(camimg[1])) print(torch.max(camimg[1])) print(torch.mean(camimg[1])) print(torch.min(camimg[0])) print(torch.max(camimg[0])) print(torch.mean(camimg[0])) . tensor(-192.8017, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;) tensor(4.0623, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;) tensor(-11.8065, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) tensor(-4.1391, device=&#39;cuda:0&#39;, grad_fn=&lt;MinBackward1&gt;) tensor(168.8966, device=&#39;cuda:0&#39;, grad_fn=&lt;MaxBackward1&gt;) tensor(10.6228, device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward0&gt;) . fig, (ax1,ax2,ax3) = plt.subplots(1,3) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;Input image&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;CAT PART&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax3.set_title(&quot;DOG PART&quot;) # fig.set_figwidth(12) fig.set_figheight(12) fig.tight_layout() . &#9733; &#54032;&#45800; &#44540;&#44144;&#44032; &#44053;&#54624;&#49688;&#47197; &#54028;&#46976;&#49353; $ to$ &#48372;&#46972;&#49353; &#48320;&#54632; . . 2nd CNN and CAM . MODE 1 만들기 . 가중치 재설정 | . | . test=camimg[0]-torch.min(camimg[0]) . camimg[0].shape . torch.Size([16, 16]) . T=camimg[0] . A1=torch.exp(-0.015*test) . A1.shape . torch.Size([16, 16]) . T1=torch.exp(-0.015*T) . A2=1-A1 . T2=1-T1 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHTT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(T2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(T1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y1) . TX1=np.array(T1.to(&quot;cpu&quot;).detach(),dtype=np.float32) TY1=torch.Tensor(cv2.resize(TX1,(512,512),interpolation=cv2.INTER_LINEAR)) Tx1=x.squeeze().to(&#39;cpu&#39;)*TY1-torch.min(x.squeeze().to(&#39;cpu&#39;)*TY1) . X12=np.array(A2.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR)) x12=x.squeeze().to(&#39;cpu&#39;)*Y12#-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y12) . TX12=np.array(T2.to(&quot;cpu&quot;).detach(),dtype=np.float32) TY12=torch.Tensor(cv2.resize(TX12,(512,512),interpolation=cv2.INTER_LINEAR)) Tx12=x.squeeze().to(&#39;cpu&#39;)*TY12#-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y12) . xx=x12+x1 . 여기서 mode res 만 minimum을 빼준 이유는 시각화할 때 까맣게 보이게 하기 위함!! | . 1st CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x12*0.2).squeeze().show(ax=ax1) #MODE1 (x1*0.35).squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig,(ax1)=plt.subplots(1,1) (xx*0.1).squeeze().show(ax=ax1) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . &lt;AxesSubplot:&gt; . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (Tx12*0.4).squeeze().show(ax=ax1) #MODE1 (Tx1*0.3).squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . $ to$ test나 T나 별 차이가 없다.. . x1=x1.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) . CAM . mode1_res에 CAM 결과 올리기 | . | . fig, (ax1,ax2) = plt.subplots(1,2) # (x1*0.3).squeeze().show(ax=ax1) ax1.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;CAT PART&quot;) # (x1*0.3).squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DOG PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째 CAM결과와 비교 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (0.9658316715967996, 0.03416832840320044) . . 3rd CNN and CAM . MODE 2 만들기 | . test1=camimg1[0]-torch.min(camimg1[0]) . A3=torch.exp(-0.06*test1) . A4=1-A3 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A3.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE2 RES WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A4.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE2 WEIGHT&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X2=np.array(A3.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR)) x2=(x1*0.35)*Y2-torch.min((x1*0.35)*Y2) . X22=np.array(A4.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR)) x22=(x1*0.35)*Y22#-torch.min((x1*0.35)*Y22) . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x12*0.15).squeeze().show(ax=ax1) #MODE1 (x1*0.3).squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x22).squeeze().show(ax=ax1) #MODE2 (x2).squeeze().show(ax=ax2) #MODE2_res ax1.set_title(&quot;MODE2&quot;) ax2.set_title(&quot;MODE2 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x2=x2.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg2 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x2).squeeze()) . CAM . mode2_res에 CAM 결과 올리기 | . | . fig, (ax1, ax2) = plt.subplots(1,2) # x2.squeeze().show(ax=ax1) ax1.imshow(camimg2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;CAT PART&quot;) # x2.squeeze().show(ax=ax2) ax2.imshow(camimg2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DOG PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째, 두번째 CAM결과와 비교 . fig, (ax1,ax2,ax3) = plt.subplots(1,3) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax3.set_title(&quot;3RD CAM&quot;) fig.set_figwidth(12) fig.set_figheight(12) fig.tight_layout() . a2=net(x2).tolist()[0][0] b2=net(x2).tolist()[0][1] np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2)) . (0.905214199073939, 0.09478580092606113) . . 4th CNN and CAM . MODE 3 만들기 | . test2=camimg2[0]-torch.min(camimg2[0]) . A5=torch.exp(-0.3*test2) . A6=1-A5 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A5.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE3 RES WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A6.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE3 WEIGHT&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X3=np.array(A5.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR)) x3=x2*Y3-torch.min(x2*Y3) . X32=np.array(A6.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR)) x32=x2*Y32#-torch.min(x2*Y32) . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x12*0.3).squeeze().show(ax=ax1) #MODE1 (x1*0.3).squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x22*0.5).squeeze().show(ax=ax1) #MODE2 x2.squeeze().show(ax=ax2) #MODE2_res ax1.set_title(&quot;MODE2&quot;) ax2.set_title(&quot;MODE2 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x32*0.3).squeeze().show(ax=ax1) #MODE3 (x3).squeeze().show(ax=ax2) #MODE3_res ax1.set_title(&quot;MODE3&quot;) ax2.set_title(&quot;MODE3 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # plt.savefig(&#39;mode_cat&#39;) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x3=x3.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg3 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x3).squeeze()) . CAM . mode3_res에 CAM 결과 올리기 | . | . fig, (ax1, ax2) = plt.subplots(1,2) # x3.squeeze().show(ax=ax1) ax1.imshow(camimg3[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;CAT PART&quot;) # x3.squeeze().show(ax=ax2) ax2.imshow(camimg3[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DOG PART&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째, 두번째, 세번째 CAM결과와 비교 . fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax3.set_title(&quot;3RD CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax4) ax4.imshow(camimg3[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax4.set_title(&quot;4TH CAM&quot;) # fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . a3=net(x3).tolist()[0][0] b3=net(x3).tolist()[0][1] np.exp(a3)/(np.exp(a3)+np.exp(b3)), np.exp(b3)/(np.exp(a3)+np.exp(b3)) . (0.9226089398162587, 0.07739106018374121) . . 25&#48264; epoch &#44208;&#44284; . - 첫번째, 두번째, 세번째 CAM결과와 비교 . fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax3.set_title(&quot;3RD CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax4) ax4.imshow(camimg3[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax4.set_title(&quot;4TH CAM&quot;) # fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . a3=net(x3).tolist()[0][0] b3=net(x3).tolist()[0][1] np.exp(a3)/(np.exp(a3)+np.exp(b3)), np.exp(b3)/(np.exp(a3)+np.exp(b3)) . (0.918799098688349, 0.0812009013116511) . 고양이는 오히려 마지막에 전체로 퍼져버리는 모습이 보임. | .",
            "url": "https://kimha02.github.io/ham/study/2022/02/13/cat-dog-3.html",
            "relUrl": "/study/2022/02/13/cat-dog-3.html",
            "date": " • Feb 13, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "(논문) Chest X-ray",
            "content": ". import . import torch from fastai.vision.all import * import cv2 . import fastbook from fastbook import * . from fastai.vision.widgets import * . data . refer : https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia . path=Path(&#39;/home/khy/chest_xray/chest_xray&#39;) . path.ls() . (#5) [Path(&#39;/home/khy/chest_xray/chest_xray/train&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/test&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/chest_xray&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/__MACOSX&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/val&#39;)] . files=get_image_files(path) . files . (#11712) [Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0766-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/NORMAL2-IM-1318-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0160-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/NORMAL2-IM-1327-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0489-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0509-0001-0002.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0761-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0416-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/NORMAL2-IM-0566-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0411-0001.jpeg&#39;)...] . dls = ImageDataLoaders.from_folder(path, train=&#39;train&#39;, valid_pct=0.2, item_tfms=Resize(224)) . dls.vocab . [&#39;NORMAL&#39;, &#39;PNEUMONIA&#39;] . dls.show_batch(max_n=16) . learn=cnn_learner(dls,resnet34,metrics=error_rate) . net1=learn.model[0] net2=learn.model[1] . net2 = torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(), torch.nn.Linear(512,out_features=2,bias=False)) . net=torch.nn.Sequential(net1,net2) . lrnr2=Learner(dls,net,metrics=accuracy) . lrnr2.fine_tune(200) . epoch train_loss valid_loss accuracy time . 0 | 0.166842 | 0.091861 | 0.967122 | 00:39 | . epoch train_loss valid_loss accuracy time . 0 | 0.076691 | 0.070642 | 0.973954 | 00:38 | . 1 | 0.065596 | 0.065189 | 0.976943 | 00:38 | . 2 | 0.063810 | 0.060881 | 0.977797 | 00:38 | . 3 | 0.058133 | 0.055606 | 0.979505 | 00:38 | . 4 | 0.047295 | 0.051751 | 0.982494 | 00:38 | . 5 | 0.049507 | 0.061955 | 0.975235 | 00:38 | . 6 | 0.040383 | 0.048890 | 0.982494 | 00:38 | . 7 | 0.037072 | 0.038793 | 0.985483 | 00:38 | . 8 | 0.029895 | 0.035411 | 0.988044 | 00:38 | . 9 | 0.024122 | 0.032279 | 0.988471 | 00:38 | . 10 | 0.022319 | 0.030799 | 0.990606 | 00:38 | . 11 | 0.022883 | 0.029063 | 0.990606 | 00:38 | . 12 | 0.018799 | 0.024217 | 0.993595 | 00:38 | . 13 | 0.018655 | 0.026862 | 0.991887 | 00:38 | . 14 | 0.017203 | 0.025556 | 0.991460 | 00:38 | . 15 | 0.012168 | 0.028741 | 0.991887 | 00:38 | . 16 | 0.013291 | 0.021540 | 0.991460 | 00:38 | . 17 | 0.013113 | 0.023177 | 0.993595 | 00:38 | . 18 | 0.014589 | 0.023715 | 0.993168 | 00:38 | . 19 | 0.010889 | 0.027784 | 0.992314 | 00:38 | . 20 | 0.010598 | 0.028819 | 0.992314 | 00:38 | . 21 | 0.013652 | 0.023543 | 0.993168 | 00:38 | . 22 | 0.010165 | 0.021542 | 0.993168 | 00:38 | . 23 | 0.011329 | 0.024496 | 0.992314 | 00:38 | . 24 | 0.009473 | 0.019847 | 0.992314 | 00:38 | . 25 | 0.007470 | 0.022198 | 0.990179 | 00:38 | . 26 | 0.007615 | 0.017968 | 0.995303 | 00:38 | . 27 | 0.006131 | 0.022273 | 0.995730 | 00:38 | . 28 | 0.008292 | 0.032437 | 0.992314 | 00:38 | . 29 | 0.008912 | 0.042545 | 0.988898 | 00:38 | . 30 | 0.009870 | 0.039163 | 0.988044 | 00:38 | . 31 | 0.010967 | 0.018784 | 0.992314 | 00:38 | . 32 | 0.006510 | 0.021688 | 0.991887 | 00:38 | . 33 | 0.006636 | 0.033374 | 0.991460 | 00:38 | . 34 | 0.010336 | 0.020198 | 0.993595 | 00:38 | . 35 | 0.009317 | 0.030448 | 0.991033 | 00:38 | . 36 | 0.007046 | 0.022307 | 0.993168 | 00:38 | . 37 | 0.009590 | 0.026956 | 0.990606 | 00:38 | . 38 | 0.006269 | 0.055886 | 0.985056 | 00:38 | . 39 | 0.010013 | 0.018850 | 0.994449 | 00:38 | . 40 | 0.008058 | 0.027818 | 0.993168 | 00:38 | . 41 | 0.007327 | 0.015476 | 0.993595 | 00:38 | . 42 | 0.006886 | 0.010855 | 0.997011 | 00:38 | . 43 | 0.011692 | 0.017141 | 0.997011 | 00:38 | . 44 | 0.007462 | 0.030888 | 0.990179 | 00:38 | . 45 | 0.006464 | 0.015794 | 0.992741 | 00:38 | . 46 | 0.007760 | 0.068463 | 0.984628 | 00:38 | . 47 | 0.006637 | 0.015711 | 0.993168 | 00:38 | . 48 | 0.010105 | 0.041067 | 0.988898 | 00:38 | . 49 | 0.007672 | 0.012651 | 0.996157 | 00:38 | . 50 | 0.014199 | 0.083004 | 0.974381 | 00:38 | . 51 | 0.012289 | 0.018203 | 0.993168 | 00:38 | . 52 | 0.009026 | 0.020449 | 0.994022 | 00:38 | . 53 | 0.004553 | 0.017501 | 0.993595 | 00:38 | . 54 | 0.010326 | 0.024923 | 0.991033 | 00:38 | . 55 | 0.015319 | 0.027962 | 0.992314 | 00:38 | . 56 | 0.004357 | 0.023815 | 0.994022 | 00:38 | . 57 | 0.005287 | 0.019874 | 0.992314 | 00:38 | . 58 | 0.009573 | 0.014026 | 0.995730 | 00:38 | . 59 | 0.006735 | 0.021964 | 0.993168 | 00:38 | . 60 | 0.005811 | 0.023319 | 0.990606 | 00:38 | . 61 | 0.011406 | 0.026691 | 0.992741 | 00:38 | . 62 | 0.005277 | 0.022868 | 0.994449 | 00:38 | . 63 | 0.006119 | 0.018390 | 0.994022 | 00:38 | . 64 | 0.007875 | 0.034545 | 0.994022 | 00:38 | . 65 | 0.005800 | 0.020408 | 0.994022 | 00:38 | . 66 | 0.002680 | 0.019692 | 0.994449 | 00:38 | . 67 | 0.006419 | 0.034546 | 0.991033 | 00:38 | . 68 | 0.006348 | 0.053590 | 0.986763 | 00:38 | . 69 | 0.005590 | 0.031790 | 0.993595 | 00:38 | . 70 | 0.007865 | 0.029411 | 0.994876 | 00:38 | . 71 | 0.002760 | 0.026847 | 0.993168 | 00:38 | . 72 | 0.009839 | 0.030372 | 0.992741 | 00:38 | . 73 | 0.008680 | 0.026388 | 0.992314 | 00:38 | . 74 | 0.004330 | 0.031201 | 0.992741 | 00:38 | . 75 | 0.009632 | 0.078810 | 0.984202 | 00:38 | . 76 | 0.003771 | 0.022387 | 0.992741 | 00:38 | . 77 | 0.006113 | 0.030133 | 0.992314 | 00:38 | . 78 | 0.003496 | 0.028839 | 0.995303 | 00:38 | . 79 | 0.003018 | 0.026174 | 0.994022 | 00:38 | . 80 | 0.007461 | 0.030011 | 0.993595 | 00:38 | . 81 | 0.004392 | 0.023791 | 0.994876 | 00:38 | . 82 | 0.005972 | 0.068508 | 0.987617 | 00:38 | . 83 | 0.006191 | 0.019870 | 0.996584 | 00:38 | . 84 | 0.005330 | 0.020402 | 0.996584 | 00:38 | . 85 | 0.002982 | 0.036186 | 0.993168 | 00:38 | . 86 | 0.003956 | 0.019152 | 0.994022 | 00:38 | . 87 | 0.006709 | 0.022051 | 0.994449 | 00:38 | . 88 | 0.004887 | 0.043770 | 0.991460 | 00:38 | . 89 | 0.004027 | 0.025353 | 0.993168 | 00:38 | . 90 | 0.002959 | 0.029085 | 0.992741 | 00:38 | . 91 | 0.003077 | 0.025070 | 0.993595 | 00:38 | . 92 | 0.004699 | 0.024857 | 0.992741 | 00:38 | . 93 | 0.002660 | 0.032952 | 0.995730 | 00:38 | . 94 | 0.003100 | 0.025073 | 0.994876 | 00:38 | . 95 | 0.002563 | 0.023130 | 0.994022 | 00:38 | . 96 | 0.001407 | 0.023987 | 0.995730 | 00:38 | . 97 | 0.002879 | 0.015754 | 0.996584 | 00:38 | . 98 | 0.002273 | 0.019964 | 0.995730 | 00:38 | . 99 | 0.001539 | 0.023395 | 0.994022 | 00:38 | . 100 | 0.002776 | 0.019369 | 0.997438 | 00:38 | . 101 | 0.001925 | 0.015023 | 0.996157 | 00:38 | . 102 | 0.002006 | 0.039217 | 0.991887 | 00:38 | . 103 | 0.003615 | 0.011737 | 0.997011 | 00:38 | . 104 | 0.002477 | 0.016405 | 0.995730 | 00:38 | . 105 | 0.001914 | 0.014328 | 0.997438 | 00:38 | . 106 | 0.000848 | 0.020702 | 0.995730 | 00:38 | . 107 | 0.005377 | 0.028292 | 0.994022 | 00:38 | . 108 | 0.003150 | 0.019413 | 0.996584 | 00:38 | . 109 | 0.001558 | 0.022858 | 0.995730 | 00:38 | . 110 | 0.002981 | 0.022044 | 0.995730 | 00:38 | . 111 | 0.003152 | 0.024832 | 0.993595 | 00:38 | . 112 | 0.001988 | 0.016285 | 0.995730 | 00:38 | . 113 | 0.000533 | 0.014695 | 0.995730 | 00:38 | . 114 | 0.000902 | 0.017304 | 0.995730 | 00:39 | . 115 | 0.001843 | 0.019725 | 0.995730 | 00:38 | . 116 | 0.001038 | 0.020030 | 0.995730 | 00:38 | . 117 | 0.000729 | 0.019264 | 0.994022 | 00:38 | . 118 | 0.001277 | 0.027110 | 0.994876 | 00:38 | . 119 | 0.001734 | 0.026816 | 0.993168 | 00:38 | . 120 | 0.002050 | 0.020589 | 0.995730 | 00:38 | . 121 | 0.002221 | 0.022525 | 0.995730 | 00:38 | . 122 | 0.000572 | 0.027818 | 0.993168 | 00:38 | . 123 | 0.001051 | 0.018991 | 0.994876 | 00:38 | . 124 | 0.000295 | 0.019816 | 0.994876 | 00:38 | . 125 | 0.001252 | 0.022995 | 0.995730 | 00:38 | . 126 | 0.000770 | 0.021016 | 0.994449 | 00:38 | . 127 | 0.000683 | 0.030154 | 0.994449 | 00:38 | . 128 | 0.003303 | 0.026239 | 0.995730 | 00:38 | . 129 | 0.001704 | 0.025088 | 0.994022 | 00:38 | . 130 | 0.002516 | 0.010910 | 0.996584 | 00:38 | . 131 | 0.000699 | 0.015325 | 0.996584 | 00:38 | . 132 | 0.000870 | 0.013863 | 0.996584 | 00:38 | . 133 | 0.000663 | 0.020103 | 0.995730 | 00:38 | . 134 | 0.000980 | 0.012507 | 0.996584 | 00:38 | . 135 | 0.000181 | 0.014895 | 0.995730 | 00:38 | . 136 | 0.000645 | 0.030882 | 0.994022 | 00:38 | . 137 | 0.000258 | 0.029726 | 0.994022 | 00:38 | . 138 | 0.000154 | 0.019418 | 0.995730 | 00:38 | . 139 | 0.000699 | 0.019971 | 0.995730 | 00:38 | . 140 | 0.000355 | 0.024038 | 0.994876 | 00:38 | . 141 | 0.000170 | 0.030813 | 0.994876 | 00:38 | . 142 | 0.000657 | 0.027899 | 0.994876 | 00:38 | . 143 | 0.001425 | 0.024708 | 0.995730 | 00:38 | . 144 | 0.000381 | 0.020135 | 0.994022 | 00:38 | . 145 | 0.000152 | 0.025634 | 0.994876 | 00:38 | . 146 | 0.000075 | 0.018921 | 0.994876 | 00:38 | . 147 | 0.000226 | 0.017673 | 0.994876 | 00:38 | . 148 | 0.000224 | 0.023066 | 0.996584 | 00:38 | . 149 | 0.000632 | 0.018082 | 0.994876 | 00:38 | . 150 | 0.000625 | 0.016179 | 0.996584 | 00:38 | . 151 | 0.000080 | 0.021201 | 0.994876 | 00:38 | . 152 | 0.000068 | 0.021460 | 0.994022 | 00:38 | . 153 | 0.000112 | 0.018794 | 0.995730 | 00:38 | . 154 | 0.000080 | 0.021812 | 0.994876 | 00:38 | . 155 | 0.000040 | 0.018293 | 0.995730 | 00:38 | . 156 | 0.000171 | 0.018570 | 0.997438 | 00:38 | . 157 | 0.000175 | 0.015313 | 0.996584 | 00:38 | . 158 | 0.000464 | 0.016535 | 0.996584 | 00:38 | . 159 | 0.000109 | 0.019572 | 0.996584 | 00:38 | . 160 | 0.000062 | 0.021594 | 0.996584 | 00:38 | . 161 | 0.000064 | 0.014384 | 0.996584 | 00:38 | . 162 | 0.000014 | 0.020526 | 0.996584 | 00:38 | . 163 | 0.000028 | 0.019420 | 0.995730 | 00:38 | . 164 | 0.000042 | 0.030555 | 0.994876 | 00:38 | . 165 | 0.000080 | 0.022019 | 0.996584 | 00:38 | . 166 | 0.000079 | 0.030117 | 0.994876 | 00:38 | . 167 | 0.000038 | 0.019891 | 0.996584 | 00:38 | . 168 | 0.000027 | 0.024130 | 0.996584 | 00:38 | . 169 | 0.000017 | 0.027270 | 0.995730 | 00:38 | . 170 | 0.000032 | 0.018282 | 0.995730 | 00:38 | . 171 | 0.000062 | 0.019155 | 0.996584 | 00:38 | . 172 | 0.000059 | 0.023948 | 0.995730 | 00:38 | . 173 | 0.000011 | 0.025428 | 0.995730 | 00:38 | . 174 | 0.000011 | 0.019787 | 0.995730 | 00:38 | . 175 | 0.000018 | 0.025644 | 0.995730 | 00:38 | . 176 | 0.000185 | 0.021899 | 0.995730 | 00:38 | . 177 | 0.000056 | 0.021866 | 0.995730 | 00:38 | . 178 | 0.000061 | 0.022560 | 0.995730 | 00:38 | . 179 | 0.000019 | 0.019159 | 0.995730 | 00:38 | . 180 | 0.000009 | 0.024180 | 0.995730 | 00:38 | . 181 | 0.000030 | 0.022470 | 0.995730 | 00:38 | . 182 | 0.000007 | 0.020468 | 0.995730 | 00:38 | . 183 | 0.000049 | 0.024680 | 0.995730 | 00:38 | . 184 | 0.000009 | 0.019799 | 0.994876 | 00:38 | . 185 | 0.000026 | 0.025008 | 0.995730 | 00:38 | . 186 | 0.000028 | 0.029448 | 0.995730 | 00:38 | . 187 | 0.000161 | 0.032871 | 0.995730 | 00:38 | . 188 | 0.000334 | 0.028276 | 0.995730 | 00:38 | . 189 | 0.000033 | 0.023425 | 0.995730 | 00:38 | . 190 | 0.000012 | 0.027646 | 0.995730 | 00:38 | . 191 | 0.000012 | 0.026857 | 0.995730 | 00:38 | . 192 | 0.000120 | 0.025125 | 0.995730 | 00:38 | . 193 | 0.000014 | 0.029498 | 0.995730 | 00:38 | . 194 | 0.000010 | 0.028255 | 0.995730 | 00:38 | . 195 | 0.000098 | 0.027213 | 0.995730 | 00:38 | . 196 | 0.000031 | 0.024639 | 0.995730 | 00:38 | . 197 | 0.000021 | 0.028268 | 0.995730 | 00:38 | . 198 | 0.000005 | 0.021215 | 0.995730 | 00:38 | . 199 | 0.000010 | 0.027356 | 0.995730 | 00:38 | . CAM &#44208;&#44284; &#54869;&#51064;_&#50640;&#54253; 200 . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] normalprob, pneumoniaprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if normalprob&gt;pneumoniaprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;normal(%s)&quot; % normalprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;pneumonia(%s)&quot; % pneumoniaprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . fig, ax = plt.subplots(5,5) k=3000 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] normalprob, pneumoniaprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if normalprob&gt;pneumoniaprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;normal(%s)&quot; % normalprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;pneumonia(%s)&quot; % pneumoniaprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . . SAMPLE . get_image_files(path)[3023] . Path(&#39;/home/khy/chest_xray/chest_xray/train/PNEUMONIA/person301_bacteria_1429.jpeg&#39;) . img = PILImage.create(get_image_files(path)[3021]) img . x, = first(dls.test_dl([img])) #이미지 텐서화 . x.shape . torch.Size([1, 3, 224, 224]) . &#9733; &#54032;&#45800; &#44540;&#44144;&#44032; &#44053;&#54624;&#49688;&#47197; &#54028;&#46976;&#49353; $ to$ &#48372;&#46972;&#49353; &#48320;&#54632; . a=net(x.to(&#39;cpu&#39;)).tolist()[0][0] b=net(x.to(&#39;cpu&#39;)).tolist()[0][1] np.exp(a)/(np.exp(a)+np.exp(b)), np.exp(b)/(np.exp(a)+np.exp(b)) . (1.0052419841905753e-22, 1.0) . camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x.to(&#39;cpu&#39;)).squeeze()) . fig, (ax1,ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . test=camimg[1]-torch.min(camimg[1]) . A1=torch.exp(-0.03*test) . A2=1-A1 . fig, (ax1, ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . $ theta$ 가 작아질수록 범위가 좁아지는? 경향 | . X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(224,224),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y1) . X12=np.array(A2.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y12=torch.Tensor(cv2.resize(X12,(224,224),interpolation=cv2.INTER_LINEAR)) x12=x.squeeze().to(&#39;cpu&#39;)*Y12#-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y12) . 1st CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x12*0.5).squeeze().show(ax=ax1) #MODE1 (x1*0.5).squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x1=x1.reshape(1,3,224,224) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) . CAM . mode1_res에 CAM 결과 올리기 | . | . fig, (ax1,ax2) = plt.subplots(1,2) # (x1*0.5).squeeze().show(ax=ax1) ax1.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # (x1*0.5).squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . x1.shape . torch.Size([1, 3, 224, 224]) . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (2.1400014909658421e-16, 0.9999999999999998) . ver2 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) . CAM | . fig, (ax1,ax2) = plt.subplots(1,2) # x1.squeeze().show(ax=ax1) ax1.imshow(ver2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # x1.squeeze().show(ax=ax2) ax2.imshow(ver2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(ver2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (2.1400014909658421e-16, 0.9999999999999998) . test1=ver2[1]-torch.min(ver2[1]) . A3=torch.exp(-0.04*test1) . A4=1-A3 . fig, (ax1, ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A3.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE2 WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A4.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE2 RES WEIGHT&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X3=np.array(A3.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y3=torch.Tensor(cv2.resize(X3,(224,224),interpolation=cv2.INTER_LINEAR)) x3=x.squeeze().to(&#39;cpu&#39;)*Y1*Y3 . X4=np.array(A4.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y4=torch.Tensor(cv2.resize(X4,(224,224),interpolation=cv2.INTER_LINEAR)) x4=x.squeeze().to(&#39;cpu&#39;)*Y1*Y4 . 2nd CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x12.squeeze().show(ax=ax1) x1.squeeze().show(ax=ax2) ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x4.squeeze().show(ax=ax1) x3.squeeze().show(ax=ax2) ax1.set_title(&quot;MODE2&quot;) ax2.set_title(&quot;MODE2 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x3=x3.reshape(1,3,224,224) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . ver3 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x3).squeeze()) . CAM | . fig, (ax1,ax2) = plt.subplots(1,2) # x3.squeeze().show(ax=ax1) ax1.imshow(ver3[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # x3.squeeze().show(ax=ax2) ax2.imshow(ver3[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . a2=net(x3).tolist()[0][0] b2=net(x3).tolist()[0][1] np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2)) . (5.538589438030889e-20, 1.0) . . $ theta=0.055$ . ✏️ CAM에서 발견한 특징의 가중치를 낮추는 mode weigth와 CAM에서 발견한 특징을 제외한 부분의 가중치를 살리는 mode res weight를 생성해 mode$n$($n$=number of acting CAM)과 mode$n$ res를 생성한다. 이 때 k라는 hyper parameter값을 곱해줘서 그 정도를 조정하는데, . k의 값이 클수록, CAM img의 가중치에 큰 값이 곱해져 이미지가 어떤 클래스로 분류되는데 기여한 부분의 범위가 넓어지며(=mode weight에서 분홍색으로 표시되는 부위가 실제 CAM img보다 넓어짐), residual에서는 더욱 어둡게 나타난다. | k의 값이 작을수록, CAM img의 가중치에 큰 값이 곱해져 이미지가 어떤 클래스로 분류되는데 기여한 부분의 범위가 CAM img에서 나타난 것과 유사하나, residual에서 완벽하게 지워지지가 않아서 다음 차수에서 동일한 부분이 탐색될 가능성이 높다. | . 위와 같은 이유로 적당한 k를 시뮬레이션을 통해 임의로 설정하였다. . k=0.04로 진행해본 결과, 이전 언급한 것과 같이 1차에서 발견된 특징이 잘 지워지지 않았다. 따라서 2번째 CAM에서 발견된 특징이 1번째 CAM에서 발견된 특징과 유사하다. | k=0.055로 진행해본 결과, 1차에서 발견된 특징이 residual img에서 잘 지워졌으나(검정색에 가깝게 나타났으나, 픽셀의 값이 0에 가깝게 나타났으나) 폐 내부?의 시각적인 특징들도 함께 사라져 2번째 CAM에서 엉뚱한 결과를 초래했다. | . test=camimg[0]-torch.min(camimg[0]) . A1=torch.exp(-0.055*test) . A2=1-A1 . fig, (ax1, ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(224,224),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 . X12=np.array(A2.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y12=torch.Tensor(cv2.resize(X12,(224,224),interpolation=cv2.INTER_LINEAR)) x12=x.squeeze().to(&#39;cpu&#39;)*Y12 . 1st CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x12*0.5).squeeze().show(ax=ax1) #MODE1 (x1*0.5).squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x1=x1.reshape(1,3,224,224) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) . CAM . mode1_res에 CAM 결과 올리기 | . | . fig, (ax1,ax2) = plt.subplots(1,2) # x1.squeeze().show(ax=ax1) ax1.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # x1.squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (5.681020375519873e-23, 1.0) . . 전체 그림에 적용하기 (n=11712) | . fig, ax = plt.subplots(5,5) k=3000 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] normalprob, pneumoniaprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if normalprob&gt;pneumoniaprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;normal(%s)&quot; % normalprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;pneumonia(%s)&quot; % pneumoniaprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . RuntimeError Traceback (most recent call last) /tmp/ipykernel_134908/2124607019.py in &lt;module&gt; 4 for j in range(5): 5 x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) -&gt; 6 camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) 7 a,b = net(x).tolist()[0] 8 normalprob, pneumoniaprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs) 1049 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks 1050 or _global_forward_hooks or _global_forward_pre_hooks): -&gt; 1051 return forward_call(*input, **kwargs) 1052 # Do not call functions when jit is used 1053 full_backward_hooks, non_full_backward_hooks = [], [] ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/container.py in forward(self, input) 137 def forward(self, input): 138 for module in self: --&gt; 139 input = module(input) 140 return input 141 ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs) 1049 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks 1050 or _global_forward_hooks or _global_forward_pre_hooks): -&gt; 1051 return forward_call(*input, **kwargs) 1052 # Do not call functions when jit is used 1053 full_backward_hooks, non_full_backward_hooks = [], [] ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/conv.py in forward(self, input) 441 442 def forward(self, input: Tensor) -&gt; Tensor: --&gt; 443 return self._conv_forward(input, self.weight, self.bias) 444 445 class Conv3d(_ConvNd): ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/conv.py in _conv_forward(self, input, weight, bias) 437 weight, bias, self.stride, 438 _pair(0), self.dilation, self.groups) --&gt; 439 return F.conv2d(input, weight, bias, self.stride, 440 self.padding, self.dilation, self.groups) 441 ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs) 338 convert=False 339 if _torch_handled(args, self._opt, func): convert,types = type(self),(torch.Tensor,) --&gt; 340 res = super().__torch_function__(func, types, args=args, kwargs=kwargs) 341 if convert: res = convert(res) 342 if isinstance(res, TensorBase): res.set_meta(self, as_copy=True) ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/_tensor.py in __torch_function__(cls, func, types, args, kwargs) 1021 1022 with _C.DisableTorchFunction(): -&gt; 1023 ret = func(*args, **kwargs) 1024 return _convert(ret, cls) 1025 RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same . import pandas as pd . col=pd.DataFrame() . k=0 col=[] for k in range(5) : col[k]=print(k) k=k+1 . . refer : https://www.analyticsvidhya.com/blog/2020/10/develop-and-deploy-an-image-classifier-app-using-fastai/ . interp = ClassificationInterpretation.from_learner(lrnr2) interp.plot_confusion_matrix() . #cleaner #잘못 예측한 이미지 제거_제거될 이미지를 보여주는 것 같음 .",
            "url": "https://kimha02.github.io/ham/study/2022/02/07/chestxray.html",
            "relUrl": "/study/2022/02/07/chestxray.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "(공부) Chest X-ray",
            "content": ". import . import torch from fastai.vision.all import * import cv2 as cv . import fastbook from fastbook import * . from fastai.vision.widgets import * . data . refer : https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia . path=Path(&#39;/home/khy/chest_xray/chest_xray&#39;) . path.ls() . (#5) [Path(&#39;/home/khy/chest_xray/chest_xray/train&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/test&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/chest_xray&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/__MACOSX&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/val&#39;)] . files=get_image_files(path) . files . (#11712) [Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0766-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/NORMAL2-IM-1318-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0160-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/NORMAL2-IM-1327-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0489-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0509-0001-0002.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0761-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0416-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/NORMAL2-IM-0566-0001.jpeg&#39;),Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0411-0001.jpeg&#39;)...] . dls = ImageDataLoaders.from_folder(path, train=&#39;train&#39;, valid_pct=0.2, item_tfms=Resize(224)) . dls.vocab . [&#39;NORMAL&#39;, &#39;PNEUMONIA&#39;] . dls.show_batch(max_n=16) . learn=cnn_learner(dls,resnet34,metrics=error_rate) . net1=learn.model[0] net2=learn.model[1] . net2 = torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(), torch.nn.Linear(512,out_features=2,bias=False)) . net=torch.nn.Sequential(net1,net2) . lrnr2=Learner(dls,net,metrics=accuracy) . lrnr2.fine_tune(200) . epoch train_loss valid_loss accuracy time . 0 | 0.166842 | 0.091861 | 0.967122 | 00:33 | . epoch train_loss valid_loss accuracy time . 0 | 0.076691 | 0.070642 | 0.973954 | 00:33 | . 1 | 0.065596 | 0.065189 | 0.976943 | 00:33 | . 2 | 0.063810 | 0.060881 | 0.977797 | 00:33 | . 3 | 0.058133 | 0.055606 | 0.979505 | 00:33 | . 4 | 0.047295 | 0.051751 | 0.982494 | 00:33 | . 5 | 0.049507 | 0.061955 | 0.975235 | 00:33 | . 6 | 0.040383 | 0.048890 | 0.982494 | 00:33 | . 7 | 0.037072 | 0.038793 | 0.985483 | 00:33 | . 8 | 0.029895 | 0.035411 | 0.988044 | 00:33 | . 9 | 0.024122 | 0.032279 | 0.988471 | 00:33 | . 10 | 0.022319 | 0.030799 | 0.990606 | 00:33 | . 11 | 0.022883 | 0.029063 | 0.990606 | 00:33 | . 12 | 0.018799 | 0.024217 | 0.993595 | 00:33 | . 13 | 0.018655 | 0.026862 | 0.991887 | 00:33 | . 14 | 0.017203 | 0.025556 | 0.991460 | 00:33 | . 15 | 0.012168 | 0.028741 | 0.991887 | 00:33 | . 16 | 0.013291 | 0.021540 | 0.991460 | 00:33 | . 17 | 0.013113 | 0.023177 | 0.993595 | 00:33 | . 18 | 0.014589 | 0.023715 | 0.993168 | 00:33 | . 19 | 0.010889 | 0.027784 | 0.992314 | 00:33 | . 20 | 0.010598 | 0.028819 | 0.992314 | 00:33 | . 21 | 0.013652 | 0.023543 | 0.993168 | 00:33 | . 22 | 0.010165 | 0.021542 | 0.993168 | 00:33 | . 23 | 0.011329 | 0.024496 | 0.992314 | 00:33 | . 24 | 0.009473 | 0.019847 | 0.992314 | 00:33 | . 25 | 0.007470 | 0.022198 | 0.990179 | 00:33 | . 26 | 0.007615 | 0.017968 | 0.995303 | 00:33 | . 27 | 0.006131 | 0.022273 | 0.995730 | 00:33 | . 28 | 0.008292 | 0.032437 | 0.992314 | 00:33 | . 29 | 0.008912 | 0.042545 | 0.988898 | 00:33 | . 30 | 0.009870 | 0.039163 | 0.988044 | 00:33 | . 31 | 0.010967 | 0.018784 | 0.992314 | 00:33 | . 32 | 0.006510 | 0.021688 | 0.991887 | 00:33 | . 33 | 0.006636 | 0.033374 | 0.991460 | 00:33 | . 34 | 0.010336 | 0.020198 | 0.993595 | 00:33 | . 35 | 0.009317 | 0.030448 | 0.991033 | 00:33 | . 36 | 0.007046 | 0.022307 | 0.993168 | 00:33 | . 37 | 0.009590 | 0.026956 | 0.990606 | 00:33 | . 38 | 0.006269 | 0.055886 | 0.985056 | 00:33 | . 39 | 0.010013 | 0.018850 | 0.994449 | 00:33 | . 40 | 0.008058 | 0.027818 | 0.993168 | 00:33 | . 41 | 0.007327 | 0.015476 | 0.993595 | 00:33 | . 42 | 0.006886 | 0.010855 | 0.997011 | 00:33 | . 43 | 0.011692 | 0.017141 | 0.997011 | 00:33 | . 44 | 0.007462 | 0.030888 | 0.990179 | 00:33 | . 45 | 0.006464 | 0.015794 | 0.992741 | 00:33 | . 46 | 0.007760 | 0.068463 | 0.984628 | 00:33 | . 47 | 0.006637 | 0.015711 | 0.993168 | 00:33 | . 48 | 0.010105 | 0.041067 | 0.988898 | 00:33 | . 49 | 0.007672 | 0.012651 | 0.996157 | 00:33 | . 50 | 0.014199 | 0.083004 | 0.974381 | 00:33 | . 51 | 0.012289 | 0.018203 | 0.993168 | 00:33 | . 52 | 0.009026 | 0.020449 | 0.994022 | 00:33 | . 53 | 0.004553 | 0.017501 | 0.993595 | 00:33 | . 54 | 0.010326 | 0.024923 | 0.991033 | 00:33 | . 55 | 0.015319 | 0.027962 | 0.992314 | 00:33 | . 56 | 0.004357 | 0.023815 | 0.994022 | 00:33 | . 57 | 0.005287 | 0.019874 | 0.992314 | 00:33 | . 58 | 0.009573 | 0.014026 | 0.995730 | 00:33 | . 59 | 0.006735 | 0.021964 | 0.993168 | 00:33 | . 60 | 0.005811 | 0.023319 | 0.990606 | 00:33 | . 61 | 0.011406 | 0.026691 | 0.992741 | 00:33 | . 62 | 0.005277 | 0.022868 | 0.994449 | 00:33 | . 63 | 0.006119 | 0.018390 | 0.994022 | 00:33 | . 64 | 0.007875 | 0.034545 | 0.994022 | 00:33 | . 65 | 0.005800 | 0.020408 | 0.994022 | 00:33 | . 66 | 0.002680 | 0.019692 | 0.994449 | 00:33 | . 67 | 0.006419 | 0.034546 | 0.991033 | 00:33 | . 68 | 0.006348 | 0.053590 | 0.986763 | 00:33 | . 69 | 0.005590 | 0.031790 | 0.993595 | 00:33 | . 70 | 0.007865 | 0.029411 | 0.994876 | 00:33 | . 71 | 0.002760 | 0.026847 | 0.993168 | 00:33 | . 72 | 0.009839 | 0.030372 | 0.992741 | 00:33 | . 73 | 0.008680 | 0.026388 | 0.992314 | 00:33 | . 74 | 0.004330 | 0.031201 | 0.992741 | 00:33 | . 75 | 0.009632 | 0.078810 | 0.984202 | 00:33 | . 76 | 0.003771 | 0.022387 | 0.992741 | 00:33 | . 77 | 0.006113 | 0.030133 | 0.992314 | 00:33 | . 78 | 0.003496 | 0.028839 | 0.995303 | 00:33 | . 79 | 0.003018 | 0.026174 | 0.994022 | 00:33 | . 80 | 0.007461 | 0.030011 | 0.993595 | 00:33 | . 81 | 0.004392 | 0.023791 | 0.994876 | 00:33 | . 82 | 0.005972 | 0.068508 | 0.987617 | 00:33 | . 83 | 0.006191 | 0.019870 | 0.996584 | 00:33 | . 84 | 0.005330 | 0.020402 | 0.996584 | 00:33 | . 85 | 0.002982 | 0.036186 | 0.993168 | 00:33 | . 86 | 0.003956 | 0.019152 | 0.994022 | 00:33 | . 87 | 0.006709 | 0.022051 | 0.994449 | 00:33 | . 88 | 0.004887 | 0.043770 | 0.991460 | 00:33 | . 89 | 0.004027 | 0.025353 | 0.993168 | 00:33 | . 90 | 0.002959 | 0.029085 | 0.992741 | 00:33 | . 91 | 0.003077 | 0.025070 | 0.993595 | 00:33 | . 92 | 0.004699 | 0.024857 | 0.992741 | 00:33 | . 93 | 0.002660 | 0.032952 | 0.995730 | 00:33 | . 94 | 0.003100 | 0.025073 | 0.994876 | 00:33 | . 95 | 0.002563 | 0.023130 | 0.994022 | 00:33 | . 96 | 0.001407 | 0.023987 | 0.995730 | 00:33 | . 97 | 0.002879 | 0.015754 | 0.996584 | 00:33 | . 98 | 0.002273 | 0.019964 | 0.995730 | 00:33 | . 99 | 0.001539 | 0.023395 | 0.994022 | 00:33 | . 100 | 0.002776 | 0.019369 | 0.997438 | 00:33 | . 101 | 0.001925 | 0.015023 | 0.996157 | 00:33 | . 102 | 0.002006 | 0.039217 | 0.991887 | 00:33 | . 103 | 0.003615 | 0.011737 | 0.997011 | 00:33 | . 104 | 0.002477 | 0.016405 | 0.995730 | 00:33 | . 105 | 0.001914 | 0.014328 | 0.997438 | 00:33 | . 106 | 0.000848 | 0.020702 | 0.995730 | 00:33 | . 107 | 0.005377 | 0.028292 | 0.994022 | 00:33 | . 108 | 0.003150 | 0.019413 | 0.996584 | 00:33 | . 109 | 0.001558 | 0.022858 | 0.995730 | 00:33 | . 110 | 0.002981 | 0.022044 | 0.995730 | 00:33 | . 111 | 0.003152 | 0.024832 | 0.993595 | 00:33 | . 112 | 0.001988 | 0.016285 | 0.995730 | 00:33 | . 113 | 0.000533 | 0.014695 | 0.995730 | 00:33 | . 114 | 0.000902 | 0.017304 | 0.995730 | 00:33 | . 115 | 0.001843 | 0.019725 | 0.995730 | 00:33 | . 116 | 0.001038 | 0.020030 | 0.995730 | 00:33 | . 117 | 0.000729 | 0.019264 | 0.994022 | 00:33 | . 118 | 0.001277 | 0.027110 | 0.994876 | 00:33 | . 119 | 0.001734 | 0.026816 | 0.993168 | 00:33 | . 120 | 0.002050 | 0.020589 | 0.995730 | 00:33 | . 121 | 0.002221 | 0.022525 | 0.995730 | 00:33 | . 122 | 0.000572 | 0.027818 | 0.993168 | 00:33 | . 123 | 0.001051 | 0.018991 | 0.994876 | 00:33 | . 124 | 0.000295 | 0.019816 | 0.994876 | 00:33 | . 125 | 0.001252 | 0.022995 | 0.995730 | 00:33 | . 126 | 0.000770 | 0.021016 | 0.994449 | 00:33 | . 127 | 0.000683 | 0.030154 | 0.994449 | 00:33 | . 128 | 0.003303 | 0.026239 | 0.995730 | 00:33 | . 129 | 0.001704 | 0.025088 | 0.994022 | 00:33 | . 130 | 0.002516 | 0.010910 | 0.996584 | 00:33 | . 131 | 0.000699 | 0.015325 | 0.996584 | 00:33 | . 132 | 0.000870 | 0.013863 | 0.996584 | 00:33 | . 133 | 0.000663 | 0.020103 | 0.995730 | 00:33 | . 134 | 0.000980 | 0.012507 | 0.996584 | 00:33 | . 135 | 0.000181 | 0.014895 | 0.995730 | 00:33 | . 136 | 0.000645 | 0.030882 | 0.994022 | 00:33 | . 137 | 0.000258 | 0.029726 | 0.994022 | 00:33 | . 138 | 0.000154 | 0.019418 | 0.995730 | 00:33 | . 139 | 0.000699 | 0.019971 | 0.995730 | 00:33 | . 140 | 0.000355 | 0.024038 | 0.994876 | 00:33 | . 141 | 0.000170 | 0.030813 | 0.994876 | 00:33 | . 142 | 0.000657 | 0.027899 | 0.994876 | 00:33 | . 143 | 0.001425 | 0.024708 | 0.995730 | 00:33 | . 144 | 0.000381 | 0.020135 | 0.994022 | 00:34 | . 145 | 0.000152 | 0.025634 | 0.994876 | 00:33 | . 146 | 0.000075 | 0.018921 | 0.994876 | 00:33 | . 147 | 0.000226 | 0.017673 | 0.994876 | 00:33 | . 148 | 0.000224 | 0.023066 | 0.996584 | 00:33 | . 149 | 0.000632 | 0.018082 | 0.994876 | 00:33 | . 150 | 0.000625 | 0.016179 | 0.996584 | 00:33 | . 151 | 0.000080 | 0.021201 | 0.994876 | 00:33 | . 152 | 0.000068 | 0.021460 | 0.994022 | 00:33 | . 153 | 0.000112 | 0.018794 | 0.995730 | 00:33 | . 154 | 0.000080 | 0.021812 | 0.994876 | 00:33 | . 155 | 0.000040 | 0.018293 | 0.995730 | 00:33 | . 156 | 0.000171 | 0.018570 | 0.997438 | 00:33 | . 157 | 0.000175 | 0.015313 | 0.996584 | 00:33 | . 158 | 0.000464 | 0.016535 | 0.996584 | 00:33 | . 159 | 0.000109 | 0.019572 | 0.996584 | 00:33 | . 160 | 0.000062 | 0.021594 | 0.996584 | 00:33 | . 161 | 0.000064 | 0.014384 | 0.996584 | 00:33 | . 162 | 0.000014 | 0.020526 | 0.996584 | 00:33 | . 163 | 0.000028 | 0.019420 | 0.995730 | 00:33 | . 164 | 0.000042 | 0.030555 | 0.994876 | 00:33 | . 165 | 0.000080 | 0.022019 | 0.996584 | 00:33 | . 166 | 0.000079 | 0.030117 | 0.994876 | 00:33 | . 167 | 0.000038 | 0.019891 | 0.996584 | 00:33 | . 168 | 0.000027 | 0.024130 | 0.996584 | 00:33 | . 169 | 0.000017 | 0.027270 | 0.995730 | 00:33 | . 170 | 0.000032 | 0.018282 | 0.995730 | 00:33 | . 171 | 0.000062 | 0.019155 | 0.996584 | 00:33 | . 172 | 0.000059 | 0.023948 | 0.995730 | 00:33 | . 173 | 0.000011 | 0.025428 | 0.995730 | 00:33 | . 174 | 0.000011 | 0.019787 | 0.995730 | 00:33 | . 175 | 0.000018 | 0.025644 | 0.995730 | 00:33 | . 176 | 0.000185 | 0.021899 | 0.995730 | 00:33 | . 177 | 0.000056 | 0.021866 | 0.995730 | 00:33 | . 178 | 0.000061 | 0.022560 | 0.995730 | 00:33 | . 179 | 0.000019 | 0.019159 | 0.995730 | 00:33 | . 180 | 0.000009 | 0.024180 | 0.995730 | 00:33 | . 181 | 0.000030 | 0.022470 | 0.995730 | 00:33 | . 182 | 0.000007 | 0.020468 | 0.995730 | 00:33 | . 183 | 0.000049 | 0.024680 | 0.995730 | 00:33 | . 184 | 0.000009 | 0.019799 | 0.994876 | 00:33 | . 185 | 0.000026 | 0.025008 | 0.995730 | 00:33 | . 186 | 0.000028 | 0.029448 | 0.995730 | 00:33 | . 187 | 0.000161 | 0.032871 | 0.995730 | 00:33 | . 188 | 0.000334 | 0.028276 | 0.995730 | 00:33 | . 189 | 0.000033 | 0.023425 | 0.995730 | 00:33 | . 190 | 0.000012 | 0.027646 | 0.995730 | 00:33 | . 191 | 0.000012 | 0.026857 | 0.995730 | 00:33 | . 192 | 0.000120 | 0.025125 | 0.995730 | 00:33 | . 193 | 0.000014 | 0.029498 | 0.995730 | 00:33 | . 194 | 0.000010 | 0.028255 | 0.995730 | 00:33 | . 195 | 0.000098 | 0.027213 | 0.995730 | 00:33 | . 196 | 0.000031 | 0.024639 | 0.995730 | 00:33 | . 197 | 0.000021 | 0.028268 | 0.995730 | 00:33 | . 198 | 0.000005 | 0.021215 | 0.995730 | 00:33 | . 199 | 0.000010 | 0.027356 | 0.995730 | 00:33 | . CAM &#44208;&#44284; &#54869;&#51064;_&#50640;&#54253; 200 . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] normalprob, pneumoniaprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if normalprob&gt;pneumoniaprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;normal(%s)&quot; % normalprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;pneumonia(%s)&quot; % pneumoniaprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . fig, ax = plt.subplots(5,5) k=3000 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] normalprob, pneumoniaprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if normalprob&gt;pneumoniaprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;normal(%s)&quot; % normalprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;pneumonia(%s)&quot; % pneumoniaprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . . SAMPLE . get_image_files(path)[0] . Path(&#39;/home/khy/chest_xray/chest_xray/train/NORMAL/IM-0766-0001.jpeg&#39;) . img = PILImage.create(get_image_files(path)[0]) img . x, = first(dls.test_dl([img])) #이미지 텐서화 . x.shape . torch.Size([1, 3, 224, 224]) . &#9733; &#54032;&#45800; &#44540;&#44144;&#44032; &#44053;&#54624;&#49688;&#47197; &#54028;&#46976;&#49353; $ to$ &#48372;&#46972;&#49353; &#48320;&#54632; . a=net(x).tolist()[0][0] b=net(x).tolist()[0][1] np.exp(a)/(np.exp(a)+np.exp(b)), np.exp(b)/(np.exp(a)+np.exp(b)) . (0.9999999999931642, 6.835666941850839e-12) . camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) . fig, (ax1,ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . test=camimg[0]-torch.min(camimg[0]) . A1=torch.exp(-0.07*test) . A2=1-A1 . fig, (ax1, ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHT WITH THETA=0.07&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT WITH THETA=0.07&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . $ theta$ 가 작아질수록 범위가 좁아지는? 경향 | . X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(224,224),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 . X12=np.array(A2.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y12=torch.Tensor(cv2.resize(X12,(224,224),interpolation=cv2.INTER_LINEAR)) x12=x.squeeze().to(&#39;cpu&#39;)*Y12 . 1st CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x12.squeeze().show(ax=ax1) #MODE1 x1.squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x1=x1.reshape(1,3,224,224) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) . CAM . mode1_res에 CAM 결과 올리기 | . | . fig, (ax1,ax2) = plt.subplots(1,2) # x1.squeeze().show(ax=ax1) ax1.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # x1.squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (1.3657330880802881e-13, 0.9999999999998634) . 하나를 지우자 바로 판단 못함.. $ theta$를 변경하면 좀 달라질까? | . . $ theta=0.02$ &#51068; &#46412; SAMPLE . AA1=torch.exp(-0.02*test) . AA2=1-AA1 . fig, (ax1, ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHT WITH THETA=0.02&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT WITH THETA=0.02&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . XX1=np.array(AA1.to(&quot;cpu&quot;).detach(),dtype=np.float32) YY1=torch.Tensor(cv2.resize(XX1,(224,224),interpolation=cv2.INTER_LINEAR)) xx1=x.squeeze().to(&#39;cpu&#39;)*YY1 . XX12=np.array(AA2.to(&quot;cpu&quot;).detach(),dtype=np.float32) YY12=torch.Tensor(cv2.resize(XX12,(224,224),interpolation=cv2.INTER_LINEAR)) xx12=x.squeeze().to(&#39;cpu&#39;)*YY12 . 1st CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) xx12.squeeze().show(ax=ax1) #MODE1 xx1.squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . xx1=xx1.reshape(1,3,224,224) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . ver1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(xx1).squeeze()) . CAM | . fig, (ax1,ax2) = plt.subplots(1,2) # xx1.squeeze().show(ax=ax1) ax1.imshow(ver1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # xx1.squeeze().show(ax=ax2) ax2.imshow(ver1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(ver1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (1.3657330880802881e-13, 0.9999999999998634) . $ theta$가 작아지니 너무 똑같이 나온다. | . . $ theta=0.04$ &#51068; &#46412; SAMPLE . AA1=torch.exp(-0.04*test) . AA2=1-AA1 . fig, (ax1, ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHT WITH THETA=0.04&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT WITH THETA=0.04&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . XX1=np.array(AA1.to(&quot;cpu&quot;).detach(),dtype=np.float32) YY1=torch.Tensor(cv2.resize(XX1,(224,224),interpolation=cv2.INTER_LINEAR)) xx1=x.squeeze().to(&#39;cpu&#39;)*YY1 . XX12=np.array(AA2.to(&quot;cpu&quot;).detach(),dtype=np.float32) YY12=torch.Tensor(cv2.resize(XX12,(224,224),interpolation=cv2.INTER_LINEAR)) xx12=x.squeeze().to(&#39;cpu&#39;)*YY12 . 1st CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) xx12.squeeze().show(ax=ax1) #MODE1 xx1.squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . xx1=xx1.reshape(1,3,224,224) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . ver2 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(xx1).squeeze()) . CAM | . fig, (ax1,ax2) = plt.subplots(1,2) # xx1.squeeze().show(ax=ax1) ax1.imshow(ver2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # xx1.squeeze().show(ax=ax2) ax2.imshow(ver2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(ver2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(xx1).tolist()[0][0] b1=net(xx1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (0.9903353645622871, 0.009664635437712963) . 이 정도면 괜찮은 것 같다. | 첫번째 CAM에서 정상 판단 근거였던 폐의 가운데 부분이 어두워지자 약간 오른쪽 폐로 이동한 모습. | . CAT/DOG 예제에서 $ theta$를 2배씩 늘려나갔으나, 여기서는 $ theta$를 이전과 동일하게 유지함. | . test1=ver2[0]-torch.min(ver2[0]) . A3=torch.exp(-0.04*test1) . A4=1-A3 . fig, (ax1, ax2) = plt.subplots(1,2) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A3.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE2 WEIGHT WITH THETA=0.04&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A4.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE2 RES WEIGHT WITH THETA=0.04&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X3=np.array(A3.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y3=torch.Tensor(cv2.resize(X3,(224,224),interpolation=cv2.INTER_LINEAR)) x3=x.squeeze().to(&#39;cpu&#39;)*YY1*Y3 . X4=np.array(A4.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y4=torch.Tensor(cv2.resize(X4,(224,224),interpolation=cv2.INTER_LINEAR)) x4=x.squeeze().to(&#39;cpu&#39;)*YY1*Y4 . 2nd CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) xx12.squeeze().show(ax=ax1) xx1.squeeze().show(ax=ax2) ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x4.squeeze().show(ax=ax1) x3.squeeze().show(ax=ax2) ax1.set_title(&quot;MODE2&quot;) ax2.set_title(&quot;MODE2 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x3=x3.reshape(1,3,224,224) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . ver22 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x3).squeeze()) . CAM | . fig, (ax1,ax2) = plt.subplots(1,2) # x3.squeeze().show(ax=ax1) ax1.imshow(ver22[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;NORMAL PART&quot;) # x3.squeeze().show(ax=ax2) ax2.imshow(ver22[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DISEASE PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, (ax1,ax2, ax3) = plt.subplots(1,3) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(ver2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(ver22[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax3.set_title(&quot;3RD CAM&quot;) # fig.set_figwidth(12) fig.set_figheight(12) fig.tight_layout() . a2=net(x3).tolist()[0][0] b2=net(x3).tolist()[0][1] np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2)) . (7.881448771332073e-16, 0.9999999999999991) . . 전체 그림에 적용하기 (n=11712) | . fig, ax = plt.subplots(5,5) k=3000 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] normalprob, pneumoniaprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if normalprob&gt;pneumoniaprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;normal(%s)&quot; % normalprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,224,224,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;pneumonia(%s)&quot; % pneumoniaprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . import pandas as pd . col=pd.DataFrame() . k=0 col=[] for k in range(5) : col[k]=print(k) k=k+1 . 0 . IndexError Traceback (most recent call last) /tmp/ipykernel_170705/2694417875.py in &lt;module&gt; 2 col=[] 3 for k in range(5) : -&gt; 4 col[k]=print(k) 5 k=k+1 IndexError: list assignment index out of range . . refer : https://www.analyticsvidhya.com/blog/2020/10/develop-and-deploy-an-image-classifier-app-using-fastai/ . interp = ClassificationInterpretation.from_learner(lrnr2) interp.plot_confusion_matrix() . #cleaner #잘못 예측한 이미지 제거_제거될 이미지를 보여주는 것 같음 .",
            "url": "https://kimha02.github.io/ham/2022/02/06/chestxray.html",
            "relUrl": "/2022/02/06/chestxray.html",
            "date": " • Feb 6, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "(논문) CAT/DOG_ver.2",
            "content": ". import . import torch from fastai.vision.all import * import cv2 . . data . path=untar_data(URLs.PETS)/&#39;images&#39; . path . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images&#39;) . files=get_image_files(path) . def label_func(f): if f[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) . . learn . lrnr=cnn_learner(dls,resnet34,metrics=error_rate) lrnr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.161830 | 0.025255 | 0.006766 | 00:33 | . epoch train_loss valid_loss error_rate time . 0 | 0.046797 | 0.014727 | 0.003383 | 00:40 | . . sample . 1st CNN and CAM . get_image_files(path)[0] . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/boxer_128.jpg&#39;) . img = PILImage.create(get_image_files(path)[0]) img . x, = first(dls.test_dl([img])) #이미지 텐서화 . x.shape . torch.Size([1, 3, 512, 512]) . net1=lrnr.model[0] net2=lrnr.model[1] . net2 = torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(), torch.nn.Linear(512,out_features=2,bias=False)) . net=torch.nn.Sequential(net1,net2) . lrnr2=Learner(dls,net,metrics=accuracy) . lrnr2.fine_tune(25) . epoch train_loss valid_loss accuracy time . 0 | 0.224944 | 0.275368 | 0.888363 | 00:39 | . epoch train_loss valid_loss accuracy time . 0 | 0.097400 | 0.066326 | 0.974290 | 00:39 | . 1 | 0.067934 | 0.086611 | 0.962111 | 00:39 | . 2 | 0.070915 | 0.132380 | 0.937754 | 00:39 | . 3 | 0.062806 | 0.066810 | 0.973613 | 00:39 | . 4 | 0.079061 | 0.128490 | 0.946549 | 00:39 | . 5 | 0.081059 | 0.156254 | 0.934371 | 00:39 | . 6 | 0.096163 | 0.333563 | 0.876184 | 00:39 | . 7 | 0.066619 | 0.257219 | 0.909337 | 00:39 | . 8 | 0.078575 | 0.395381 | 0.921516 | 00:39 | . 9 | 0.057312 | 0.077355 | 0.965494 | 00:39 | . 10 | 0.054073 | 0.148319 | 0.945873 | 00:39 | . 11 | 0.045641 | 0.230499 | 0.935047 | 00:39 | . 12 | 0.036473 | 0.057884 | 0.978349 | 00:39 | . 13 | 0.029111 | 0.053304 | 0.979026 | 00:39 | . 14 | 0.027518 | 0.057935 | 0.976996 | 00:39 | . 15 | 0.024966 | 0.085742 | 0.974966 | 00:39 | . 16 | 0.013425 | 0.041078 | 0.983762 | 00:39 | . 17 | 0.007923 | 0.038059 | 0.987821 | 00:39 | . 18 | 0.009184 | 0.061577 | 0.983085 | 00:39 | . 19 | 0.008305 | 0.041248 | 0.981732 | 00:39 | . 20 | 0.005009 | 0.045444 | 0.985115 | 00:39 | . 21 | 0.004198 | 0.053832 | 0.985115 | 00:40 | . 22 | 0.003753 | 0.050990 | 0.987145 | 00:39 | . 23 | 0.003923 | 0.042834 | 0.987145 | 00:39 | . 24 | 0.002910 | 0.044543 | 0.987821 | 00:39 | . dls.vocab . [&#39;cat&#39;, &#39;dog&#39;] . (고양이,강아지)라고 생각한 확률 | . a=net(x).tolist()[0][0] b=net(x).tolist()[0][1] np.exp(a)/(np.exp(a)+np.exp(b)), np.exp(b)/(np.exp(a)+np.exp(b)) . (1.7321613661884395e-05, 0.999982678386338) . CAM | . camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;CAT PART&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DOG PART&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . &#9733; &#54032;&#45800; &#44540;&#44144;&#44032; &#44053;&#54624;&#49688;&#47197; &#54028;&#46976;&#49353; $ to$ &#48372;&#46972;&#49353; &#48320;&#54632; . . 2nd CNN and CAM . MODE 1 만들기 . 가중치 재설정 | . | . test=camimg[1]-torch.min(camimg[1]) . A1=torch.exp(-0.015*test) . A2=1-A1 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE1 WEIGHTT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE1 RES WEIGHT&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y1*0.9) . X12=np.array(A2.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR)) x12=x.squeeze().to(&#39;cpu&#39;)*Y12-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y12) . . &#55176;&#49828;&#53664;&#44536;&#47016; &#54217;&#54876;&#54868; . x1.show() plt.savefig(&#39;mode1_res&#39;) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . img = cv2.imread(&#39;mode1_res.png&#39;) . img.shape . (360, 360, 3) . img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV) . img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0]) . img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR) . 에러나는 부분 | . cv2.imshow(&#39;Color input image&#39;, img) cv2.imshow(&#39;Histogram equalized&#39;, img_output) . 그림이 나오긴 했는데... 조금 이상하다. | . fig, (ax1,ax2) = plt.subplots(1,2) ax1.imshow(img) ax2.imshow(img_output) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . . 1st CAM 결과를 분리하면 아래와 같음. | . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x12-torch.min(x12)).squeeze().show(ax=ax1) #MODE1 x1.squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x1=x1.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) . CAM . mode1_res에 CAM 결과 올리기 | . | . fig, (ax1,ax2) = plt.subplots(1,2) # x1.squeeze().show(ax=ax1) ax1.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;CAT PART&quot;) # x1.squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DOG PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째 CAM결과와 비교 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (0.07156445481742568, 0.9284355451825743) . . 3rd CNN and CAM . MODE 2 만들기 | . test1=camimg1[1]-torch.min(camimg1[1]) . A3=torch.exp(-0.03*test1) . A4=1-A3 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A3.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE2 RES WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A4.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE2 WEIGHT&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X2=np.array(A3.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR)) x2=x.squeeze().to(&#39;cpu&#39;)*Y1*Y2-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y1*Y2) . X22=np.array(A4.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR)) x22=x.squeeze().to(&#39;cpu&#39;)*Y1*Y22-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y1*Y22)*2.5 . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x12.squeeze().show(ax=ax1) #MODE1 x1.squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x22.squeeze().show(ax=ax1) #MODE2 x2.squeeze().show(ax=ax2) #MODE2_res ax1.set_title(&quot;MODE2&quot;) ax2.set_title(&quot;MODE2 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x2=x2.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg2 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x2).squeeze()) . CAM . mode2_res에 CAM 결과 올리기 | . | . fig, (ax1, ax2) = plt.subplots(1,2) # x2.squeeze().show(ax=ax1) ax1.imshow(camimg2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;CAT PART&quot;) # x2.squeeze().show(ax=ax2) ax2.imshow(camimg2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DOG PART&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째, 두번째 CAM결과와 비교 . fig, (ax1,ax2,ax3) = plt.subplots(1,3) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax3.set_title(&quot;3RD CAM&quot;) fig.set_figwidth(12) fig.set_figheight(12) fig.tight_layout() . a2=net(x2).tolist()[0][0] b2=net(x2).tolist()[0][1] np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2)) . (0.27261557988582774, 0.7273844201141721) . . 4th CNN and CAM . MODE 3 만들기 | . test2=camimg2[1]-torch.min(camimg2[1]) . A5=torch.exp(-0.06*test2) . A6=1-A5 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A5.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;MODE3 RES WEIGHT&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A6.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;MODE3 WEIGHT&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . X3=np.array(A5.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR)) x3=x.squeeze().to(&#39;cpu&#39;)*Y1*Y2*Y3-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y1*Y2*Y3) . X32=np.array(A6.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR)) x32=x.squeeze().to(&#39;cpu&#39;)*Y1*Y2*Y32-torch.min(x.squeeze().to(&#39;cpu&#39;)*Y1*Y2*Y32)*2.8 . fig, (ax1) = plt.subplots(1,1) dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.set_title(&quot;ORIGINAL&quot;) fig.set_figwidth(4) fig.set_figheight(4) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x12.squeeze().show(ax=ax1) #MODE1 x1.squeeze().show(ax=ax2) #MODE1_res ax1.set_title(&quot;MODE1&quot;) ax2.set_title(&quot;MODE1 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) x22.squeeze().show(ax=ax1) #MODE2 x2.squeeze().show(ax=ax2) #MODE2_res ax1.set_title(&quot;MODE2&quot;) ax2.set_title(&quot;MODE2 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() # fig, (ax1, ax2) = plt.subplots(1,2) (x32).squeeze().show(ax=ax1) #MODE3 x3.squeeze().show(ax=ax2) #MODE3_res ax1.set_title(&quot;MODE3&quot;) ax2.set_title(&quot;MODE3 RES&quot;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x3=x3.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg3 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x3).squeeze()) . CAM . mode3_res에 CAM 결과 올리기 | . | . fig, (ax1, ax2) = plt.subplots(1,2) # x3.squeeze().show(ax=ax1) ax1.imshow(camimg3[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;CAT PART&quot;) # x3.squeeze().show(ax=ax2) ax2.imshow(camimg3[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;DOG PART&quot;) # fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째, 두번째, 세번째 CAM결과와 비교 . fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax1.set_title(&quot;1ST CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax2.set_title(&quot;2ND CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax3.set_title(&quot;3RD CAM&quot;) # dls.train.decode((x,))[0].squeeze().show(ax=ax4) ax4.imshow(camimg3[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;cool&#39;) ax4.set_title(&quot;4TH CAM&quot;) # fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . a3=net(x3).tolist()[0][0] b3=net(x3).tolist()[0][1] np.exp(a3)/(np.exp(a3)+np.exp(b3)), np.exp(b3)/(np.exp(a3)+np.exp(b3)) . (0.5805579321414458, 0.41944206785855426) .",
            "url": "https://kimha02.github.io/ham/study/2022/01/26/cat-dog-2.html",
            "relUrl": "/study/2022/01/26/cat-dog-2.html",
            "date": " • Jan 26, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "(논문) CAT/DOG",
            "content": ". import . import torch from fastai.vision.all import * import cv2 . . data . path=untar_data(URLs.PETS)/&#39;images&#39; . path . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images&#39;) . files=get_image_files(path) . def label_func(f): if f[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) . Could not do one pass in your dataloader, there is something wrong in it . . learn . lrnr=cnn_learner(dls,resnet34,metrics=error_rate) lrnr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.178037 | 0.019520 | 0.009472 | 00:34 | . epoch train_loss valid_loss error_rate time . 0 | 0.039352 | 0.005454 | 0.000677 | 00:41 | . . sample . 1st CNN and CAM . get_image_files(path)[0] . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/boxer_128.jpg&#39;) . img = PILImage.create(get_image_files(path)[0]) img . x, = first(dls.test_dl([img])) #이미지 텐서화 . x.shape . torch.Size([1, 3, 512, 512]) . net1=lrnr.model[0] net2=lrnr.model[1] . net2 = torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(), torch.nn.Linear(512,out_features=2,bias=False)) . net=torch.nn.Sequential(net1,net2) . lrnr2=Learner(dls,net,metrics=accuracy) . lrnr2.fine_tune(15) . epoch train_loss valid_loss accuracy time . 0 | 0.259194 | 5.446237 | 0.415426 | 00:41 | . epoch train_loss valid_loss accuracy time . 0 | 0.115573 | 0.098918 | 0.966847 | 00:41 | . 1 | 0.084512 | 0.192782 | 0.924899 | 00:41 | . 2 | 0.108377 | 0.263869 | 0.929635 | 00:41 | . 3 | 0.108298 | 0.147747 | 0.946549 | 00:41 | . 4 | 0.092053 | 0.091769 | 0.966170 | 00:41 | . 5 | 0.071956 | 0.128430 | 0.957375 | 00:41 | . 6 | 0.085712 | 0.074232 | 0.974966 | 00:41 | . 7 | 0.055636 | 0.113164 | 0.956698 | 00:41 | . 8 | 0.049553 | 0.095807 | 0.968200 | 00:41 | . 9 | 0.032400 | 0.098665 | 0.966170 | 00:41 | . 10 | 0.021480 | 0.058845 | 0.978349 | 00:41 | . 11 | 0.014291 | 0.047291 | 0.983085 | 00:41 | . 12 | 0.009199 | 0.043928 | 0.982409 | 00:41 | . 13 | 0.008911 | 0.048288 | 0.982409 | 00:41 | . 14 | 0.006678 | 0.049579 | 0.982409 | 00:41 | . dls.vocab . [&#39;cat&#39;, &#39;dog&#39;] . (고양이,강아지)라고 생각한 확률 | . a=net(x).tolist()[0][0] b=net(x).tolist()[0][1] np.exp(a)/(np.exp(a)+np.exp(b)), np.exp(b)/(np.exp(a)+np.exp(b)) . (1.752036905842922e-05, 0.9999824796309416) . CAM | . camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . . 2nd CNN and CAM . MODE 1 만들기 . 가중치 재설정 | . | . test=camimg[1]-torch.min(camimg[1]) . A1=torch.exp(-0.015*test) . A2=1-A1 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A1.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A2.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . A1.data.to(&#39;cpu&#39;).shape . torch.Size([16, 16]) . X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) . Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) . x1=x.squeeze().to(&#39;cpu&#39;)*Y1 #MODE1을 x1으로 저장 . fig, (ax1,ax2) = plt.subplots(1,2) # x1.squeeze().show(ax=ax1) #MODE1 dls.train.decode((x,))[0].squeeze().show(ax=ax2) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x1=x1.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) . camimg1.shape . torch.Size([2, 16, 16]) . CAM . mode1에 CAM 결과 올리기 | . | . fig, (ax1,ax2) = plt.subplots(1,2) # x1.squeeze().show(ax=ax1) ax1.imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # x1.squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째 CAM결과와 비교 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . a1=net(x1).tolist()[0][0] b1=net(x1).tolist()[0][1] np.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1)) . (0.004487248125871372, 0.9955127518741286) . . 3rd CNN . MODE 2 만들기 | . test1=camimg1[1]-torch.min(camimg1[1]) . A3=torch.exp(-0.03*test1) . A4=1-A3 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A3.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A4.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . A3.data.to(&#39;cpu&#39;).shape . torch.Size([16, 16]) . X2=np.array(A3.to(&quot;cpu&quot;).detach(),dtype=np.float32) . Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR)) . x2=x1.squeeze().to(&#39;cpu&#39;)*Y2 #MODE2을 x2로 저장 . fig, (ax1,ax2,ax3) = plt.subplots(1,3) # x2.show(ax=ax1) #MODE2 x1.squeeze().show(ax=ax2) #MODE1 dls.train.decode((x,))[0].squeeze().show(ax=ax3) fig.set_figwidth(12) fig.set_figheight(12) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x2=x2.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg2 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x2).squeeze()) . CAM . mode2에 CAM 결과 올리기 | . | . fig, (ax1, ax2) = plt.subplots(1,2) x2.squeeze().show(ax=ax1) ax1.imshow(camimg2[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) x2.squeeze().show(ax=ax2) ax2.imshow(camimg2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째, 두번째 CAM결과와 비교 . fig, (ax1,ax2,ax3) = plt.subplots(1,3) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . a2=net(x2).tolist()[0][0] b2=net(x2).tolist()[0][1] np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2)) . (0.026369678868924343, 0.9736303211310757) . . 4th CNN . MODE 3 만들기 | . test2=camimg2[1]-torch.min(camimg2[1]) . A5=torch.exp(-0.06*test2) . A6=1-A5 . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(A5.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(A6.data.to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . A5.data.to(&#39;cpu&#39;).shape . torch.Size([16, 16]) . X3=np.array(A5.to(&quot;cpu&quot;).detach(),dtype=np.float32) . Y3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR)) . x3=x2.squeeze().to(&#39;cpu&#39;)*Y3 #MODE3을 x3로 저장 . fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) # x3.show(ax=ax1) #MODE3 x2.squeeze().show(ax=ax2) #MODE2 x1.squeeze().show(ax=ax3) #MODE1 dls.train.decode((x,))[0].squeeze().show(ax=ax4) fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . x3=x3.reshape(1,3,512,512) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . camimg3 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x3).squeeze()) . CAM . mode3에 CAM 결과 올리기 | . | . fig, (ax1, ax2) = plt.subplots(1,2) x3.squeeze().show(ax=ax1) ax1.imshow(camimg3[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) x3.squeeze().show(ax=ax2) ax2.imshow(camimg3[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(8) fig.set_figheight(8) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . - 첫번째, 두번째, 세번째 CAM결과와 비교 . fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax3) ax3.imshow(camimg2[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax4) ax4.imshow(camimg3[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . a3=net(x3).tolist()[0][0] b3=net(x3).tolist()[0][1] np.exp(a3)/(np.exp(a3)+np.exp(b3)), np.exp(b3)/(np.exp(a3)+np.exp(b3)) . (0.052085219034464114, 0.9479147809655359) . . CNN, CAM 횟수가 증가함에 따라 exp(-k*test)의 k를 2배씩 해주었음.$ to$ 2배로 증가시키니 k값을 유지했을 때보다 강아지라고 인식한 곳이 잘 이동함. | . lrnr2 epoch수를 늘려 과적합시킬수록 강아지라고 인식한 곳의 이동이 확연히 드러남. | . . &#51060;&#48120;&#51648; &#49688;&#47484; &#45720;&#47140;&#48372;&#51088; . 1st CNN and CAM . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x.to(&#39;cpu&#39;)).squeeze()) a,b = net(x.to(&#39;cpu&#39;)).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . mode1 | . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x.to(&#39;cpu&#39;)).squeeze()) a,b = net(x.to(&#39;cpu&#39;)).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: test=camimg[0]-torch.min(camimg[0]) A1=torch.exp(-0.015*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1.squeeze().show(ax=ax[i][j]) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: test=camimg[1]-torch.min(camimg[1]) A1=torch.exp(-0.015*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1.squeeze().show(ax=ax[i][j]) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . mode1의 residual | . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x.to(&#39;cpu&#39;)).squeeze()) a,b = net(x.to(&#39;cpu&#39;)).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: test=camimg[0]-torch.min(camimg[0]) A1=torch.exp(-0.015*test) A2=1-A1 X12=np.array(A2.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR)) x12=x.squeeze().to(&#39;cpu&#39;)*Y12 x12.squeeze().show(ax=ax[i][j]) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: test=camimg[1]-torch.min(camimg[1]) A1=torch.exp(-0.015*test) A2=1-A1 X12=np.array(A2.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR)) x12=x.squeeze().to(&#39;cpu&#39;)*Y12 x12.squeeze().show(ax=ax[i][j]) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . 2nd CNN and CAM . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x.to(&#39;cpu&#39;)).squeeze()) a,b = net(x.to(&#39;cpu&#39;)).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: test=camimg[0]-torch.min(camimg[0]) A1=torch.exp(-0.03*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1=x1.reshape(1,3,512,512) camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) x1.squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg1[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) else: test=camimg[1]-torch.min(camimg[1]) A1=torch.exp(-0.03*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1=x1.reshape(1,3,512,512) camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) x1.squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg1[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . mode2 | . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x.to(&#39;cpu&#39;)).squeeze()) a,b = net(x.to(&#39;cpu&#39;)).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: test=camimg[0]-torch.min(camimg[0]) A1=torch.exp(-0.03*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1=x1.reshape(1,3,512,512) camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) test1=camimg1[1]-torch.min(camimg1[1]) A3=torch.exp(-0.03*test1) X2=np.array(A3.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR)) x2=x1.squeeze().to(&#39;cpu&#39;)*Y2 x2.squeeze().show(ax=ax[i][j]) else: test=camimg[1]-torch.min(camimg[1]) A1=torch.exp(-0.03*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1=x1.reshape(1,3,512,512) camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) test1=camimg1[1]-torch.min(camimg1[1]) A3=torch.exp(-0.03*test1) X2=np.array(A3.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR)) x2=x1.squeeze().to(&#39;cpu&#39;)*Y2 x2.squeeze().show(ax=ax[i][j]) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . mode2의 residual | . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x.to(&#39;cpu&#39;)).squeeze()) a,b = net(x.to(&#39;cpu&#39;)).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: test=camimg[0]-torch.min(camimg[0]) A1=torch.exp(-0.03*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1=x1.reshape(1,3,512,512) camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) test1=camimg1[1]-torch.min(camimg1[1]) A3=torch.exp(-0.03*test1) A4=1-A3 X22=np.array(A4.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR)) x22=x1.squeeze().to(&#39;cpu&#39;)*Y22 x22.squeeze().show(ax=ax[i][j]) else: test=camimg[1]-torch.min(camimg[1]) A1=torch.exp(-0.03*test) X1=np.array(A1.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR)) x1=x.squeeze().to(&#39;cpu&#39;)*Y1 x1=x1.reshape(1,3,512,512) camimg1 = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x1).squeeze()) test1=camimg1[1]-torch.min(camimg1[1]) A3=torch.exp(-0.03*test1) A4=1-A3 X22=np.array(A4.to(&quot;cpu&quot;).detach(),dtype=np.float32) Y22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR)) x22=x1.squeeze().to(&#39;cpu&#39;)*Y22 x22.squeeze().show(ax=ax[i][j]) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . NameError Traceback (most recent call last) /tmp/ipykernel_1490982/3407106732.py in &lt;module&gt; -&gt; 1 fig, ax = plt.subplots(5,5) 2 k=0 3 for i in range(5): 4 for j in range(5): 5 x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) NameError: name &#39;plt&#39; is not defined .",
            "url": "https://kimha02.github.io/ham/study/2022/01/25/cat-dog.html",
            "relUrl": "/study/2022/01/25/cat-dog.html",
            "date": " • Jan 25, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "(공부) 빅데이터 수업 정리",
            "content": ". import . import torch from fastai.vision.all import * . import graphviz . def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+ s + &#39;;}&#39;) . data . path = untar_data(URLs.MNIST_SAMPLE) . path.ls() . (#3) [Path(&#39;/home/khy/.fastai/data/mnist_sample/train&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/valid&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/labels.csv&#39;)] . - list . threes=(path/&#39;train&#39;/&#39;3&#39;).ls() sevens=(path/&#39;train&#39;/&#39;7&#39;).ls() . - list $ to$ image . Image.open(threes[4]) . - image $ to$ tensor . tensor(Image.open(threes[4])) . tensor([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 211, 254, 254, 241, 144, 144, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 247, 253, 253, 253, 254, 253, 253, 247, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 253, 236, 154, 154, 154, 223, 253, 253, 244, 171, 52, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 241, 95, 0, 0, 0, 7, 54, 229, 253, 253, 141, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 23, 253, 253, 250, 65, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 199, 253, 253, 206, 22, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 75, 199, 241, 253, 253, 245, 78, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 45, 113, 155, 241, 254, 253, 253, 250, 185, 22, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 51, 188, 211, 253, 253, 253, 253, 254, 253, 253, 238, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 253, 253, 253, 253, 206, 253, 253, 253, 208, 24, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 10, 183, 183, 111, 111, 29, 0, 0, 0, 135, 253, 254, 70, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 214, 253, 227, 15, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 90, 250, 253, 234, 17, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 166, 244, 253, 253, 79, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 45, 122, 236, 253, 253, 238, 108, 5, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 81, 145, 69, 155, 155, 215, 253, 253, 255, 253, 236, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 176, 253, 253, 253, 253, 253, 253, 253, 177, 99, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 13, 42, 143, 230, 200, 143, 110, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8) . seven_tensor = torch.stack([tensor(Image.open(i)) for i in sevens]).float()/255 three_tensor = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255 . - $X$와 $y$를 만들자. . seven_tensor.shape, three_tensor.shape . (torch.Size([6265, 28, 28]), torch.Size([6131, 28, 28])) . y=torch.tensor([0.0]*6265+ [1.0]*6131).reshape(12396,1) . X=torch.vstack([seven_tensor,three_tensor]).reshape(12396,-1) . X.shape, y.shape . (torch.Size([12396, 784]), torch.Size([12396, 1])) . 28*28 . 784 . X=X.reshape(12396,1,28,28) . X.shape . torch.Size([12396, 1, 28, 28]) . . 6&#51452;&#52264; MNIST &#50696;&#51228;) MLP &#47784;&#54805; . ${ bf X} to { bf WX+b} to f({ bf WX+b}) to dots to { bf y}$ . ${ bf X}=12396 times 784$ matrix | ${ bf y}=12396 times 1$ (col) vector | . gv(&#39;&#39;&#39; splines=line subgraph cluster_1{ style=filled; color=lightgrey; &quot;x1&quot; &quot;x2&quot; &quot;..&quot; &quot;x784&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;x1&quot; -&gt; &quot;node1&quot; &quot;x2&quot; -&gt; &quot;node1&quot; &quot;..&quot; -&gt; &quot;node1&quot; &quot;x784&quot; -&gt; &quot;node1&quot; &quot;x1&quot; -&gt; &quot;node2&quot; &quot;x2&quot; -&gt; &quot;node2&quot; &quot;..&quot; -&gt; &quot;node2&quot; &quot;x784&quot; -&gt; &quot;node2&quot; &quot;x1&quot; -&gt; &quot;...&quot; &quot;x2&quot; -&gt; &quot;...&quot; &quot;..&quot; -&gt; &quot;...&quot; &quot;x784&quot; -&gt; &quot;...&quot; &quot;x1&quot; -&gt; &quot;node30&quot; &quot;x2&quot; -&gt; &quot;node30&quot; &quot;..&quot; -&gt; &quot;node30&quot; &quot;x784&quot; -&gt; &quot;node30&quot; label = &quot;Layer 1: ReLU&quot; } subgraph cluster_3{ style=filled; color=lightgrey; &quot;node1&quot; -&gt; &quot;y&quot; &quot;node2&quot; -&gt; &quot;y&quot; &quot;...&quot; -&gt; &quot;y&quot; &quot;node30&quot; -&gt; &quot;y&quot; label = &quot;Layer 2: Sigmoid&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: ReLU cluster_3 Layer 2: Sigmoid x1 x1 node1 node1 x1&#45;&gt;node1 node2 node2 x1&#45;&gt;node2 ... ... x1&#45;&gt;... node30 node30 x1&#45;&gt;node30 x2 x2 x2&#45;&gt;node1 x2&#45;&gt;node2 x2&#45;&gt;... x2&#45;&gt;node30 .. .. ..&#45;&gt;node1 ..&#45;&gt;node2 ..&#45;&gt;... ..&#45;&gt;node30 x784 x784 x784&#45;&gt;node1 x784&#45;&gt;node2 x784&#45;&gt;... x784&#45;&gt;node30 y y node1&#45;&gt;y node2&#45;&gt;y ...&#45;&gt;y node30&#45;&gt;y - 왜 28$ times$28 이미지를 펼쳐서 784개의 벡터로 만든 다음에 모형을 돌려야 하는가? . - 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌 . - observation의 차원은 $784$가 아니라 $1 times (28 times 28)$이 되어야 맞다. . 예제는 흑백이라서 $1 times(28 times28)$로 나타나고, 컬러인 경우에는 $3 times(28 times28)$ . . &#50696;&#51228; 1) &#51649;&#51217;&#45348;&#53944;&#50892;&#53356;&#49444;&#44228;, pytorch . 2d convolution with windowsize=5 . c1=torch.nn.Conv2d(1,16,5) # 입력채널=1 (흑백이므로), 출력채널=16, 윈도우크기5 . X.shape, c1(X).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24])) . X.shape는 28인데 왜 c1(X).shape는 24인가요? 윈도우 사이즈가 5씩 움직이다 보면, 첫 시작 윈도우는 1-5, 마지막 윈도우는 24-28이 된다. $ to$ 약간 겹치는 부분이 생기다 보니 $28 times 28$행렬에서 $24 times 24$로 차원이 변함 . 1에서 16으로 변한 것은 뭐지? 1개 이미지를 16개로 나눈 것 ! (뻥튀기 했다) . MaxPool2d . MaxPooling의 역할은 데이터의 단순화$ to$저화질로 변함 저화질로 변환해주는 이유 :이미지 분석 시 이미지의 전체 픽셀에 연결되는 것이 아니라 수용영역에 있는 픽셀에만 연결이 되기 때문에 우선 저화질(저수준)일 때의 특징에 집중하고, 이후 합성곱층에서 고수준으로 조합해 나감 ref : https://excelsior-cjh.tistory.com/180 . m1=torch.nn.MaxPool2d(2) . X.shape,c1(X).shape,m1(c1(X)).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12])) . ReLU . 비선형 과정 추가, ReLU는 0보다 크면 살리고, 0보다 작으면 날리는 방식으로 작동함 . a1=torch.nn.ReLU() . X.shape,c1(X).shape, m1(c1(X)).shape, a1(m1(c1(X))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 16, 12, 12])) . flatten . class Flatten(torch.nn.Module): def forward(self,x): return x.reshape(12396,-1) . flatten=Flatten() . X.shape,c1(X).shape, m1(c1(X)).shape, a1(m1(c1(X))).shape, flatten(a1(m1(c1(X)))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 2304])) . 16*12*12 . 2304 . 결국 y는 0,1의 값을 가지기 때문에 우리는 기존 신경망과 비슷하게 만들어야(펼쳐야) 함 . linear . l1=torch.nn.Linear(in_features=2304,out_features=1) . 2304의 디멘젼을 1로 만들자. 숨겨진 layer 없이 바로! 선형변환을 통해 2304의 디멘젼을 1로! . X.shape, c1(X).shape, m1(c1(X)).shape, a1(m1(c1(X))).shape, flatten(a1(m1(c1(X)))).shape, l1(flatten(a1(m1(c1(X))))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 2304]), torch.Size([12396, 1])) . plt.plot(l1(flatten(a1(m1(c1(X))))).data) . [&lt;matplotlib.lines.Line2D at 0x7f351c3c9e20&gt;] . 학습이 되지 않아서 분리되지 않은 모습이다. | . networks &#49444;&#44228; . net = nn.Sequential(c1,m1,a1,flatten,l1) ## 마지막의 sigmoid는 생략한다. torch.nn..BCEWithLogitsLoss()에 내장되어 있을것이므로 . - 손실함수와 옵티마이저 정의 . loss_fn=torch.nn.BCEWithLogitsLoss() optimizer= torch.optim.Adam(net.parameters()) . - step1~4 . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . zero_grad()는 gradients 초기화 역할 net.zero_grad() sets the gradients of all its parameters (including parameters of submodules) to zero. . a2= torch.nn.Sigmoid() . plt.plot(y) plt.plot(a2(yhat.data),&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f35681f1dc0&gt;] . ypred=a2(yhat.data)&gt;0.5 . sum(ypred==y)/12396 . tensor([0.9928]) . &#50696;&#51228; 2) &#46300;&#46989;&#50500;&#50883;, &#48176;&#52824;&#52628;&#44032; (&#51649;&#51217;&#45348;&#53944;&#50892;&#53356;&#49444;&#44228;, pytorch+fastai) . step1: dls&#47484; &#47564;&#46308;&#51088;. . ds=torch.utils.data.TensorDataset(X,y) . ds.tensors[0].shape #이미지 자체가 들어간 모습 . torch.Size([12396, 1, 28, 28]) . training/validation으로 나누자 | 10000개는 training, 2396개는 validation | . ds1,ds2 = torch.utils.data.random_split(ds,[10000,2396]) . dl1 = torch.utils.data.DataLoader(ds1,batch_size=500) dl2 = torch.utils.data.DataLoader(ds2,batch_size=2396) . 트레이닝 데이터는 배치사이즈 500으로 나눠줬다 | . dls=DataLoaders(dl1,dl2) #여기부터 fastai . step2: &#50500;&#53412;&#53581;&#52376;, &#49552;&#49892;&#54632;&#49688;, &#50741;&#54000;&#47560;&#51060;&#51200; . X.shape . torch.Size([12396, 1, 28, 28]) . class Flatten(torch.nn.Module): def forward(self,x): return x.reshape(x.shape[0],-1) . 이전 예제에서는 직접 값을 넣어줬는데 이번에는 열로 지정 | . net=torch.nn.Sequential( torch.nn.Conv2d(1,16,5), torch.nn.MaxPool2d(2), torch.nn.ReLU(), torch.nn.Dropout2d(), #dropout에도 2D! Flatten(), torch.nn.Linear(2304,1)) . loss_fn=torch.nn.BCEWithLogitsLoss() #optimizer= torch.optim.Adam(net.parameters()) : 러너에서 옵션으로 들어가기 때문에 주석 처리 . step3: lrnr &#49373;&#49457; &#54980; &#51201;&#54633; . lrnr1 = Learner(dls,net,opt_func=Adam,loss_func=loss_fn) . lrnr1.fit(10) . epoch train_loss valid_loss time . 0 | 0.453193 | 0.240746 | 00:00 | . 1 | 0.280424 | 0.091232 | 00:00 | . 2 | 0.192244 | 0.061074 | 00:00 | . 3 | 0.143204 | 0.050336 | 00:00 | . 4 | 0.112302 | 0.043875 | 00:00 | . 5 | 0.092774 | 0.038814 | 00:00 | . 6 | 0.079013 | 0.034993 | 00:00 | . 7 | 0.069009 | 0.032063 | 00:00 | . 8 | 0.061776 | 0.029489 | 00:00 | . 9 | 0.055343 | 0.026958 | 00:00 | . 왜 10번만 돌렸을까? 우리가 넣은 데이터는 총 10,000개, 배치 사이즈는 500 $ to$ 20번이 1 epoc 이전 예제에서 총 200번 학습하였기 때문에 10*20=200이므로 10번만 학습하면 된다. . - 결과를 시각화하면 아래와 같다. . plt.plot(a2(net(X.to(&quot;cuda:0&quot;)).to(&quot;cpu&quot;).data),&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f3567cf93d0&gt;] . lrnr1 분해하기! | . print(X.shape, &#39;--&gt; input image&#39;) print(lrnr1.model[0](X.to(&quot;cuda:0&quot;)).shape, &#39;--&gt; 2dConv&#39;) print(lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;))).shape, &#39;--&gt; MaxPool2d&#39;) print(lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;)))).shape, &#39;--&gt; ReLU&#39;) print(lrnr1.model[3](lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;))))).shape, &#39;--&gt; Dropout2d&#39;) print(lrnr1.model[4](lrnr1.model[3](lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;)))))).shape, &#39;--&gt; Flatten&#39;) print(lrnr1.model[5](lrnr1.model[4](lrnr1.model[3](lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;))))))).shape, &#39;--&gt; Linear&#39;) . torch.Size([12396, 1, 28, 28]) --&gt; input image torch.Size([12396, 16, 24, 24]) --&gt; 2dConv torch.Size([12396, 16, 12, 12]) --&gt; MaxPool2d torch.Size([12396, 16, 12, 12]) --&gt; ReLU torch.Size([12396, 16, 12, 12]) --&gt; Dropout2d torch.Size([12396, 2304]) --&gt; Flatten torch.Size([12396, 1]) --&gt; Linear . - 정리: 모형은 항상 아래와 같이 2d-part 와 1d-part로 나누어진다. . torch.Size([12396, 1, 28, 28]) --&gt; input image torch.Size([12396, 16, 24, 24]) --&gt; 2dConv torch.Size([12396, 16, 12, 12]) --&gt; MaxPool2d torch.Size([12396, 16, 12, 12]) --&gt; ReLU torch.Size([12396, 16, 12, 12]) --&gt; Dropout2d =============================================================== torch.Size([12396, 2304]) --&gt; Flatten torch.Size([12396, 1]) --&gt; Linear . - 2d-part: . 2d선형변환: nn.torch.nn.Conv2d() | 2d비선형변환: torch.nn.MaxPool2d(), torch.nn.ReLU() | . 선형-비선형 변환을 반복하면 특별한 특징들을 추출할 수 있음 . - 1d-part: . 1d선형변환: torch.nn.Linear() | 1d비선형변환: torch.nn.ReLU() | . 1d part에도 ReLU, Dropout을 넣기도 한다? 2d part에서 그냥 우리 옛날 예제처럼 1d로 바꿔주고 1d part에서 dropout, ReLU 등을 하는 것임! . &#50696;&#51228; 3) resnet34 (&#44592;&#51316;&#51032; &#45348;&#53944;&#50892;&#53356; &#49324;&#50857;, &#49692;&#49688; fastai) . - 데이터로부터 새로운 데이터로더스를 만들고 이를 dls2라고 하자. . resnet34는 $3 times 28 times 28$ 이 기본이기 때문에 이전이 데이터로더스를 쓸 수 없음 | . path=untar_data(URLs.MNIST_SAMPLE) path . Path(&#39;/home/khy/.fastai/data/mnist_sample&#39;) . dls2=ImageDataLoaders.from_folder( path, train=&#39;train&#39;, valid_pct=0.2) . - 러너오브젝트를 생성하고 학습하자. . lrnr2=cnn_learner(dls2,resnet34,metrics=error_rate) lrnr2.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.290861 | 0.187896 | 0.061331 | 00:05 | . epoch train_loss valid_loss error_rate time . 0 | 0.053579 | 0.024938 | 0.008663 | 00:05 | . - 결과관찰 . lrnr2.show_results() . - resnet은 현재 가장 성능이 좋은 모형(state of the art)중 하나이다. . lrnr2.model[1] #2d part #lrnr2.model[0] #1d part . Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): Flatten(full=False) (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25, inplace=False) (4): Linear(in_features=1024, out_features=512, bias=False) (5): ReLU(inplace=True) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5, inplace=False) (8): Linear(in_features=512, out_features=2, bias=False) ) . - 특징 . 2d-part: 입력채널이3이다, Conv2d에 padding/stride의 옵션이 있다, 드랍아웃이 없다, 배치정규화(BatchNorm1d)가 있다.흑백이미지라 입력채널 1개로 충분하지만, 일반화를 위해 입력채널 3개임. 그래서 우리가 이전에 만든 dls를 쓸 수 없는 것 . | 1d-part:배치정규화가 있다, 출력의 차원이 2이다. | . DLS, Networks . 네트워크의 형태에 따라서 dls의 형태도 다르게 만들어야 한다. | MLP모형: 입력이 $784$, 첫 네트워크의 형태가 $784 to 30$ 인 torch.nn.Linear() | CNN모형: 입력이 $1 times 28 times 28$, 첫 네트워크의 형태가 $1 times 28 times 28 to 16 times 24 times 24$ 인 torch.nn.Conv2d() | Resnet34: 입력이 $3 times 28 times 28$, 첫 네트워크의 형태가 $3 times 28 times 28 to 3 times 28 times 28$ 유지 | . 참고 . $y$ 분포가정 마지막층의 활성화함수 손실함수(파이토치) . 3.45, 4.43, ... (연속형) | 정규분포 | Linear | MSEloss | . 0 or 1 | 이항분포(베르누이) | Sigmoid | BCEloss | . [0,0,1], [0,1,0], [1,0,0] | 다항분포 | Softmax | CrossEntropyLoss | . . &#49444;&#47749;&#44032;&#45733;&#54620; CNN&#47784;&#54805; . - 현재까지의 모형 . 1단계: 2d선형변환 $ to$ 2d비선형변환 | 2단계: Flatten $ to$ MLP | . - lrnr1모형을 다시 복습 . lrnr1.model . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) (4): Flatten() (5): Linear(in_features=2304, out_features=1, bias=True) ) . net1=torch.nn.Sequential( lrnr1.model[0], lrnr1.model[1], lrnr1.model[2], lrnr1.model[3]) . net1(X.to(&#39;cuda:0&#39;)).shape . torch.Size([12396, 16, 12, 12]) . - 1단계까지의 출력결과를 시각화 . fig, axs = plt.subplots(4,4) k=0 for i in range(4): for j in range(4): axs[i,j].imshow(net1(X.to(&quot;cuda:0&quot;))[0][k].to(&quot;cpu&quot;).data) k=k+1 fig.set_figheight(8) fig.set_figwidth(8) fig.tight_layout() . net1&#51008; &#50976;&#51648;+ net2&#51032; &#44396;&#51312;&#47484; &#48320;&#44221;!! . lrnr1.model . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) (4): Flatten() (5): Linear(in_features=2304, out_features=1, bias=True) ) . - 계획 . 변경전net2: $(n,16,12,12) overset{flatten}{ Longrightarrow} (n,?) overset{Linear(?,1)}{ Longrightarrow} (n,1)$ | 변경후net2: $(n,16,12,12) overset{gap+flatten}{ Longrightarrow} (n,16) overset{Linear(16,1)}{ Longrightarrow} (n,1)$ | . - gap: 12$ times$12 픽셀을 평균내서 하나의 값으로 대표하자. . ap(average pooling)는 그냥 평균 . ap=torch.nn.AdaptiveAvgPool2d(output_size=1) . ap(net1(X.to(&quot;cuda:0&quot;))).shape . torch.Size([12396, 16, 1, 1]) . - flatten . flatten(ap(net1(X.to(&quot;cuda:0&quot;)))).shape . torch.Size([12396, 16]) . - linear . _l1=torch.nn.Linear(16,1,bias=False) . _l1.to(&quot;cuda:0&quot;) . Linear(in_features=16, out_features=1, bias=False) . _l1(flatten(ap(net1(X.to(&quot;cuda:0&quot;))))).shape . torch.Size([12396, 1]) . - 이걸 net2로 구성하자. $ to$ (net1,net2)를 묶어서 하나의 새로운 네트워크를 만들자. . net2=torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(1), Flatten(), torch.nn.Linear(16,1,bias=False)) . net=torch.nn.Sequential(net1,net2) net . Sequential( (0): Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) ) (1): Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten() (2): Linear(in_features=16, out_features=1, bias=False) ) ) . - 수정된 네트워크로 lrnr3을 만들고 재학습 . ds=torch.utils.data.TensorDataset(X,y) ds1,ds2=torch.utils.data.random_split(ds,[10000,2396]) dl1=torch.utils.data.DataLoader(ds1,batch_size=1000) dl2=torch.utils.data.DataLoader(ds2,batch_size=2396) dls=DataLoaders(dl1,dl2) . lrnr3=Learner(dls,net,opt_func=Adam,loss_func=loss_fn,lr=0.1) . lrnr3.fit(10) . epoch train_loss valid_loss time . 0 | 0.710577 | 0.685368 | 00:00 | . 1 | 0.699252 | 0.685568 | 00:00 | . 2 | 0.689714 | 0.629893 | 00:00 | . 3 | 0.674966 | 0.587605 | 00:00 | . 4 | 0.662550 | 0.578305 | 00:00 | . 5 | 0.653932 | 0.581777 | 00:00 | . 6 | 0.646438 | 0.568852 | 00:00 | . 7 | 0.639298 | 0.561586 | 00:00 | . 8 | 0.633959 | 0.544246 | 00:00 | . 9 | 0.629759 | 0.556775 | 00:00 | . CAM: observation&#51012; 1&#44060;&#47196; &#44256;&#51221;&#54616;&#44256; net2&#50640;&#49436; layer&#51032; &#49692;&#49436;&#47484; &#48148;&#45012;&#49436; &#49884;&#44033;&#54868; . - 계획 . 변경전net2: $(n,16,12,12) overset{flatten}{ Longrightarrow} (n,?) overset{Linear(?,1)}{ Longrightarrow} (n,1)$ | 변경후net2: $(n,16,12,12) overset{gap+flatten}{ Longrightarrow} (n,16) overset{Linear(16,1)}{ Longrightarrow} (n,1)$ | CAM: $(1,16,12,12) overset{Linear(16,1)+flatten}{ Longrightarrow} (12,12) overset{gap}{ Longrightarrow} 1$ | . - 준비과정1: 시각화할 샘플을 하나 준비하자. . x=X[100] X.shape,x.shape . (torch.Size([12396, 1, 28, 28]), torch.Size([1, 28, 28])) . 차원이 다르므로 나중에 네트워크에 넣을때 문제가 생길 수 있음 $ to$ 차원을 맞춰주자 | . x=x.reshape(1,1,28,28) . plt.imshow(x.squeeze()) . &lt;matplotlib.image.AxesImage at 0x7f3567339df0&gt; . - 준비과정2: 계산과 시각화를 위해서 각 네트워크를 cpu로 옮기자. (fastai로 학습한 직후라 GPU에 있음) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten() (2): Linear(in_features=16, out_features=1, bias=False) ) . - forward확인: 이 값을 기억하자. . net2(net1(x)) ## 음수이므로 class=7 이라고 CNN이 판단 . tensor([[-0.1985]], grad_fn=&lt;MmBackward&gt;) . - net2를 수정하고 forward값 확인 . net2 . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten() (2): Linear(in_features=16, out_features=1, bias=False) ) . - 차원확인 . net1(x).squeeze().shape . torch.Size([16, 12, 12]) . net1(x).shape . torch.Size([1, 16, 12, 12]) . net2[2].weight.squeeze().shape . torch.Size([16]) . Linear(in_features=16, out_features=1, bias=False) 를 적용: 16 $ times$ (16,12,12) $ to$ (12,12) . camimg=torch.einsum(&#39;i,ijk -&gt; jk&#39;,net2[2].weight.squeeze(), net1(x).squeeze()) #어떻게 변해야 하는지를 알려줘야 함 camimg.shape . torch.Size([12, 12]) . AdaptiveAvgPool2d(output_size=1) 를 적용 . ap(camimg) . tensor([[-0.1985]], grad_fn=&lt;MeanBackward1&gt;) . ★- 아래의 값이 같다. . net2(net1(x)),ap(camimg) . (tensor([[-0.1985]], grad_fn=&lt;MmBackward&gt;), tensor([[-0.1985]], grad_fn=&lt;MeanBackward1&gt;)) . - 왜냐하면 ap와 선형변환 모두 linear이므로 순서를 바꿔도 상관없음 . - 이제 camimg 에 관심을 가져보자. . camimg . tensor([[-0.9221, -0.9221, -0.9221, -0.9221, -0.9221, -0.9221, -0.9221, -0.9221, -0.9221, -0.9221, -0.9221, -0.9221], [-0.9221, -0.9221, -0.9221, -0.9221, -0.9221, 0.0000, 0.0000, 0.0000, 0.1071, 0.0000, 0.0000, -0.9221], [-0.9221, -0.9221, -0.9221, -0.9221, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.9221], [-0.9221, -0.9221, -0.9221, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.9221], [-0.9221, -0.1133, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.9221], [-0.1133, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.6413, -0.9221], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.9320, -0.9221], [ 9.5905, 8.9635, 0.0000, 0.0000, -0.1136, -0.9221, 0.0000, 0.0000, 0.0000, -0.3261, -0.9221, -0.9221], [ 4.2501, 8.4594, 0.0000, -0.9221, -0.9221, 0.0000, 0.0000, 0.0000, 0.0000, -0.9221, -0.9221, -0.9221], [-0.9221, -0.9221, -0.9221, -0.9221, -0.9221, 0.0000, 0.0000, 0.0000, 0.0000, -0.9254, -0.9221, -0.9221], [-0.9221, -0.9221, -0.9221, -0.9221, -0.1133, 0.0000, 0.0000, 0.0000, -0.4274, -0.9221, -0.9221, -0.9221], [-0.9221, -0.9221, -0.9221, -0.9221, 0.0000, 0.0000, 0.0000, 0.0000, -0.9221, -0.9221, -0.9221, -0.9221]], grad_fn=&lt;ViewBackward&gt;) . ap(camimg), torch.mean(camimg) . (tensor([[-0.1985]], grad_fn=&lt;MeanBackward1&gt;), tensor(-0.1985, grad_fn=&lt;MeanBackward0&gt;)) . - 결국 특정픽셀에서 큰 음의 값이 나오기 떄문에 궁극적으로는 평균이 음수가 된다. . 평균이 음수이다. $ leftrightarrow$ 이미지가 의미하는것이 7이다. | 특정픽셀이 큰 음수값을 가진다. $ leftrightarrow$ 그 픽셀에서 이미지가 7임을 뚜렷하게 알 수 있다. | . - 그 특정픽셀이 어딘가? . plt.imshow(camimg.data) . &lt;matplotlib.image.AxesImage at 0x7f356758ec70&gt; . 초록색으로 표현된 부분은 CNN모형이 이 숫자를 7이라고 생각한 근거가 된다. | . - 원래의 이미지와 비교 . plt.imshow(x.squeeze()) . &lt;matplotlib.image.AxesImage at 0x7f356758cc70&gt; . - 두 이미지를 겹쳐보자 . step1: 원래이미지를 흑백으로 그리자. . plt.imshow(x.squeeze(),cmap=&#39;gray&#39;,alpha=0.5) . &lt;matplotlib.image.AxesImage at 0x7f35673ac850&gt; . - step2: 원래이미지는 (28,28)인데 camimg는 (12,12)픽셀 $ to$ camimg의 픽셀을 늘리자. . plt.imshow(camimg.data,alpha=0.5, extent=(0,27,27,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) . &lt;matplotlib.image.AxesImage at 0x7f35673f1c40&gt; . - step3: 합치자. . plt.imshow(x.squeeze(),cmap=&#39;gray&#39;,alpha=0.5) plt.imshow(camimg.data,alpha=0.5, extent=(0,27,27,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) . &lt;matplotlib.image.AxesImage at 0x7f351c205130&gt; .",
            "url": "https://kimha02.github.io/ham/python/2022/01/11/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-7%EC%A3%BC%EC%B0%A8-%EC%A0%95%EB%A6%AC.html",
            "relUrl": "/python/2022/01/11/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-7%EC%A3%BC%EC%B0%A8-%EC%A0%95%EB%A6%AC.html",
            "date": " • Jan 11, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "(공부) 빅데이터 수업 정리",
            "content": ". &#48120;&#45768;&#48176;&#52824; . 아이디어 : 어떻게 해야 메모리를 줄일 수 있을까? | . 1. &#47676;&#51200; &#51060;&#54644;&#54644;&#50556; &#54624; &#44060;&#45392; . dataset : 텐서들의 pairds=torch.utils.data.TensorDataset(X,y) . | . dataloader : 데이터를 가져와 여러 개의 그룹으로 나눈 후 반복 작업하는 것을 수월하게 해줌 $ to$ 배치(batch)를 만들어줌dl=torch.utils.data.DataLoader(ds,batch_size=2,shuffle=True) . | . 2. &#50696;&#51228;&#47196; &#48372;&#45716; &#48120;&#45768;&#48176;&#52824; . MNIST 3/7 &#50696;&#51228; . - 우선 텐서로 이루어진 X,y를 만들자. . import torch from fastai.vision.all import * . path = untar_data(URLs.MNIST_SAMPLE) #데이터 다운로드 . threes=(path/&#39;train&#39;/&#39;3&#39;).ls() sevens=(path/&#39;train&#39;/&#39;7&#39;).ls() . seven_tensor = torch.stack([tensor(Image.open(i)) for i in sevens]).float()/255 #리스트를 텐서로! three_tensor = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255 . three_tensor.shape, seven_tensor.shape . (torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28])) . X=torch.vstack([seven_tensor,three_tensor]).reshape(12396,-1) #vstack으로 합치고 reshape y=torch.tensor([0.0]*6265 + [1.0]*6131).reshape(12396,1) #0을 seven_tensor만큼, 1을 three_tensor만큼 만들어서 tensor로 바꿔준다 . X.shape, y.shape #784=28*28 . (torch.Size([12396, 784]), torch.Size([12396, 1])) . import graphviz . def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+ s + &#39;;}&#39;) . gv(&#39;&#39;&#39; splines=line subgraph cluster_1{ style=filled; color=lightgrey; &quot;x1&quot; &quot;x2&quot; &quot;..&quot; &quot;x784&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;x1&quot; -&gt; &quot;node1&quot; &quot;x2&quot; -&gt; &quot;node1&quot; &quot;..&quot; -&gt; &quot;node1&quot; &quot;x784&quot; -&gt; &quot;node1&quot; &quot;x1&quot; -&gt; &quot;node2&quot; &quot;x2&quot; -&gt; &quot;node2&quot; &quot;..&quot; -&gt; &quot;node2&quot; &quot;x784&quot; -&gt; &quot;node2&quot; &quot;x1&quot; -&gt; &quot;...&quot; &quot;x2&quot; -&gt; &quot;...&quot; &quot;..&quot; -&gt; &quot;...&quot; &quot;x784&quot; -&gt; &quot;...&quot; &quot;x1&quot; -&gt; &quot;node30&quot; &quot;x2&quot; -&gt; &quot;node30&quot; &quot;..&quot; -&gt; &quot;node30&quot; &quot;x784&quot; -&gt; &quot;node30&quot; label = &quot;Layer 1: ReLU&quot; } subgraph cluster_3{ style=filled; color=lightgrey; &quot;node1&quot; -&gt; &quot;y&quot; &quot;node2&quot; -&gt; &quot;y&quot; &quot;...&quot; -&gt; &quot;y&quot; &quot;node30&quot; -&gt; &quot;y&quot; label = &quot;Layer 2: Sigmoid&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: ReLU cluster_3 Layer 2: Sigmoid x1 x1 node1 node1 x1&#45;&gt;node1 node2 node2 x1&#45;&gt;node2 ... ... x1&#45;&gt;... node30 node30 x1&#45;&gt;node30 x2 x2 x2&#45;&gt;node1 x2&#45;&gt;node2 x2&#45;&gt;... x2&#45;&gt;node30 .. .. ..&#45;&gt;node1 ..&#45;&gt;node2 ..&#45;&gt;... ..&#45;&gt;node30 x784 x784 x784&#45;&gt;node1 x784&#45;&gt;node2 x784&#45;&gt;... x784&#45;&gt;node30 y y node1&#45;&gt;y node2&#45;&gt;y ...&#45;&gt;y node30&#45;&gt;y (1) 미니 배치 사용 안 했을 때 . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=784,out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30,out_features=1) #torch.nn.Sigmoid() ) loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss= loss_fn(yhat,y) ## 3 : 미분 loss.backward() ## 4 : 업데이트 optimizer.step() net.zero_grad() . f=torch.nn.Sigmoid() plt.plot(f(yhat.data),&#39;.&#39;) #우리가 원하는 0,1 모양으로 나옴 . [&lt;matplotlib.lines.Line2D at 0x7faa9f546790&gt;] . (2) 미니 배치 . - 네트워크 파라메터 초기화 . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=784,out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30,out_features=1) #torch.nn.Sigmoid() ) loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . - dataset . ds=torch.utils.data.TensorDataset(X,y) . ds . &lt;torch.utils.data.dataset.TensorDataset at 0x7faa9fd8e6a0&gt; . ds.tensors . (tensor([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]), tensor([[0.], [0.], [0.], ..., [1.], [1.], [1.]])) . - dataloader . dl=torch.utils.data.DataLoader(ds,batch_size=2048,shuffle=True) . - 네트워크(아키텍처), 손실함수, 옵티마이저 . - 30은 node의 숫자 . 12396 / 2048 . 6.052734375 . - 총 7개의 미니배치가 만들어질것임 $ to$ 따라서 파라메터를 업데이트하는 횟수는 7 $ times$ epoc 임 (실제적으로는 6 $ times$ epoc) . 200/6 . 33.333333333333336 . - 파라메터를 200번 업데이트 하고 싶음 - 1번 에폭이 돌 때 6번 반복 $ to$ 200/6=33.3333... . for epoc in range(33): for xx,yy in dl: ### 총 7번돌면 끝나는 for ## 1 yyhat=net(xx) ## 2 loss= loss_fn(yyhat,yy) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(yyhat.data,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7faa9f4999a0&gt;] . - 배치사이즈를 다시 확인해보자. . for xx,yy in dl: print(xx.shape,yy.shape) . torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([108, 784]) torch.Size([108, 1]) . - 마지막이 108개이므로 108개의 y만 그려짐 . list(net.parameters()) . [Parameter containing: tensor([[ 0.0184, -0.0158, -0.0069, ..., 0.0068, -0.0041, 0.0025], [-0.0274, -0.0224, -0.0309, ..., -0.0029, 0.0013, -0.0167], [ 0.0282, -0.0095, -0.0340, ..., -0.0141, 0.0056, -0.0335], ..., [ 0.0267, 0.0186, -0.0326, ..., 0.0047, -0.0072, -0.0301], [-0.0190, 0.0291, 0.0221, ..., 0.0067, 0.0206, 0.0151], [ 0.0226, 0.0331, 0.0182, ..., 0.0150, 0.0278, -0.0073]], requires_grad=True), Parameter containing: tensor([-0.0119, 0.0269, 0.0336, -0.0091, 0.1124, 0.0174, 0.0163, -0.0248, 0.0344, 0.0378, -0.0179, 0.0448, 0.0205, 0.0758, 0.0097, 0.0005, 0.0353, 0.0356, 0.0543, 0.0156, 0.0577, 0.0128, 0.0486, 0.0669, -0.0036, -0.0301, 0.1002, 0.0440, 0.0642, 0.0564], requires_grad=True), Parameter containing: tensor([[ 0.2202, 0.1959, 0.2053, 0.1672, -0.2607, -0.0727, -0.1659, 0.1090, -0.2555, -0.2506, 0.1318, -0.1846, 0.1062, -0.1006, -0.2849, 0.1306, 0.1898, 0.2527, -0.1435, 0.2091, -0.2595, 0.1951, -0.1899, -0.1756, 0.1217, 0.1742, -0.1170, 0.1343, -0.1668, -0.1572]], requires_grad=True), Parameter containing: tensor([-0.0992], requires_grad=True)] . - 만약 잘 추정되었다면 아래의 결과가 잘 나와야겠지? . net(X) . tensor([[-7.6275], [-0.9907], [-8.1248], ..., [ 7.8302], [11.8567], [ 9.7307]], grad_fn=&lt;AddmmBackward&gt;) . plt.plot(net(X).data,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7faa9f524fd0&gt;] . f=torch.nn.Sigmoid() plt.plot(f(net(X).data),&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7faa9f3e5280&gt;] . . &#46300;&#46989;&#50500;&#50883; . 아이디어 : parameter 수가 많아져서 overfitting 현상 발생 $ to$ 변수를 줄이자 | . import torch import matplotlib.pyplot as plt . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . 오버피팅 예시 . for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(X,y) plt.plot(X,yhat.data) . [&lt;matplotlib.lines.Line2D at 0x7faa9f38d2b0&gt;] . - train/test 구분하여 예측해보자 . X1=X[:80] y1=y[:80] X2=X[80:] y2=y[80:] . torch.manual_seed(1) net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . for epoc in range(1000): ## 1 y1hat=net(X1) ## 2 loss=loss_fn(y1hat,y1) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(X,y) plt.plot(X1,net(X1).data,&#39;--r&#39;) plt.plot(X2,net(X2).data,&#39;--g&#39;) . [&lt;matplotlib.lines.Line2D at 0x7faa9f378160&gt;] . 드랍아웃 . - 드랍아웃은 좋은 node들만 업데이트 할 수 있도록 하는 것임 - Dropout(0.8)은 에폭마다 80%를 날리고 좋은 node 20%만 학습을 진행하는 것임 - 유의할 것은 평가할 때 모든 node를 사용해야 한다는 것! . torch.manual_seed(1) net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Dropout(0.8), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . for epoc in range(1000): ## 1 y1hat=net(X1) ## 2 loss=loss_fn(y1hat,y1) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . - 평가모드 안 했을 때 . plt.plot(X,y) plt.plot(X1,net(X1).data,&#39;--r&#39;) plt.plot(X2,net(X2).data,&#39;--g&#39;) . [&lt;matplotlib.lines.Line2D at 0x7faa9f2df7f0&gt;] . - 평가모드 했을 때 . net.eval() plt.plot(X,y) plt.plot(X1,net(X1).data,&#39;--r&#39;) plt.plot(X2,net(X2).data,&#39;--g&#39;) . [&lt;matplotlib.lines.Line2D at 0x7faa9f241f70&gt;] . ( ! ) 그런데 두 방법 중 어느 것이 더 나은지는 말하기 어려움. 비교를 해보자! . . pytorch + fastai . 아이디어 : 위와 같은 코드를 합해서 비교하려고 하니 너무 복잡하다 $ to$ pytorch+fastai 조합으로 해결! | . X_tr=X[:80] y_tr=y[:80] X_val=X[80:] y_val=y[80:] . ds1=torch.utils.data.TensorDataset(X_tr,y_tr) ds2=torch.utils.data.TensorDataset(X_val,y_val) . dl1 = torch.utils.data.DataLoader(ds1, batch_size=80) dl2 = torch.utils.data.DataLoader(ds2, batch_size=20) . - 데이터로더스(데이터로더의 집합)를 만든다. . from fastai.vision.all import * . dls=DataLoaders(dl1,dl2) . 드랍아웃 제외버전 . torch.manual_seed(1) net_fastai = torch.nn.Sequential( torch.nn.Linear(in_features=1, out_features=512), torch.nn.ReLU(), #torch.nn.Dropout(0.8), torch.nn.Linear(in_features=512, out_features=1)) #optimizer loss_fn=torch.nn.MSELoss() . - 러너오브젝트 (for문 대신돌려주는 오브젝트) . lrnr= Learner(dls,net_fastai,opt_func=Adam,loss_func=loss_fn) . - 에폭만 설정하고 바로 학습 . ★여기서 학습할 때 중간에서 멈추는 오류가 계속 나고 있음 . #lrnr.fit(1000) . - loss들도 에폭별로 기록되어 있음 . lrnr.recorder.plot_loss() . - net_fastai에도 파라메터가 업데이트 되어있음 . # list(net1.parameters()) #비교용, cuda 없음. cpu학습 . 리스트를 확인해보면 device가 cuda임 | net_fastai 의 파라메터가 알아서 GPU로 옮겨져서 학습됨. | . - 플랏 . net_fastai.to(&quot;cpu&quot;) #같은 디바이스에 올려주기 plt.plot(X,y,&#39;.&#39;) plt.plot(X_tr,net_fastai(X_tr).data) plt.plot(X_val,net_fastai(X_val).data) . [&lt;matplotlib.lines.Line2D at 0x7faa9c3a2e20&gt;] . 드랍아웃 추가버전 . torch.manual_seed(1) net_fastai = torch.nn.Sequential( torch.nn.Linear(in_features=1, out_features=512), torch.nn.ReLU(), torch.nn.Dropout(0.8), torch.nn.Linear(in_features=512, out_features=1)) #optimizer loss_fn=torch.nn.MSELoss() . lrnr= Learner(dls,net_fastai,opt_func=Adam,loss_func=loss_fn) . #lrnr.fit(1000) . lrnr.recorder.plot_loss() . 교수님 그림하고 다른 결과.. | . . net_fastai.to(&quot;cpu&quot;) plt.plot(X,y,&#39;.&#39;) plt.plot(X_tr,net_fastai(X_tr).data) plt.plot(X_val,net_fastai(X_val).data) . [&lt;matplotlib.lines.Line2D at 0x7faa9c611370&gt;] .",
            "url": "https://kimha02.github.io/ham/python/2022/01/03/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-6%EC%A3%BC%EC%B0%A8-%EC%A0%95%EB%A6%AC.html",
            "relUrl": "/python/2022/01/03/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-6%EC%A3%BC%EC%B0%A8-%EC%A0%95%EB%A6%AC.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "(8주차) 11월1일",
            "content": ". import . import torch from fastai.vision.all import * . data . path=untar_data(URLs.PETS)/&#39;images&#39; . path . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images&#39;) . path.ls() #path안에 있는 데이터 확인 . (#7393) [Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/boxer_128.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Sphynx_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/British_Shorthair_203.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Ragdoll_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Persian_272.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Bombay_200.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/shiba_inu_103.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/chihuahua_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/scottish_terrier_156.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/basset_hound_163.jpg&#39;)...] . files=get_image_files(path) . def label_func(f): if f[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) . learn . lrnr=cnn_learner(dls,resnet34,metrics=error_rate) lrnr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.170455 | 0.014030 | 0.006766 | 00:34 | . epoch train_loss valid_loss error_rate time . 0 | 0.050615 | 0.019925 | 0.005413 | 00:40 | . &#47784;&#54805;&#46895;&#50612;&#48372;&#44592; . - 샘플로 하나의 관측치를 만든다. . get_image_files(path)[0] . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/boxer_128.jpg&#39;) . img = PILImage.create(get_image_files(path)[0]) img . x, = first(dls.test_dl([img])) #이미지 텐서화 . x.shape . torch.Size([1, 3, 512, 512]) . - 전체네트워크를 1,2로 나눈다. . net1=lrnr.model[0] net2=lrnr.model[1] . - net2를 수정한다. . net1(x).shape . torch.Size([1, 512, 16, 16]) . net2 . Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): Flatten(full=False) (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25, inplace=False) (4): Linear(in_features=1024, out_features=512, bias=False) (5): ReLU(inplace=True) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5, inplace=False) (8): Linear(in_features=512, out_features=2, bias=False) ) . Linear(in_features=512, out_features=2, bias=False)에서 out_features=2인 걸 보니 SoftMax를 사용 . net2 = torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(), torch.nn.Linear(512,out_features=2,bias=False)) . - net1, net2를 묶어서 새로운 네트워크를 만들고 다시 학습 . net=torch.nn.Sequential(net1,net2) . lrnr2=Learner(dls,net,metrics=accuracy) . lrnr2.loss_func, lrnr.loss_func . (FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss()) . loss함수가 알아서 잘 들어가서 우리가 지정해줄 필요가 없음 . lrnr2.fine_tune(5) . epoch train_loss valid_loss accuracy time . 0 | 0.370238 | 0.680171 | 0.726658 | 00:40 | . epoch train_loss valid_loss accuracy time . 0 | 0.247451 | 0.297885 | 0.891746 | 00:40 | . 1 | 0.178602 | 0.126031 | 0.955345 | 00:40 | . 2 | 0.120577 | 0.093900 | 0.967524 | 00:40 | . 3 | 0.059919 | 0.047852 | 0.983762 | 00:40 | . 4 | 0.032076 | 0.037155 | 0.987145 | 00:40 | . - 시각화 . net1(x).shape, net2[2].weight.shape . (torch.Size([1, 512, 16, 16]), torch.Size([2, 512])) . camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) . 앞에 1은 날려주는 거 잊지 말자. $ij=2,512$, $jkl=521,16,16$를 $ikl=2,16,16$ . camimg.shape . torch.Size([2, 16, 16]) . 원래는 [1,7,7] 이었는데.. $ to$ 그래서 (7,7)를 평균내서 양인지 음인지 판단했고, 음이면 고양이 양수이면 강아지 와 같은 식으로 예측했음 (반대도가능) | 지금은 내가 데이터를 만들지 않았기 때문에 1을 고양이로 했는지 0을 강아지로 했는지 모르겠음 | 첫번째 차원이 왜 2인지도 클리어하지 않음 (마지막 활성화함수가 sigmoid가 아니고 softmax이기 때문이라는 것은 알고 있으나 명확하게 모르겠음) | . -- . &#49548;&#54532;&#53944;&#47589;&#49828; vs &#49884;&#44536;&#47784;&#51060;&#46300; . - 시그모이드 . y의 형태: 고양이=0, 개=1 . | 마지막 활성화함수: $u to frac{e^u}{1+e^u}$ 이때 $u$는 시그모이드층의 인풋 (=마지막 리니어층의 아웃풋) . | $u$의 값이 클수록 dog . | . - 소프트맥스 . $y$의 형태: 고양이=[1,0], 개=[0,1] . | 마지막 활성화함수: $(u_1,u_2) to big( frac{e^{u_1}}{e^{u_1}+e^{u_2}}, frac{e^{u_2}}{e^{u_1}+e^{u_2}} big)$, 이때 $(u_1,u_2)$는 소프트맥스의 인풋 (=마지막 리니어층의 아웃풋) . | $u_1$의 값이 클수록 cat, $u_2$의 값이 클수록 dog . | . - 참고로 $ big( frac{e^{u_1}}{e^{u_1}+e^{u_2}}, frac{e^{u_2}}{e^{u_1}+e^{u_2}} big)$에서 분자분모에 각각 $e^{-u_1}$을 곱하면 . $$ big( frac{1}{1+e^{u_2-u_1}}, frac{e^{u_2-u_1}}{1+e^{u_2-u_1}} big)$$ . 그리고 $u_2-u_1=u$라고 생각하면 . $$ big( frac{1}{1+e^{u}}, frac{e^{u}}{1+e^{u}} big)$$ . 이므로, 강아지라고 생각할 확률은 $ frac{e^u}{1+e^u}$, 고양이라고 생각할 확률은 $1- frac{e^u}{1+e^u}$이 되므로 시그모이드와 같아진다. . - 결국 이 경우 (2개의 클래스를 가지는 경우)는 똑같은 모형을 이득도 없이 파라메터만 더 써서 표현한 꼴임 . - 따라서 엄밀하게 따지면 이것은 파라메터의 낭비이다. 마치 . $$y_i = alpha_0 + beta_0 +( alpha_1+ beta_1)x_i+ epsilon_i$$ . 와 비슷함 . - 아래의 사례역시 유사하다. . 사례1: Ber(p) 대신 Ber(p,q)로 쓰는 꼴, (단 $p+q=1$) | 사례2: Bin(n,p) 대신 Bin(n, (p,q))로 쓰는 꼴, (단 $p+q=1$) | . - 하지만 위와 같은 표현식은 다차원으로 확장이 용이할 경우가 많다. . - 그리고 사실 파라메터를 몇개 더 써도 큰 문제는 아님(우리가 이미 쓰고 있는 파라메터가 10,000개 이상..) . - 전역최소해를 찾지 못할거라는 주장도 있지만 꼭 전역최소해를 찾야아하는 것도 아니다. . - 결론 . 소프트맥스는 시그모이드의 확장이다. | 클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다. | 그런데 사실 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (흑백이미지를 칼라잉크로 출력하는 느낌) | 오히려 resnet 같이 최적화된 모형을 뜯어 고치면서 성능 저하시키는 것이 더 안좋을 수 있다. | -- . - 다시 돌아오자. camimg를 이미지를 AP layer에 통과시키자. . torch.nn.AdaptiveAvgPool2d(output_size=1)(camimg) . tensor([[[-4.8805]], [[ 4.9498]]], device=&#39;cuda:0&#39;, grad_fn=&lt;MeanBackward1&gt;) . - $y approx[0,1]$ 임은 알겠는데 이것이 개인지 고양이인지는 모르겠음. . - dls에 코딩된 라벨을 확인 . dls.vocab . [&#39;cat&#39;, &#39;dog&#39;] . 뒷쪽값이 클수록 강아지이다. | . - 강아지라고 판단한 근거를 시각화하자. . plt.imshow(camimg[1].to(&quot;cpu&quot;).detach(),extent=(0,223,223,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) . &lt;matplotlib.image.AxesImage at 0x7f5a217ea040&gt; . - 학습에 사용된 그림 . dls.train.decode((x,))[0].squeeze().show() . &lt;AxesSubplot:&gt; . - plot . fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) . &lt;matplotlib.image.AxesImage at 0x7f5a226fbdc0&gt; . magma: 검-보-빨-노 순으로 값이 크다. | . - 오른쪽 그림에서 노란색으로 표현된 부분이 개라고 생각한 근거임 . 고양이가 아니라고 생각한 근거: 왼쪽그림의 보라색 | 강아지라고 생각한 근거: 오른쪽그램의 노란색 | . - (고양이,강아지)라고 생각한 확률 . a=net(x).tolist()[0][0] b=net(x).tolist()[0][1] np.exp(a)/(np.exp(a)+np.exp(b)), np.exp(b)/(np.exp(a)+np.exp(b)) . (5.376349728339599e-05, 0.9999462365027166) . &#54616;&#45768; . x, = first(dls.test_dl([PILImage.create(&#39;2021-09-06-hani01.png&#39;)])) . a,b = net(x).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) . camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) fig, (ax1,ax2) = plt.subplots(1,2) # dls.train.decode((x,))[0].squeeze().show(ax=ax1) ax1.imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax1.set_title(&quot;cat(%s)&quot; % catprob.round(5)) # dls.train.decode((x,))[0].squeeze().show(ax=ax2) ax2.imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax2.set_title(&quot;dog(%s)&quot; % dogprob.round(5)) . Text(0.5, 1.0, &#39;dog(0.99759)&#39;) . CAM &#44208;&#44284; &#54869;&#51064; . fig, ax = plt.subplots(5,5) k=0 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . fig, ax = plt.subplots(5,5) k=25 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . fig, ax = plt.subplots(5,5) k=50 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . fig, ax = plt.subplots(5,5) k=75 for i in range(5): for j in range(5): x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])])) camimg = torch.einsum(&#39;ij,jkl -&gt; ikl&#39;, net2[2].weight, net1(x).squeeze()) a,b = net(x).tolist()[0] catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) , np.exp(b)/ (np.exp(a)+np.exp(b)) if catprob&gt;dogprob: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[0].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;cat(%s)&quot; % catprob.round(5)) else: dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j]) ax[i][j].imshow(camimg[1].to(&quot;cpu&quot;).detach(),alpha=0.5,extent=(0,511,511,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) ax[i][j].set_title(&quot;dog(%s)&quot; % dogprob.round(5)) k=k+1 fig.set_figwidth(16) fig.set_figheight(16) fig.tight_layout() . discusstion about CAM . - 장점: CNN 모형의 판단근거를 시각화하기에 우수한 툴이다. . - 단점: 모형을 일부수정해야 한다. . - 단점2: 최종아웃풋에서만 시각화를 할 수 있음. .",
            "url": "https://kimha02.github.io/ham/python/2021/11/01/(8%EC%A3%BC%EC%B0%A8)-11%EC%9B%941%EC%9D%BC.html",
            "relUrl": "/python/2021/11/01/(8%EC%A3%BC%EC%B0%A8)-11%EC%9B%941%EC%9D%BC.html",
            "date": " • Nov 1, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "(7-8주차) 10월26일 10월28일",
            "content": ". import . import torch from fastai.vision.all import * . import graphviz . def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+ s + &#39;;}&#39;) . data . - download data . path = untar_data(URLs.MNIST_SAMPLE) . path.ls() . (#3) [Path(&#39;/home/khy/.fastai/data/mnist_sample/train&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/valid&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/labels.csv&#39;)] . - list . threes=(path/&#39;train&#39;/&#39;3&#39;).ls() sevens=(path/&#39;train&#39;/&#39;7&#39;).ls() . - list $ to$ image . Image.open(threes[4]) . - image $ to$ tensor . tensor(Image.open(threes[4])) . tensor([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 211, 254, 254, 241, 144, 144, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 247, 253, 253, 253, 254, 253, 253, 247, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 253, 236, 154, 154, 154, 223, 253, 253, 244, 171, 52, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 241, 95, 0, 0, 0, 7, 54, 229, 253, 253, 141, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 23, 253, 253, 250, 65, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 199, 253, 253, 206, 22, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 75, 199, 241, 253, 253, 245, 78, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 45, 113, 155, 241, 254, 253, 253, 250, 185, 22, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 51, 188, 211, 253, 253, 253, 253, 254, 253, 253, 238, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 253, 253, 253, 253, 206, 253, 253, 253, 208, 24, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 10, 183, 183, 111, 111, 29, 0, 0, 0, 135, 253, 254, 70, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 214, 253, 227, 15, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 90, 250, 253, 234, 17, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 166, 244, 253, 253, 79, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 45, 122, 236, 253, 253, 238, 108, 5, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 81, 145, 69, 155, 155, 215, 253, 253, 255, 253, 236, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 176, 253, 253, 253, 253, 253, 253, 253, 177, 99, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 13, 42, 143, 230, 200, 143, 110, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8) . 여기에서 tensor는 파이토치가 아니라 fastai에서 구현한 함수임 | . - 여러개의 리스트를 모두 텐서로 바꿔보자. . seven_tensor = torch.stack([tensor(Image.open(i)) for i in sevens]).float()/255 three_tensor = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255 . - $X$와 $y$를 만들자. . seven_tensor.shape, three_tensor.shape . (torch.Size([6265, 28, 28]), torch.Size([6131, 28, 28])) . y=torch.tensor([0.0]*6265+ [1.0]*6131).reshape(12396,1) . X=torch.vstack([seven_tensor,three_tensor]).reshape(12396,-1) . X.shape, y.shape . (torch.Size([12396, 784]), torch.Size([12396, 1])) . X=X.reshape(12396,1,28,28) . X.shape . torch.Size([12396, 1, 28, 28]) . 1. &#51648;&#45212;&#49884;&#44036;&#44620;&#51648;&#51032; &#47784;&#54805; (&#51649;&#51217;&#45348;&#53944;&#50892;&#53356;&#49444;&#44228;, pytorch) . 2d convolution with windowsize=5 . c1=torch.nn.Conv2d(1,16,5) # 입력채널=1 (흑백이므로), 출력채널=16, 윈도우크기5 . X.shape, c1(X).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24])) . MaxPool2d . m1=torch.nn.MaxPool2d(2) . X.shape,c1(X).shape,m1(c1(X)).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12])) . ReLU . a1=torch.nn.ReLU() . X.shape,c1(X).shape, m1(c1(X)).shape, a1(m1(c1(X))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 16, 12, 12])) . flatten . class Flatten(torch.nn.Module): def forward(self,x): return x.reshape(12396,-1) . flatten=Flatten() . X.shape,c1(X).shape, m1(c1(X)).shape, a1(m1(c1(X))).shape, flatten(a1(m1(c1(X)))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 2304])) . linear . l1=torch.nn.Linear(in_features=2304,out_features=1) . X.shape, c1(X).shape, m1(c1(X)).shape, a1(m1(c1(X))).shape, flatten(a1(m1(c1(X)))).shape, l1(flatten(a1(m1(c1(X))))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 2304]), torch.Size([12396, 1])) . plt.plot(l1(flatten(a1(m1(c1(X))))).data) . [&lt;matplotlib.lines.Line2D at 0x7fbb6f340b50&gt;] . 학습이 되지 않아서 분리되지 않은 모습이다. | . networks &#49444;&#44228; . net = nn.Sequential(c1,m1,a1,flatten,l1) ## 마지막의 sigmoid는 생략한다. torch.nn..BCEWithLogitsLoss()에 내장되어 있을것이므로 . - 손실함수와 옵티마이저 정의 . loss_fn=torch.nn.BCEWithLogitsLoss() optimizer= torch.optim.Adam(net.parameters()) . - step1~4 . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . a2= torch.nn.Sigmoid() . plt.plot(y) plt.plot(a2(yhat.data),&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fbb6f158490&gt;] . ypred=a2(yhat.data)&gt;0.5 . sum(ypred==y)/12396 . tensor([0.9925]) . 2. &#46300;&#46989;&#50500;&#50883;, &#48176;&#52824;&#52628;&#44032; (&#51649;&#51217;&#45348;&#53944;&#50892;&#53356;&#49444;&#44228;, pytorch+fastai) . step1: dls&#47484; &#47564;&#46308;&#51088;. . ds=torch.utils.data.TensorDataset(X,y) . ds.tensors[0].shape #이미지 자체가 들어간 모습 . torch.Size([12396, 1, 28, 28]) . training/validation으로 나누자 | 10000개는 training, 2396개는 validation | . ds1,ds2 = torch.utils.data.random_split(ds,[10000,2396]) . dl1 = torch.utils.data.DataLoader(ds1,batch_size=500) dl2 = torch.utils.data.DataLoader(ds2,batch_size=2396) . 트레이닝 데이터는 배치사이즈 500으로 나눠줬다 | . dls=DataLoaders(dl1,dl2) #여기부터 fastai . step2: &#50500;&#53412;&#53581;&#52376;, &#49552;&#49892;&#54632;&#49688;, &#50741;&#54000;&#47560;&#51060;&#51200; . X.shape . torch.Size([12396, 1, 28, 28]) . class Flatten(torch.nn.Module): def forward(self,x): return x.reshape(x.shape[0],-1) . 이전 예제에서는 직접 값을 넣어줬는데 이번에는 열로 지정 | . net=torch.nn.Sequential( torch.nn.Conv2d(1,16,5), torch.nn.MaxPool2d(2), torch.nn.ReLU(), torch.nn.Dropout2d(), #dropout에도 2D! Flatten(), torch.nn.Linear(2304,1)) . loss_fn=torch.nn.BCEWithLogitsLoss() #optimizer= torch.optim.Adam(net.parameters()) : 러너에서 옵션으로 들어가기 때문에 주석 처리 . step3: lrnr &#49373;&#49457; &#54980; &#51201;&#54633; . lrnr1 = Learner(dls,net,opt_func=Adam,loss_func=loss_fn) . lrnr1.fit(10) . epoch train_loss valid_loss time . 0 | 0.423429 | 0.211979 | 00:00 | . 1 | 0.257305 | 0.089080 | 00:00 | . 2 | 0.176406 | 0.066869 | 00:00 | . 3 | 0.132031 | 0.057877 | 00:00 | . 4 | 0.104421 | 0.052093 | 00:00 | . 5 | 0.086606 | 0.048054 | 00:00 | . 6 | 0.074307 | 0.044980 | 00:00 | . 7 | 0.064603 | 0.041866 | 00:00 | . 8 | 0.058012 | 0.039282 | 00:00 | . 9 | 0.052672 | 0.037370 | 00:00 | . 왜 10번만 돌렸을까? 우리가 넣은 데이터는 총 10,000개, 배치 사이즈는 500 $ to$ 20번이 1 epoc 이전 예제에서 총 200번 학습하였기 때문에 10*20=200이므로 10번만 학습하면 된다. . - 결과를 시각화하면 아래와 같다. . plt.plot(a2(net(X.to(&quot;cuda:0&quot;)).to(&quot;cpu&quot;).data),&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fbb6dce6880&gt;] . 네트워크의 parameter가 GPU(cuda:0)에 올라가 있기 때문에 X도 GPU에 올려주고 다시 CPU로 옮겨야 그림을 그릴 수 있음.-&gt;사실 GPU에 올려서 그려도 되는데 메모리 아끼기 위한..? . - 빠르고 적합결과도 좋음 . 3. resnet34 (&#44592;&#51316;&#51032; &#45348;&#53944;&#50892;&#53356; &#49324;&#50857;, &#49692;&#49688; fastai) . - 데이터로부터 새로운 데이터로더스를 만들고 이를 dls2라고 하자. . 전에 만든 거 쓰면 안됨!! | . path=untar_data(URLs.MNIST_SAMPLE) path . Path(&#39;/home/khy/.fastai/data/mnist_sample&#39;) . dls2=ImageDataLoaders.from_folder( path, train=&#39;train&#39;, valid_pct=0.2) . 참고 :가수 사진 분류 하기 . - 러너오브젝트를 생성하고 학습하자. . lrnr2=cnn_learner(dls2,resnet34,metrics=error_rate) lrnr2.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.312044 | 0.162629 | 0.054054 | 00:05 | . epoch train_loss valid_loss error_rate time . 0 | 0.043864 | 0.020806 | 0.007623 | 00:05 | . - 결과관찰 . lrnr2.show_results() . &#47784;&#54805;&#51012; &#46895;&#50612;&#48372;&#45716; &#48169;&#48277; (lrnr1.model) . - 우선 방법2로 돌아가자. . net(X.to(&quot;cuda:0&quot;)) #적합결과 . tensor([[-10.7490], [ -0.9917], [ -7.9382], ..., [ 11.1710], [ 14.0146], [ 12.4753]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward&gt;) . - 네트워크 구조 . net . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) (4): Flatten() (5): Linear(in_features=2304, out_features=1, bias=True) ) . net[1] #층별로 확인할 수 있음 . MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) . - 층별변환과정 . print(X.shape, &#39;--&gt; input image&#39;) print(net[0](X.to(&quot;cuda:0&quot;)).shape, &#39;--&gt; 2dConv&#39;) print(net[1](net[0](X.to(&quot;cuda:0&quot;))).shape, &#39;--&gt; MaxPool2d&#39;) print(net[2](net[1](net[0](X.to(&quot;cuda:0&quot;)))).shape, &#39;--&gt; ReLU&#39;) print(net[3](net[2](net[1](net[0](X.to(&quot;cuda:0&quot;))))).shape, &#39;--&gt; Dropout2d&#39;) print(net[4](net[3](net[2](net[1](net[0](X.to(&quot;cuda:0&quot;)))))).shape, &#39;--&gt; Flatten&#39;) print(net[5](net[4](net[3](net[2](net[1](net[0](X.to(&quot;cuda:0&quot;))))))).shape, &#39;--&gt; Linear&#39;) . torch.Size([12396, 1, 28, 28]) --&gt; input image torch.Size([12396, 16, 24, 24]) --&gt; 2dConv torch.Size([12396, 16, 12, 12]) --&gt; MaxPool2d torch.Size([12396, 16, 12, 12]) --&gt; ReLU torch.Size([12396, 16, 12, 12]) --&gt; Dropout2d torch.Size([12396, 2304]) --&gt; Flatten torch.Size([12396, 1]) --&gt; Linear . - 최종결과 . net[5](net[4](net[3](net[2](net[1](net[0](X.to(&quot;cuda:0&quot;))))))) . tensor([[-10.7490], [ -0.9917], [ -7.9382], ..., [ 11.1710], [ 14.0146], [ 12.4753]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward&gt;) . net(X.to(&quot;cuda:0&quot;)) . tensor([[-10.7490], [ -0.9917], [ -7.9382], ..., [ 11.1710], [ 14.0146], [ 12.4753]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward&gt;) . - lrnr1자체를 활용해도 층별변환과정을 추적할수 있음. (lrnr1.model = net 임을 이용) . lrnr1.model . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) (4): Flatten() (5): Linear(in_features=2304, out_features=1, bias=True) ) . lrnr1.model[0] . Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) . lrnr1.model(X.to(&quot;cuda:0&quot;)) . tensor([[-10.7490], [ -0.9917], [ -7.9382], ..., [ 11.1710], [ 14.0146], [ 12.4753]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward&gt;) . print(X.shape, &#39;--&gt; input image&#39;) print(lrnr1.model[0](X.to(&quot;cuda:0&quot;)).shape, &#39;--&gt; 2dConv&#39;) print(lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;))).shape, &#39;--&gt; MaxPool2d&#39;) print(lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;)))).shape, &#39;--&gt; ReLU&#39;) print(lrnr1.model[3](lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;))))).shape, &#39;--&gt; Dropout2d&#39;) print(lrnr1.model[4](lrnr1.model[3](lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;)))))).shape, &#39;--&gt; Flatten&#39;) print(lrnr1.model[5](lrnr1.model[4](lrnr1.model[3](lrnr1.model[2](lrnr1.model[1](lrnr1.model[0](X.to(&quot;cuda:0&quot;))))))).shape, &#39;--&gt; Linear&#39;) . torch.Size([12396, 1, 28, 28]) --&gt; input image torch.Size([12396, 16, 24, 24]) --&gt; 2dConv torch.Size([12396, 16, 12, 12]) --&gt; MaxPool2d torch.Size([12396, 16, 12, 12]) --&gt; ReLU torch.Size([12396, 16, 12, 12]) --&gt; Dropout2d torch.Size([12396, 2304]) --&gt; Flatten torch.Size([12396, 1]) --&gt; Linear . - 정리: 모형은 항상 아래와 같이 2d-part 와 1d-part로 나누어진다. . torch.Size([12396, 1, 28, 28]) --&gt; input image torch.Size([12396, 16, 24, 24]) --&gt; 2dConv torch.Size([12396, 16, 12, 12]) --&gt; MaxPool2d torch.Size([12396, 16, 12, 12]) --&gt; ReLU torch.Size([12396, 16, 12, 12]) --&gt; Dropout2d =============================================================== torch.Size([12396, 2304]) --&gt; Flatten torch.Size([12396, 1]) --&gt; Linear . - 2d-part: . 2d선형변환: nn.torch.nn.Conv2d() | 2d비선형변환: torch.nn.MaxPool2d(), torch.nn.ReLU() | . 선형-비선형 변환을 반복하면 특별한 특징들을 추출할 수 있음 . - 1d-part: . 1d선형변환: torch.nn.Linear() | 1d비선형변환: torch.nn.ReLU() | . 1d part에도 ReLU, Dropout을 넣기도 한다? 2d part에서 그냥 우리 옛날 예제처럼 1d로 바꿔주고 1d part에서 dropout, ReLU 등을 하는 것임! . 네트워크를 정리할 때 아래와 같이 2d, 1d를 나눠서 모형을 짜기도 함! | . _net1=torch.nn.Sequential( net[0], net[1], net[2], net[3]) _net2=torch.nn.Sequential( net[4], net[5]) . _net1 . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) ) . _net2 . Sequential( (0): Flatten() (1): Linear(in_features=2304, out_features=1, bias=True) ) . _net=torch.nn.Sequential(_net1,_net2) . _net[1](_net[0](X.to(&#39;cuda:0&#39;))) . tensor([[-10.7490], [ -0.9917], [ -7.9382], ..., [ 11.1710], [ 14.0146], [ 12.4753]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward&gt;) . lrnr2.model &#48516;&#49437; . - 아래의 모형은 현재 가장 성능이 좋은 모형(state of the art)중 하나인 resnet이다. . lrnr2.model[1] #2d part #lrnr2.model[0] #1d part . Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): Flatten(full=False) (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25, inplace=False) (4): Linear(in_features=1024, out_features=512, bias=False) (5): ReLU(inplace=True) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5, inplace=False) (8): Linear(in_features=512, out_features=2, bias=False) ) . - 특징 . 2d-part: 입력채널이3이다, Conv2d에 padding/stride의 옵션이 있다, 드랍아웃이 없다, 배치정규화(BatchNorm1d)가 있다.흑백이미지라 입력채널 1개로 충분하지만, 일반화를 위해 입력채널 3개임. 그래서 우리가 이전에 만든 dls를 쓸 수 없는 것 . | 1d-part:배치정규화가 있다, 출력의 차원이 2이다. | . DLS, Networks . 네트워크의 형태에 따라서 dls의 형태도 다르게 만들어야 한다. | MLP모형: 입력이 $784$, 첫 네트워크의 형태가 $784 to 30$ 인 torch.nn.Linear() | CNN모형: 입력이 $1 times 28 times 28$, 첫 네트워크의 형태가 $1 times 28 times 28 to 16 times 24 times 24$ 인 torch.nn.Conv2d() | Resnet34: 입력이 $3 times 28 times 28$, 첫 네트워크의 형태가 $3 times 28 times 28 to ??$ | . 참고 . $y$ 분포가정 마지막층의 활성화함수 손실함수(파이토치) . 3.45, 4.43, ... (연속형) | 정규분포 | Linear | MSEloss | . 0 or 1 | 이항분포(베르누이) | Sigmoid | BCEloss | . [0,0,1], [0,1,0], [1,0,0] | 다항분포 | Softmax | CrossEntropyLoss | . &#46373;&#47084;&#45789; &#50672;&#44396;&#51032; &#45348;&#44032;&#51648; &#52629; . (1) 아키텍처 $( star)$ . 한 영역의 전문적인 지식이 필요한 것이 아닌것 같다. | 끈기, 약간의 운, 직관, 좋은컴퓨터.. | . (2) 손실함수 . 통계적지식필요 // 기존의 손실함수를 변형하는 형태 (패널티텀활용) | . (3) 미분계산 . 병렬처리등에 대한 지식 필요 | . (4) 옵티마이저 . 최적화에 대한 이론적 토대 필요 | . - 딥러닝 이전까지의 아키텍처에 대한 연구 . 파라메트릭 모형: 전문가 | 넌파라메트릭 모형: 전문가 | 딥러닝: 상대적으로 비전문가 | . - 특징: 비전문가도 만들수 있다 + 블랙박스 (내부연산을 뜯어볼 수는 있지만 우리가 해석하기 어려움) . - 설명가능한 딥러닝에 대한 요구 (XAI) . &#49444;&#47749;&#44032;&#45733;&#54620; CNN&#47784;&#54805; . - 현재까지의 모형 . 1단계: 2d선형변환 $ to$ 2d비선형변환 | 2단계: Flatten $ to$ MLP | . - lrnr1(제가만들었던 모형)의 모형을 다시 복습 . lrnr1.model . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) (4): Flatten() (5): Linear(in_features=2304, out_features=1, bias=True) ) . net1=torch.nn.Sequential( lrnr1.model[0], lrnr1.model[1], lrnr1.model[2], lrnr1.model[3]) . net1(X.to(&#39;cuda:0&#39;)).shape . torch.Size([12396, 16, 12, 12]) . - 1단계까지의 출력결과를 시각화 . fig, axs = plt.subplots(4,4) k=0 for i in range(4): for j in range(4): axs[i,j].imshow(net1(X.to(&quot;cuda:0&quot;))[0][k].to(&quot;cpu&quot;).data) k=k+1 fig.set_figheight(8) fig.set_figwidth(8) fig.tight_layout() . net1&#51008; &#50976;&#51648;+ net2&#51032; &#44396;&#51312;&#47484; &#48320;&#44221;!! . lrnr1.model . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) (4): Flatten() (5): Linear(in_features=2304, out_features=1, bias=True) ) . - 계획 . 변경전net2: $(n,16,12,12) overset{flatten}{ Longrightarrow} (n,?) overset{Linear(?,1)}{ Longrightarrow} (n,1)$ | 변경후net2: $(n,16,12,12) overset{gap+flatten}{ Longrightarrow} (n,16) overset{Linear(16,1)}{ Longrightarrow} (n,1)$ | . - gap: 12$ times$12 픽셀을 평균내서 하나의 값으로 대표하자 (왜?) . ap=torch.nn.AdaptiveAvgPool2d(output_size=1) . ap(net1(X.to(&quot;cuda:0&quot;))).shape . torch.Size([12396, 16, 1, 1]) . . 보충학습 : ap(average pooling)는 그냥 평균 . torch.tensor([[0.1,0.2],[0.3,0.4]]) . tensor([[0.1000, 0.2000], [0.3000, 0.4000]]) . ap(torch.tensor([[0.1,0.2],[0.3,0.4]])) . tensor([[0.2500]]) . . - flatten . flatten(ap(net1(X.to(&quot;cuda:0&quot;)))).shape . torch.Size([12396, 16]) . - linear . _l1=torch.nn.Linear(16,1,bias=False) . _l1.to(&quot;cuda:0&quot;) . Linear(in_features=16, out_features=1, bias=False) . _l1(flatten(ap(net1(X.to(&quot;cuda:0&quot;))))).shape . torch.Size([12396, 1]) . - 이걸 net2로 구성하자. $ to$ (net1,net2)를 묶어서 하나의 새로운 네트워크를 만들자. . net2=torch.nn.Sequential( torch.nn.AdaptiveAvgPool2d(1), Flatten(), torch.nn.Linear(16,1,bias=False)) . net=torch.nn.Sequential(net1,net2) net . Sequential( (0): Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): ReLU() (3): Dropout2d(p=0.5, inplace=False) ) (1): Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten() (2): Linear(in_features=16, out_features=1, bias=False) ) ) . - 수정된 네트워크로 lrnr3을 만들고 재학습 . ds=torch.utils.data.TensorDataset(X,y) ds1,ds2=torch.utils.data.random_split(ds,[10000,2396]) dl1=torch.utils.data.DataLoader(ds1,batch_size=1000) dl2=torch.utils.data.DataLoader(ds2,batch_size=2396) dls=DataLoaders(dl1,dl2) . lrnr3=Learner(dls,net,opt_func=Adam,loss_func=loss_fn,lr=0.1) . lrnr3.fit(10) . epoch train_loss valid_loss time . 0 | 0.700811 | 0.687434 | 00:00 | . 1 | 0.687112 | 0.645707 | 00:00 | . 2 | 0.674917 | 0.603300 | 00:00 | . 3 | 0.664421 | 0.589552 | 00:00 | . 4 | 0.656465 | 0.578558 | 00:00 | . 5 | 0.651120 | 0.575888 | 00:00 | . 6 | 0.646332 | 0.564358 | 00:00 | . 7 | 0.642453 | 0.561910 | 00:00 | . 8 | 0.639582 | 0.549238 | 00:00 | . 9 | 0.636548 | 0.552422 | 00:00 | . CAM: observation&#51012; 1&#44060;&#47196; &#44256;&#51221;&#54616;&#44256; net2&#50640;&#49436; layer&#51032; &#49692;&#49436;&#47484; &#48148;&#45012;&#49436; &#49884;&#44033;&#54868; . - 계획 . 변경전net2: $(n,16,12,12) overset{flatten}{ Longrightarrow} (n,?) overset{Linear(?,1)}{ Longrightarrow} (n,1)$ | 변경후net2: $(n,16,12,12) overset{gap+flatten}{ Longrightarrow} (n,16) overset{Linear(16,1)}{ Longrightarrow} (n,1)$ | CAM: $(1,16,12,12) overset{Linear(16,1)+flatten}{ Longrightarrow} (12,12) overset{gap}{ Longrightarrow} 1$ | . - 준비과정1: 시각화할 샘플을 하나 준비하자. . x=X[100] X.shape,x.shape . (torch.Size([12396, 1, 28, 28]), torch.Size([1, 28, 28])) . 차원이 다르므로 나중에 네트워크에 넣을때 문제가 생길 수 있음 $ to$ 차원을 맞춰주자 | . x=x.reshape(1,1,28,28) . plt.imshow(x.squeeze()) . &lt;matplotlib.image.AxesImage at 0x7fbbbf077820&gt; . - 준비과정2: 계산과 시각화를 위해서 각 네트워크를 cpu로 옮기자. (fastai로 학습한 직후라 GPU에 있음) . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten() (2): Linear(in_features=16, out_features=1, bias=False) ) . - forward확인: 이 값을 기억하자. . net2(net1(x)) ## 음수이므로 class=7 이라고 CNN이 판단 . tensor([[-0.0378]], grad_fn=&lt;MmBackward&gt;) . - net2를 수정하고 forward값 확인 . net2 . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten() (2): Linear(in_features=16, out_features=1, bias=False) ) . net2에서 Linear와 AdaptiveAvgPool2d의 적용순서를 바꿔줌 | . 차원확인 . net1(x).squeeze().shape . torch.Size([16, 12, 12]) . squeeze로 차원을 줄여주나? . net2[2].weight.squeeze().shape . torch.Size([16]) . Linear(in_features=16, out_features=1, bias=False) 를 적용: 16 $ times$ (16,12,12) $ to$ (12,12) . net2[2].weight.squeeze() @ net1(x).squeeze() . RuntimeError Traceback (most recent call last) /tmp/ipykernel_1243196/2879013373.py in &lt;module&gt; -&gt; 1 net2[2].weight.squeeze() @ net1(x).squeeze() RuntimeError: mat1 and mat2 shapes cannot be multiplied (192x12 and 16x1) . 실패.. | . camimg=torch.einsum(&#39;i,ijk -&gt; jk&#39;,net2[2].weight.squeeze(), net1(x).squeeze()) #어떻게 변해야 하는지를 알려줘야 함 camimg.shape . torch.Size([12, 12]) . 성공 | . AdaptiveAvgPool2d(output_size=1) 를 적용 . ap(camimg) . tensor([[-0.0378]], grad_fn=&lt;MeanBackward1&gt;) . !!!! 똑같다? . - 아래의 값이 같다. . net2(net1(x)),ap(camimg) . (tensor([[-0.0378]], grad_fn=&lt;MmBackward&gt;), tensor([[-0.0378]], grad_fn=&lt;MeanBackward1&gt;)) . - 왜냐하면 ap와 선형변환 모두 linear이므로 순서를 바꿔도 상관없음 . - 아래와 결국 같은 이치 . _x= np.array([1,2,3,4]) _x . array([1, 2, 3, 4]) . np.mean(_x*2+1) . 6.0 . 2*np.mean(_x)+1 . 6.0 . - 이제 camimg 에 관심을 가져보자. . camimg . tensor([[-0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.8703], [-0.8703, -0.8703, -0.8703, -0.8703, -0.8703, -0.0642, -0.0699, 0.0000, 0.0000, 4.7832, 6.2696, -0.8703], [-0.8703, -0.8703, -0.8703, -0.8703, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.2098, 8.6752, -0.8703], [-0.8703, -0.8703, -0.8703, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.8703], [-0.8703, -0.4438, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.8703], [-0.4438, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.4498, -0.8703], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.8808, -0.8703], [ 6.4213, 7.9686, 0.0000, 0.0000, -0.1827, -0.8703, 0.0000, 0.0000, 0.0000, -0.3028, -0.8703, -0.8703], [ 0.1681, 3.7961, -0.0220, -0.8703, -0.8703, -0.0173, 0.0000, 0.0000, 0.0000, -0.8703, -0.8703, -0.8703], [-0.8703, -0.8703, -0.8703, -0.8703, -0.8703, 0.0000, 0.0000, 0.0000, 0.0000, -0.8738, -0.8703, -0.8703], [-0.8703, -0.8703, -0.8703, -0.8703, -0.4438, 0.0000, 0.0000, 0.0000, -0.3890, -0.8703, -0.8703, -0.8703], [-0.8703, -0.8703, -0.8703, -0.8703, 5.5741, 6.3670, 0.0000, 0.0000, -0.8703, -0.8703, -0.8703, -0.8703]], grad_fn=&lt;ViewBackward&gt;) . ap(camimg), torch.mean(camimg) . (tensor([[-0.0378]], grad_fn=&lt;MeanBackward1&gt;), tensor(-0.0378, grad_fn=&lt;MeanBackward0&gt;)) . 이미지의 값은 대부분0이지만 궁극적으로는 평균을 내서 음수의 값이 나와야 한다. | . - 결국 특정픽셀에서 큰 음의 값이 나오기 떄문에 궁극적으로는 평균이 음수가 된다. . 평균이 음수이다. $ leftrightarrow$ 이미지가 의미하는것이 7이다. | 특정픽셀이 큰 음수값을 가진다. $ leftrightarrow$ 그 픽셀에서 이미지가 7임을 뚜렷하게 알 수 있다. | . - 그 특정픽셀이 어딘가? . plt.imshow(camimg.data) . &lt;matplotlib.image.AxesImage at 0x7fbbbf06a5e0&gt; . 초록색으로 표현된 부분은 CNN모형이 이 숫자를 7이라고 생각한 근거가 된다. | . - 원래의 이미지와 비교 . plt.imshow(x.squeeze()) . &lt;matplotlib.image.AxesImage at 0x7fbbbf0dc460&gt; . - 두 이미지를 겹쳐서 그리면 멋진 그림이 될 것 같다. . step1: 원래이미지를 흑백으로 그리자. . plt.imshow(x.squeeze(),cmap=&#39;gray&#39;,alpha=0.5) . &lt;matplotlib.image.AxesImage at 0x7fbbbf118640&gt; . - step2: 원래이미지는 (28,28)인데 camimg는 (12,12)픽셀 $ to$ camimg의 픽셀을 늘리자. . plt.imshow(camimg.data,alpha=0.5, extent=(0,27,27,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) . &lt;matplotlib.image.AxesImage at 0x7fbbbea2b3a0&gt; . - step3: 합치자. . plt.imshow(x.squeeze(),cmap=&#39;gray&#39;,alpha=0.5) plt.imshow(camimg.data,alpha=0.5, extent=(0,27,27,0),interpolation=&#39;bilinear&#39;,cmap=&#39;magma&#39;) . &lt;matplotlib.image.AxesImage at 0x7fbbbea18f10&gt; . &#49689;&#51228; . - 숫자3이 그려진 이미지를 observation으로 선택하고 위와 같이 cam을 이용하여 시각화하라. .",
            "url": "https://kimha02.github.io/ham/python/2021/10/28/(7-8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9426%EC%9D%BC-10%EC%9B%9428%EC%9D%BC.html",
            "relUrl": "/python/2021/10/28/(7-8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9426%EC%9D%BC-10%EC%9B%9428%EC%9D%BC.html",
            "date": " • Oct 28, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "(7주차) 10월21일",
            "content": ". import . import torch from fastai.vision.all import * . import graphviz . def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+ s + &#39;;}&#39;) . data . - download data . path = untar_data(URLs.MNIST_SAMPLE) . path.ls() . (#3) [Path(&#39;/home/khy/.fastai/data/mnist_sample/train&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/valid&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/labels.csv&#39;)] . - list . threes=(path/&#39;train&#39;/&#39;3&#39;).ls() sevens=(path/&#39;train&#39;/&#39;7&#39;).ls() . - list $ to$ image . Image.open(threes[4]) . - image $ to$ tensor . tensor(Image.open(threes[4])) . tensor([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 211, 254, 254, 241, 144, 144, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 247, 253, 253, 253, 254, 253, 253, 247, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 253, 236, 154, 154, 154, 223, 253, 253, 244, 171, 52, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 241, 95, 0, 0, 0, 7, 54, 229, 253, 253, 141, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 23, 253, 253, 250, 65, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 199, 253, 253, 206, 22, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 75, 199, 241, 253, 253, 245, 78, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 45, 113, 155, 241, 254, 253, 253, 250, 185, 22, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 51, 188, 211, 253, 253, 253, 253, 254, 253, 253, 238, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 253, 253, 253, 253, 206, 253, 253, 253, 208, 24, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 10, 183, 183, 111, 111, 29, 0, 0, 0, 135, 253, 254, 70, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 214, 253, 227, 15, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 90, 250, 253, 234, 17, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 166, 244, 253, 253, 79, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 45, 122, 236, 253, 253, 238, 108, 5, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 81, 145, 69, 155, 155, 215, 253, 253, 255, 253, 236, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 176, 253, 253, 253, 253, 253, 253, 253, 177, 99, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 13, 42, 143, 230, 200, 143, 110, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8) . 여기에서 tensor는 파이토치가 아니라 fastai에서 구현한 함수임 | . - 여러개의 리스트를 모두 텐서로 바꿔보자. . seven_tensor = torch.stack([tensor(Image.open(i)) for i in sevens]).float()/255 three_tensor = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255 . - $X$와 $y$를 만들자. . seven_tensor.shape, three_tensor.shape . (torch.Size([6265, 28, 28]), torch.Size([6131, 28, 28])) . y=torch.tensor([0.0]*6265+ [1.0]*6131).reshape(12396,1) . X=torch.vstack([seven_tensor,three_tensor]).reshape(12396,-1) . X.shape, y.shape . (torch.Size([12396, 784]), torch.Size([12396, 1])) . &#44592;&#51316;&#51032; MLP &#47784;&#54805; . ${ bf X} to { bf WX+b} to f({ bf WX+b}) to dots to { bf y}$ . ${ bf X}=12396 times 784$ matrix | ${ bf y}=12396 times 1$ (col) vector | . - 교재의 모형 . gv(&#39;&#39;&#39; splines=line subgraph cluster_1{ style=filled; color=lightgrey; &quot;x1&quot; &quot;x2&quot; &quot;..&quot; &quot;x784&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;x1&quot; -&gt; &quot;node1&quot; &quot;x2&quot; -&gt; &quot;node1&quot; &quot;..&quot; -&gt; &quot;node1&quot; &quot;x784&quot; -&gt; &quot;node1&quot; &quot;x1&quot; -&gt; &quot;node2&quot; &quot;x2&quot; -&gt; &quot;node2&quot; &quot;..&quot; -&gt; &quot;node2&quot; &quot;x784&quot; -&gt; &quot;node2&quot; &quot;x1&quot; -&gt; &quot;...&quot; &quot;x2&quot; -&gt; &quot;...&quot; &quot;..&quot; -&gt; &quot;...&quot; &quot;x784&quot; -&gt; &quot;...&quot; &quot;x1&quot; -&gt; &quot;node30&quot; &quot;x2&quot; -&gt; &quot;node30&quot; &quot;..&quot; -&gt; &quot;node30&quot; &quot;x784&quot; -&gt; &quot;node30&quot; label = &quot;Layer 1: ReLU&quot; } subgraph cluster_3{ style=filled; color=lightgrey; &quot;node1&quot; -&gt; &quot;y&quot; &quot;node2&quot; -&gt; &quot;y&quot; &quot;...&quot; -&gt; &quot;y&quot; &quot;node30&quot; -&gt; &quot;y&quot; label = &quot;Layer 2: Sigmoid&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: ReLU cluster_3 Layer 2: Sigmoid x1 x1 node1 node1 x1&#45;&gt;node1 node2 node2 x1&#45;&gt;node2 ... ... x1&#45;&gt;... node30 node30 x1&#45;&gt;node30 x2 x2 x2&#45;&gt;node1 x2&#45;&gt;node2 x2&#45;&gt;... x2&#45;&gt;node30 .. .. ..&#45;&gt;node1 ..&#45;&gt;node2 ..&#45;&gt;... ..&#45;&gt;node30 x784 x784 x784&#45;&gt;node1 x784&#45;&gt;node2 x784&#45;&gt;... x784&#45;&gt;node30 y y node1&#45;&gt;y node2&#45;&gt;y ...&#45;&gt;y node30&#45;&gt;y - 왜 28$ times$28 이미지를 펼쳐서 784개의 벡터로 만든 다음에 모형을 돌려야 하는가? . - 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌 . - observation의 차원은 $784$가 아니라 $1 times (28 times 28)$이 되어야 맞다. . 예제는 흑백이라서 $1 times(28 times28)$로 나타나고, 컬러인 경우에는 $3 times(28 times28)$ . X.shape . torch.Size([12396, 784]) . X=X.reshape(12396,1,28,28) . X.shape . torch.Size([12396, 1, 28, 28]) . plt.imshow(X[776][0]) #[0]꼭 넣어주기(흑백이미지여서?) . &lt;matplotlib.image.AxesImage at 0x7f4abcd0f3d0&gt; . &#49440;&#54805;&#48320;&#54872; &#45824;&#49888;&#50640; 2d convolution with windowsize=5 . window size=5 이면 window는 5X5 | . c1=torch.nn.Conv2d(1,16,5) # 입력채널=1 (흑백이므로), 출력채널=16, 윈도우크기5 . NameError Traceback (most recent call last) /tmp/ipykernel_1661330/3897445218.py in &lt;module&gt; -&gt; 1 c1=torch.nn.Conv2d(1,16,5) # 입력채널=1 (흑백이므로), 출력채널=16, 윈도우크기5 NameError: name &#39;torch&#39; is not defined . X.shape, c1(X).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24])) . X.shape는 28인데 왜 c1(X).shape는 24인가요? 윈도우 사이즈가 5씩 움직이다 보면, 첫 시작 윈도우는 1-5, 마지막 윈도우는 24-28이 된다. $ to$ 약간 겹치는 부분이 생기다 보니 숫자가 달라진 것이다! $ to$ $28 times 28$행렬에서 $24 times 24$로 차원이 변함 . 1에서 16으로 변한 것은 뭐지? 1개 이미지를 16개로 나눈 것 ! (뻥튀기 했다) . fig, axs = plt.subplots(4,4) k=0 for i in range(4): for j in range(4): axs[i,j].imshow(c1(X)[776][k].data) k=k+1 . 같은 777번째 이미지(0포함 776번째) 불러오고, 1개였던 이미지가 16개가 되니까 k는 1에서 16까지 변함. .data는 선형 변환된 값이 출력되어 나오는데 미분되어 나오니까 붙여줘야 함. . fig.set_figheight(8) fig.set_figwidth(8) fig.tight_layout() fig . ReLU() &#45824;&#49888; MaxPool2d + ReLU . MaxPool2d . m1=torch.nn.MaxPool2d(2) #여기서 2를 넣어서 24-&gt;12로 바뀜 . X.shape,c1(X).shape,m1(c1(X)).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12])) . 12,12는 왜 등장했는지 확인해보자. . fig, axs = plt.subplots(4,4) k=0 for i in range(4): for j in range(4): axs[i,j].imshow(m1(c1(X))[776][k].data) k=k+1 fig.set_figheight(8) fig.set_figwidth(8) fig.tight_layout() . 비교 화질이 좀 안 좋아진 것 같다 MaxPooling의 역할은 데이터의 단순화$ to$저화질로 변함 다른 역할은 다음에 설명 추가! . ReLU . a1=torch.nn.ReLU() . X.shape,c1(X).shape, m1(c1(X)).shape, a1(m1(c1(X))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 12, 12]), torch.Size([12396, 16, 12, 12])) . ReLU를 거쳐도 숫자에서 바뀌는 것은 없음 하지만 비선형 과정을 거치기 때문에 약간 달리지는 것이 있음! . fig, axs = plt.subplots(4,4) k=0 for i in range(4): for j in range(4): axs[i,j].imshow(a1(m1(c1(X)))[776][k].data) k=k+1 fig.set_figheight(8) fig.set_figwidth(8) fig.tight_layout() . 몇 개의 이미지가 잘린 모습, 배경 색이 변함(초록에서 남색으로) . ReLU는 0보다 크면 살리고, 0보다 작으면 날리는 방식으로 작동함 | . 확인해보기! . torch.manual_seed(1) _A= torch.randn((3,3)) _A . tensor([[ 0.6614, 0.2669, 0.0617], [ 0.6213, -0.4519, -0.1661], [-1.5228, 0.3817, -1.0276]]) . a1(_A) . tensor([[0.6614, 0.2669, 0.0617], [0.6213, 0.0000, 0.0000], [0.0000, 0.3817, 0.0000]]) . &#50668;&#44592;&#50640;&#49436; &#44536;&#45285; &#49884;&#44536;&#47784;&#51060;&#46300;&#50640; &#53468;&#50864;&#51088;. . - 현재상황 . a1(m1(c1(X))).shape . torch.Size([12396, 16, 12, 12]) . - 펼치자 . 결국 y는 0,1의 값을 가지기 때문에 우리는 기존 신경망과 비슷하게 만들어야(펼쳐야) 함 . a1(m1(c1(X))).reshape(12396,-1).shape . torch.Size([12396, 2304]) . 16*12*12 . 2304 . - 2304의 디멘젼을 1로 만들자. . 숨겨진 layer 없이 바로! 선형변환을 통해 2304의 디멘젼을 1로! . l1=torch.nn.Linear(in_features=2304,out_features=1) . l1(a1(m1(c1(X))).reshape(12396,-1)) . tensor([[-0.0645], [-0.0081], [-0.0085], ..., [-0.0154], [-0.0199], [-0.1047]], grad_fn=&lt;AddmmBackward&gt;) . - 시그모이드를 걸자. . a2=torch.nn.Sigmoid() a2(l1(a1(m1(c1(X))).reshape(12396,-1))) . tensor([[0.4839], [0.4980], [0.4979], ..., [0.4961], [0.4950], [0.4738]], grad_fn=&lt;SigmoidBackward&gt;) . networks &#49444;&#44228; . net = nn.Sequential( c1, # 컨볼루션(선형) m1, # 맥스풀링(비선형) -- 효과? 이미지를 계층적으로 파악할 수 있게함 a1, # 렐루(비선형) a1(m1(c1(X))).reshape(12396,-1), ## 이걸 구현해야하는데?? l1) ## 마지막의 a2(sigmoid)는 생략한다. torch.nn..BCEWithLogitsLoss()에 내장되어 있을것이므로 . TypeError Traceback (most recent call last) /tmp/ipykernel_552020/380748644.py in &lt;module&gt; -&gt; 1 net = nn.Sequential( 2 c1, # 컨볼루션(선형) 3 m1, # 맥스풀링(비선형) -- 효과? 이미지를 계층적으로 파악할 수 있게함 4 a1, # 렐루(비선형) 5 ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/container.py in __init__(self, *args) 87 else: 88 for idx, module in enumerate(args): &gt; 89 self.add_module(str(idx), module) 90 91 def _get_item_by_idx(self, iterator, idx) -&gt; T: ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/module.py in add_module(self, name, module) 370 &#34;&#34;&#34; 371 if not isinstance(module, Module) and module is not None: --&gt; 372 raise TypeError(&#34;{} is not a Module subclass&#34;.format( 373 torch.typename(module))) 374 elif not isinstance(name, torch._six.string_classes): TypeError: torch.FloatTensor is not a Module subclass . net = nn.Sequential( c1, # 컨볼루션(선형) m1, # 맥스풀링(비선형) -- 효과? 이미지를 계층적으로 파악할 수 있게함 a1, # 렐루(비선형) # a1(m1(c1(X))).reshape(12396,-1), ## 이걸 구현해야하는데?? l1) ## 마지막의 a2는 생략한다. torch.nn..BCEWithLogitsLoss()에 내장되어 있을것이므로 . - 결국 주석처리한 부분을 구현해야함. . - c1,m1,a1,l1의 공통점 . 무언가를 상속받는 클래스에서 생성된 인스턴스이다. | forward메소드가 있다. | . - custom layer를 만드는 방법 . torch.nn.Module(=슈퍼클래스)을 상속받아서 클래스를 하나 만든다. | forward 메소드를 정의한다. (다음레이어로 리턴할 값) | . class Flatten(torch.nn.Module): def forward(self,x): return x.reshape(12396,-1) . flatten=Flatten() . flatten(a1(m1(c1(X)))).shape . torch.Size([12396, 2304]) . - 잘 구현이 된 것 같다. 네트워크 설정 완료! . net = nn.Sequential( c1, # 컨볼루션(선형) m1, # 맥스풀링(비선형) -- 효과? 이미지를 계층적으로 파악할 수 있게함 a1, # 렐루(비선형) flatten,# a1(m1(c1(X))).reshape(12396,-1), ## 이걸 구현해야하는데?? l1) ## 마지막의 a2는 생략한다. torch.nn..BCEWithLogitsLoss()에 내장되어 있을것이므로 . - 손실함수와 옵티마이저 정의 . loss_fn=torch.nn.BCEWithLogitsLoss() optimizer= torch.optim.Adam(net.parameters()) . - step1~4 . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(y) plt.plot(a2(yhat.data),&#39;.&#39;) #마지막 시그모이드 취해준다 . [&lt;matplotlib.lines.Line2D at 0x7f4c24334340&gt;] . ypred=a2(yhat.data)&gt;0.5 . sum(ypred==y)/12396 . tensor([0.9927]) . - 좀 더 성능이 좋아졌다. (이미 좋았는데 약간 더 좋아짐) . &#49689;&#51228; . - torch.nn.MaxPool2d(2) 대신 torch.nn.MaxPool2d(3) 을 사용하여 모형을 학습해보고 결과비교 . m2=torch.nn.MaxPool2d(3) #3를 넣어서 24-&gt;8로 바뀜 . X.shape,c1(X).shape, m2(c1(X)).shape, a1(m2(c1(X))).shape . (torch.Size([12396, 1, 28, 28]), torch.Size([12396, 16, 24, 24]), torch.Size([12396, 16, 8, 8]), torch.Size([12396, 16, 8, 8])) . flatten(a1(m2(c1(X)))).shape . torch.Size([12396, 1024]) . 16*8*8 . 1024 . l2=torch.nn.Linear(in_features=1024,out_features=1) . net = nn.Sequential( c1, # 컨볼루션(선형) m2, # 맥스풀링(비선형) -- 효과? 이미지를 계층적으로 파악할 수 있게함 a1, # 렐루(비선형) flatten, l2) ## 마지막의 a2는 생략한다. torch.nn..BCEWithLogitsLoss()에 내장되어 있을것이므로 . loss_fn=torch.nn.BCEWithLogitsLoss() optimizer= torch.optim.Adam(net.parameters()) . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(y) plt.plot(a2(yhat.data),&#39;.&#39;) #마지막 시그모이드 취해준다 . [&lt;matplotlib.lines.Line2D at 0x7f4abc667f70&gt;] . ypred=a2(yhat.data)&gt;0.5 . sum(ypred==y)/12396 . tensor([0.9894]) . 2로 했을 때 보다 성능이 약간 안 좋아졌다. 그림으로는 큰 차이 없어보임.. | .",
            "url": "https://kimha02.github.io/ham/python/2021/10/21/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9421%EC%9D%BC.html",
            "relUrl": "/python/2021/10/21/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9421%EC%9D%BC.html",
            "date": " • Oct 21, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "(6주차) 10월19일",
            "content": ". import torch import matplotlib.pyplot as plt . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . plt.plot(X,y) . [&lt;matplotlib.lines.Line2D at 0x7f40d2438460&gt;] . &#45348;&#53944;&#50892;&#53356; &#49444;&#51221;, &#50741;&#54000;&#47560;&#51060;&#51200;, &#47196;&#49828; . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . &#47784;&#54805;&#54617;&#49845; . for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(X,y) plt.plot(X,yhat.data) . [&lt;matplotlib.lines.Line2D at 0x7f40d032a850&gt;] . 잘못나왓음. | y는 완전 random이기 때문에 다음 값을 예측할 때 가장 합리적인 대답은 0. | 대표적인 overfitting 사례 | . train / validation . 위와 같은 문제를 해결하기 위하여 | 80개는 training, 나머지는 validation | 학습한 걸로 나머지 20개 맞추는 거 확인해보기 | . X1=X[:80] y1=y[:80] X2=X[80:] y2=y[80:] . torch.manual_seed(1) net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . for epoc in range(1000): ## 1 y1hat=net(X1) ## 2 loss=loss_fn(y1hat,y1) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(X,y) plt.plot(X1,net(X1).data,&#39;--r&#39;) plt.plot(X2,net(X2).data,&#39;--g&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f40d02a3310&gt;] . &#46300;&#46989;&#50500;&#50883; . parameter 수가 많아져서 overfitting 현상때문에 위와 같은 현상이 나타남 | 변수를 줄이자는 아이디어 -&gt; 드랍아웃 | . X1=X[:80] y1=y[:80] X2=X[80:] y2=y[80:] . Dropout을 0.8로 줘서 들어온 변수 중 80%가 0으로 출력되게 함 | . torch.manual_seed(1) net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Dropout(0.8), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . for epoc in range(1000): ## 1 y1hat=net(X1) ## 2 loss=loss_fn(y1hat,y1) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(X,y) plt.plot(X1,net(X1).data,&#39;--r&#39;) plt.plot(X2,net(X2).data,&#39;--g&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f40d002d340&gt;] . 학습을 할 때는 드랍아웃으로 노드?를 날렸다 -&gt; 그 노드는 학습을 멈춤 | 에폭마다 20%의 노드만 학습이 되는 것 -&gt; 좋은 노드들만 업데이트가 되는 것임 | 평가를 할 때는 임의로 0을 만들 필요가 없음 -&gt; 모든 weight를 사용하여야 함 | . net.eval() ## 네트워크를 평가모드로 전환_evaluation plt.plot(X,y) plt.plot(X1,net(X1).data,&#39;--r&#39;) plt.plot(X2,net(X2).data,&#39;--g&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f40b7f9c220&gt;] . 그런데 학습한 것만 보면 두 그래프 중 무엇이 더 좋은지 말하기 힘들다 -&gt; 첫번째는 오버피팅, 두번째는 언더피팅하는 것처럼 보여서 | . &#54617;&#49845;&#44284;&#51221; &#48708;&#44368; (&#51452;&#51032;: &#53076;&#46300;&#48373;&#51105;&#54632;) . - 데이터 생성 . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1) . - tr/val 분리 . X_tr=X[:80] y_tr=y[:80] X_val=X[80:] y_val=y[80:] . - 네트워크, 옵티마이저, 손실함수 설정 . 드랍아웃을 이용한 네트워크 (net2)와 그렇지 않은 네트워크 (net1) | 대응하는 옵티마이저 1,2 설정 | 손실함수 | . torch.manual_seed(1) net1=torch.nn.Sequential( torch.nn.Linear(1,512), torch.nn.ReLU(), torch.nn.Linear(512,1)) optimizer_net1 = torch.optim.Adam(net1.parameters()) net2=torch.nn.Sequential( torch.nn.Linear(1,512), torch.nn.ReLU(), torch.nn.Dropout(0.8), torch.nn.Linear(512,1)) optimizer_net2 = torch.optim.Adam(net2.parameters()) loss_fn=torch.nn.MSELoss() . 시뮬레이션 결과를 저장하기 위한 공간을 만들자 | . tr_loss_net1=[] val_loss_net1=[] tr_loss_net2=[] val_loss_net2=[] . net1을 학습시켜보자 | . for epoc in range(1000): ## 1 yhat_tr_net1 = net1(X_tr) ## 2 loss_tr = loss_fn(yhat_tr_net1, y_tr) ## 3 loss_tr.backward() ## 4 optimizer_net1.step() net1.zero_grad() ## 5 기록 ### tr tr_loss_net1.append(loss_tr.item()) ### val yhat_val_net1 = net1(X_val) loss_val = loss_fn(yhat_val_net1,y_val) val_loss_net1.append(loss_val.item()) . net2를 학습시켜보자 | . for epoc in range(1000): ## 1 yhat_tr_net2 = net2(X_tr) ## 2 loss_tr = loss_fn(yhat_tr_net2, y_tr) ## 3 loss_tr.backward() ## 4 optimizer_net2.step() net2.zero_grad() ## 5 기록 ### tr net2.eval() #net2는 드랍아웃 시켰으니까 넣어줘야 해! tr_loss_net2.append(loss_tr.item()) ### val yhat_val_net2 = net2(X_val) loss_val = loss_fn(yhat_val_net2,y_val) val_loss_net2.append(loss_val.item()) net2.train() . net2.eval() fig , ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) ax1.plot(X,y,&#39;.&#39;);ax1.plot(X_tr,net1(X_tr).data); ax1.plot(X_val,net1(X_val).data); ax2.plot(X,y,&#39;.&#39;);ax2.plot(X_tr,net2(X_tr).data); ax2.plot(X_val,net2(X_val).data); ax3.plot(tr_loss_net1);ax3.plot(val_loss_net1); ax4.plot(tr_loss_net2);ax4.plot(val_loss_net2); . 다음에 기억을 잘 할 수 있게 코드를 각각 정리해주면net2.eval() #드랍아웃 쓴 net2 평가모드로 fig , ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) #그래프 그릴 창 만들어주고 ax1.plot(X,y,&#39;.&#39;);ax1.plot(X_tr,net1(X_tr).data); #주황색 선 그리기 ax1.plot(X_val,net1(X_val).data); #초록색 선 그리기 ax2.plot(X,y,&#39;.&#39;);ax2.plot(X_tr,net2(X_tr).data); #주황색 선 그리기 ax2.plot(X_val,net2(X_val).data); #초록색 선 그리기 : 합리적인 추론(=0)에 근사한 예측치를 보여준다(net1에 비해서) ax3.plot(tr_loss_net1);ax3.plot(val_loss_net1); #net1 loss 관찰 : tr_loss(파란선)은 줄어드는 모습, 주황선은 우리가 보지 못한 데이터에 대한 것인데 줄어들다가 증가하는 모습을 보임-&gt;과적합, 어느 순간부터 제대로 학습이 되지 않고 있음 ax4.plot(tr_loss_net2);ax4.plot(val_loss_net2); #net2 loss 관찰 : tr_loss(파란선)은 줄어드는 모습, 주황선은 우리가 보지 못한 데이터에 대한 것인데 감소하는 모습을 보임 . | . fig , ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) ax1.plot(X,y,&#39;.&#39;);ax1.plot(X_tr,net1(X_tr).data); ax1.plot(X_val,net1(X_val).data); ax2.plot(X,y,&#39;.&#39;);ax2.plot(X_tr,net2(X_tr).data); ax2.plot(X_val,net2(X_val).data); ax3.plot(tr_loss_net1);ax3.plot(val_loss_net1); ax4.plot(tr_loss_net2);ax4.plot(val_loss_net2); . - 다 좋은데 코드를 짜는것이 너무 힘들다. . 생각해보니까 미니배치도 만들어야 함 + 미니배치를 나눈상태에서 GPU 메모리에 파라메터도 올려야함. | 조기종료(val_loss가 다시 증가하기 전에 감소)와 같은 기능도 구현해야함 + 기타등등을 구현해야함. | 나중에는 학습률을 서로 다르게 돌려가며 결과도 기록해야함 $ to$ 그래야 좋은 학습률 선택가능 | for문안에 step1~step4를 넣는것도 너무 반복작업임. | 등등.. | . - 위와 같은 것들의 특징: 머리로 상상하기는 쉽지만 실제 구현하는 것은 까다롭다. . - 사실 우리가 하고싶은것 . 아키텍처를 설계: 데이터를 보고 맞춰서 설계해야할 때가 많음 (우리가 해야한다) | 손실함수: 통계학과 교수님들이 연구하심 | 옵티마이저: 산공교수님들이 연구하심 | . - 제 생각 . 기업의욕심: read-data를 분석하는 딥러닝 아키텍처 설계 $ to$ 아키텍처별로 결과를 관찰 (편하게) $ Longrightarrow$ fastai + read data | 학생의욕심: 그러면서도 모형이 돌아가는 원리는 아주 세밀하게 알고싶음 $ Longrightarrow$ pytorch + toy example (regression 등을 위주로) | 연구자의욕심: 기존의 모형을 조금 변경해서 쓰고싶음 $ Longrightarrow$ (pytorch +fastai) + any data | . - tensorflow + keras vs pytorch + fastai . pytorch + fastai . - 데이터셋을 만든다. . X_tr=X[:80] y_tr=y[:80] X_val=X[80:] y_val=y[80:] . ds1=torch.utils.data.TensorDataset(X_tr,y_tr) ds2=torch.utils.data.TensorDataset(X_val,y_val) . - 데이터로더를 만든다. . dl1 = torch.utils.data.DataLoader(ds1, batch_size=80) dl2 = torch.utils.data.DataLoader(ds2, batch_size=20) . - 데이터로더스(데이터로더의 집합)를 만든다. . from fastai.vision.all import * . dls=DataLoaders(dl1,dl2) . &#46300;&#46989;&#50500;&#50883; &#51228;&#50808;&#48260;&#51204; . - 네트워크 설계 (드랍아웃 제외) . torch.manual_seed(1) net_fastai = torch.nn.Sequential( torch.nn.Linear(in_features=1, out_features=512), torch.nn.ReLU(), #torch.nn.Dropout(0.8), torch.nn.Linear(in_features=512, out_features=1)) #optimizer loss_fn=torch.nn.MSELoss() . - 러너오브젝트 (for문 대신돌려주는 오브젝트) . lrnr= Learner(dls,net_fastai,opt_func=Adam,loss_func=loss_fn) . - 에폭만 설정하고 바로 학습 . lrnr.fit(1000) . epoch train_loss valid_loss time . 0 | 1.277156 | 0.491314 | 00:00 | . 1 | 1.277145 | 0.455286 | 00:00 | . 2 | 1.275104 | 0.444275 | 00:00 | . 3 | 1.274429 | 0.465787 | 00:00 | . 4 | 1.273436 | 0.507203 | 00:00 | . 5 | 1.272421 | 0.548102 | 00:00 | . 6 | 1.271840 | 0.561292 | 00:00 | . 7 | 1.271377 | 0.549409 | 00:00 | . 8 | 1.270855 | 0.530416 | 00:00 | . 9 | 1.270437 | 0.520700 | 00:00 | . 10 | 1.270176 | 0.526273 | 00:00 | . 11 | 1.269935 | 0.543579 | 00:00 | . 12 | 1.269655 | 0.562939 | 00:00 | . 13 | 1.269411 | 0.571586 | 00:00 | . 14 | 1.269217 | 0.563700 | 00:00 | . 15 | 1.269018 | 0.543646 | 00:00 | . 16 | 1.268787 | 0.521385 | 00:00 | . 17 | 1.268563 | 0.505799 | 00:00 | . 18 | 1.268362 | 0.500011 | 00:00 | . 19 | 1.268159 | 0.501830 | 00:00 | . 20 | 1.267941 | 0.506255 | 00:00 | . 21 | 1.267730 | 0.506739 | 00:00 | . 22 | 1.267540 | 0.499733 | 00:00 | . 23 | 1.267353 | 0.487385 | 00:00 | . 24 | 1.267163 | 0.474839 | 00:00 | . 25 | 1.266981 | 0.466926 | 00:00 | . 26 | 1.266814 | 0.465347 | 00:00 | . 27 | 1.266648 | 0.468656 | 00:00 | . 28 | 1.266480 | 0.473641 | 00:00 | . 29 | 1.266316 | 0.476266 | 00:00 | . 30 | 1.266156 | 0.474677 | 00:00 | . 31 | 1.265996 | 0.469958 | 00:00 | . 32 | 1.265833 | 0.465630 | 00:00 | . 33 | 1.265673 | 0.464544 | 00:00 | . 34 | 1.265514 | 0.467181 | 00:00 | . 35 | 1.265355 | 0.472571 | 00:00 | . 36 | 1.265194 | 0.477105 | 00:00 | . 37 | 1.265037 | 0.478357 | 00:00 | . 38 | 1.264880 | 0.475766 | 00:00 | . 39 | 1.264724 | 0.471696 | 00:00 | . 40 | 1.264569 | 0.469089 | 00:00 | . 41 | 1.264416 | 0.469158 | 00:00 | . 42 | 1.264262 | 0.471343 | 00:00 | . 43 | 1.264108 | 0.472992 | 00:00 | . 44 | 1.263955 | 0.471979 | 00:00 | . 45 | 1.263801 | 0.468276 | 00:00 | . 46 | 1.263646 | 0.463477 | 00:00 | . 47 | 1.263491 | 0.460086 | 00:00 | . 48 | 1.263336 | 0.458932 | 00:00 | . 49 | 1.263181 | 0.459443 | 00:00 | . 50 | 1.263025 | 0.459690 | 00:00 | . 51 | 1.262869 | 0.457996 | 00:00 | . 52 | 1.262714 | 0.454969 | 00:00 | . 53 | 1.262558 | 0.451982 | 00:00 | . 54 | 1.262402 | 0.450564 | 00:00 | . 55 | 1.262247 | 0.450934 | 00:00 | . 56 | 1.262090 | 0.451861 | 00:00 | . 57 | 1.261933 | 0.451914 | 00:00 | . 58 | 1.261776 | 0.450721 | 00:00 | . 59 | 1.261619 | 0.448978 | 00:00 | . 60 | 1.261461 | 0.447796 | 00:00 | . 61 | 1.261303 | 0.448038 | 00:00 | . 62 | 1.261144 | 0.448761 | 00:00 | . 63 | 1.260986 | 0.449142 | 00:00 | . 64 | 1.260826 | 0.448443 | 00:00 | . 65 | 1.260667 | 0.446837 | 00:00 | . 66 | 1.260507 | 0.445661 | 00:00 | . 67 | 1.260347 | 0.445344 | 00:00 | . 68 | 1.260187 | 0.445592 | 00:00 | . 69 | 1.260026 | 0.445488 | 00:00 | . 70 | 1.259866 | 0.444427 | 00:00 | . 71 | 1.259705 | 0.442824 | 00:00 | . 72 | 1.259543 | 0.441615 | 00:00 | . 73 | 1.259382 | 0.441126 | 00:00 | . 74 | 1.259220 | 0.441023 | 00:00 | . 75 | 1.259058 | 0.440497 | 00:00 | . 76 | 1.258896 | 0.439592 | 00:00 | . 77 | 1.258733 | 0.438460 | 00:00 | . 78 | 1.258569 | 0.437588 | 00:00 | . 79 | 1.258405 | 0.437321 | 00:00 | . 80 | 1.258241 | 0.437219 | 00:00 | . 81 | 1.258077 | 0.436916 | 00:00 | . 82 | 1.257912 | 0.435913 | 00:00 | . 83 | 1.257747 | 0.435003 | 00:00 | . 84 | 1.257582 | 0.434601 | 00:00 | . 85 | 1.257416 | 0.434494 | 00:00 | . 86 | 1.257249 | 0.434309 | 00:00 | . 87 | 1.257081 | 0.433745 | 00:00 | . 88 | 1.256913 | 0.432914 | 00:00 | . 89 | 1.256744 | 0.432331 | 00:00 | . 90 | 1.256575 | 0.432165 | 00:00 | . 91 | 1.256406 | 0.432003 | 00:00 | . 92 | 1.256236 | 0.431670 | 00:00 | . 93 | 1.256065 | 0.430937 | 00:00 | . 94 | 1.255894 | 0.430317 | 00:00 | . 95 | 1.255723 | 0.429924 | 00:00 | . 96 | 1.255550 | 0.429707 | 00:00 | . 97 | 1.255377 | 0.429296 | 00:00 | . 98 | 1.255203 | 0.428846 | 00:00 | . 99 | 1.255029 | 0.428160 | 00:00 | . 100 | 1.254854 | 0.427743 | 00:00 | . 101 | 1.254679 | 0.427369 | 00:00 | . 102 | 1.254504 | 0.426952 | 00:00 | . 103 | 1.254328 | 0.426511 | 00:00 | . 104 | 1.254151 | 0.426140 | 00:00 | . 105 | 1.253973 | 0.425836 | 00:00 | . 106 | 1.253796 | 0.425516 | 00:00 | . 107 | 1.253617 | 0.425156 | 00:00 | . 108 | 1.253438 | 0.424890 | 00:00 | . 109 | 1.253259 | 0.424599 | 00:00 | . 110 | 1.253079 | 0.424250 | 00:00 | . 111 | 1.252898 | 0.423973 | 00:00 | . 112 | 1.252717 | 0.423872 | 00:00 | . 113 | 1.252535 | 0.423620 | 00:00 | . 114 | 1.252353 | 0.423358 | 00:00 | . 115 | 1.252170 | 0.422883 | 00:00 | . 116 | 1.251987 | 0.422549 | 00:00 | . 117 | 1.251803 | 0.422482 | 00:00 | . 118 | 1.251619 | 0.422277 | 00:00 | . 119 | 1.251435 | 0.421926 | 00:00 | . 120 | 1.251249 | 0.421529 | 00:00 | . 121 | 1.251063 | 0.421358 | 00:00 | . 122 | 1.250877 | 0.421251 | 00:00 | . 123 | 1.250690 | 0.421048 | 00:00 | . 124 | 1.250502 | 0.420763 | 00:00 | . 125 | 1.250314 | 0.420404 | 00:00 | . 126 | 1.250125 | 0.420322 | 00:00 | . 127 | 1.249936 | 0.420242 | 00:00 | . 128 | 1.249746 | 0.420147 | 00:00 | . 129 | 1.249556 | 0.419852 | 00:00 | . 130 | 1.249366 | 0.419579 | 00:00 | . 131 | 1.249175 | 0.419527 | 00:00 | . 132 | 1.248984 | 0.419416 | 00:00 | . 133 | 1.248792 | 0.419148 | 00:00 | . 134 | 1.248599 | 0.418997 | 00:00 | . 135 | 1.248406 | 0.418859 | 00:00 | . 136 | 1.248212 | 0.418857 | 00:00 | . 137 | 1.248018 | 0.418830 | 00:00 | . 138 | 1.247823 | 0.418669 | 00:00 | . 139 | 1.247628 | 0.418535 | 00:00 | . 140 | 1.247432 | 0.418488 | 00:00 | . 141 | 1.247236 | 0.418400 | 00:00 | . 142 | 1.247040 | 0.418214 | 00:00 | . 143 | 1.246843 | 0.417942 | 00:00 | . 144 | 1.246645 | 0.417894 | 00:00 | . 145 | 1.246448 | 0.417886 | 00:00 | . 146 | 1.246250 | 0.417820 | 00:00 | . 147 | 1.246051 | 0.417744 | 00:00 | . 148 | 1.245852 | 0.417791 | 00:00 | . 149 | 1.245651 | 0.417857 | 00:00 | . 150 | 1.245451 | 0.417884 | 00:00 | . 151 | 1.245250 | 0.417780 | 00:00 | . 152 | 1.245049 | 0.417736 | 00:00 | . 153 | 1.244848 | 0.417721 | 00:00 | . 154 | 1.244646 | 0.417662 | 00:00 | . 155 | 1.244443 | 0.417639 | 00:00 | . 156 | 1.244240 | 0.417623 | 00:00 | . 157 | 1.244037 | 0.417599 | 00:00 | . 158 | 1.243833 | 0.417624 | 00:00 | . 159 | 1.243629 | 0.417713 | 00:00 | . 160 | 1.243424 | 0.417719 | 00:00 | . 161 | 1.243219 | 0.417705 | 00:00 | . 162 | 1.243013 | 0.417843 | 00:00 | . 163 | 1.242807 | 0.417914 | 00:00 | . 164 | 1.242601 | 0.417929 | 00:00 | . 165 | 1.242394 | 0.417990 | 00:00 | . 166 | 1.242187 | 0.418116 | 00:00 | . 167 | 1.241980 | 0.418189 | 00:00 | . 168 | 1.241772 | 0.418205 | 00:00 | . 169 | 1.241564 | 0.418334 | 00:00 | . 170 | 1.241355 | 0.418501 | 00:00 | . 171 | 1.241146 | 0.418554 | 00:00 | . 172 | 1.240937 | 0.418608 | 00:00 | . 173 | 1.240727 | 0.418772 | 00:00 | . 174 | 1.240517 | 0.418854 | 00:00 | . 175 | 1.240307 | 0.418996 | 00:00 | . 176 | 1.240097 | 0.419114 | 00:00 | . 177 | 1.239886 | 0.419256 | 00:00 | . 178 | 1.239675 | 0.419356 | 00:00 | . 179 | 1.239463 | 0.419527 | 00:00 | . 180 | 1.239251 | 0.419626 | 00:00 | . 181 | 1.239039 | 0.419796 | 00:00 | . 182 | 1.238827 | 0.419984 | 00:00 | . 183 | 1.238615 | 0.420269 | 00:00 | . 184 | 1.238402 | 0.420389 | 00:00 | . 185 | 1.238188 | 0.420558 | 00:00 | . 186 | 1.237974 | 0.420761 | 00:00 | . 187 | 1.237759 | 0.420946 | 00:00 | . 188 | 1.237545 | 0.421110 | 00:00 | . 189 | 1.237331 | 0.421286 | 00:00 | . 190 | 1.237115 | 0.421507 | 00:00 | . 191 | 1.236900 | 0.421727 | 00:00 | . 192 | 1.236684 | 0.421919 | 00:00 | . 193 | 1.236467 | 0.422220 | 00:00 | . 194 | 1.236251 | 0.422527 | 00:00 | . 195 | 1.236034 | 0.422738 | 00:00 | . 196 | 1.235817 | 0.422963 | 00:00 | . 197 | 1.235600 | 0.423270 | 00:00 | . 198 | 1.235382 | 0.423566 | 00:00 | . 199 | 1.235164 | 0.423725 | 00:00 | . 200 | 1.234946 | 0.423986 | 00:00 | . 201 | 1.234727 | 0.424333 | 00:00 | . 202 | 1.234508 | 0.424390 | 00:00 | . 203 | 1.234289 | 0.424699 | 00:00 | . 204 | 1.234070 | 0.425270 | 00:00 | . 205 | 1.233850 | 0.425272 | 00:00 | . 206 | 1.233630 | 0.425684 | 00:00 | . 207 | 1.233410 | 0.426120 | 00:00 | . 208 | 1.233190 | 0.426429 | 00:00 | . 209 | 1.232970 | 0.426418 | 00:00 | . 210 | 1.232749 | 0.427115 | 00:00 | . 211 | 1.232528 | 0.427216 | 00:00 | . 212 | 1.232306 | 0.427429 | 00:00 | . 213 | 1.232085 | 0.427920 | 00:00 | . 214 | 1.231864 | 0.428236 | 00:00 | . 215 | 1.231642 | 0.428453 | 00:00 | . 216 | 1.231421 | 0.428856 | 00:00 | . 217 | 1.231198 | 0.429515 | 00:00 | . 218 | 1.230976 | 0.429647 | 00:00 | . 219 | 1.230753 | 0.430105 | 00:00 | . 220 | 1.230530 | 0.430761 | 00:00 | . 221 | 1.230307 | 0.430849 | 00:00 | . 222 | 1.230084 | 0.431280 | 00:00 | . 223 | 1.229861 | 0.431862 | 00:00 | . 224 | 1.229637 | 0.432191 | 00:00 | . 225 | 1.229413 | 0.432374 | 00:00 | . 226 | 1.229189 | 0.433027 | 00:00 | . 227 | 1.228966 | 0.433583 | 00:00 | . 228 | 1.228741 | 0.433802 | 00:00 | . 229 | 1.228517 | 0.434520 | 00:00 | . 230 | 1.228293 | 0.435066 | 00:00 | . 231 | 1.228068 | 0.435148 | 00:00 | . 232 | 1.227843 | 0.435727 | 00:00 | . 233 | 1.227618 | 0.436116 | 00:00 | . 234 | 1.227393 | 0.435958 | 00:00 | . 235 | 1.227168 | 0.436991 | 00:00 | . 236 | 1.226943 | 0.437511 | 00:00 | . 237 | 1.226718 | 0.438006 | 00:00 | . 238 | 1.226493 | 0.438966 | 00:00 | . 239 | 1.226267 | 0.439815 | 00:00 | . 240 | 1.226041 | 0.439775 | 00:00 | . 241 | 1.225815 | 0.440939 | 00:00 | . 242 | 1.225590 | 0.440882 | 00:00 | . 243 | 1.225363 | 0.440836 | 00:00 | . 244 | 1.225137 | 0.441480 | 00:00 | . 245 | 1.224910 | 0.441281 | 00:00 | . 246 | 1.224684 | 0.442244 | 00:00 | . 247 | 1.224457 | 0.442685 | 00:00 | . 248 | 1.224231 | 0.443636 | 00:00 | . 249 | 1.224004 | 0.444059 | 00:00 | . 250 | 1.223777 | 0.444930 | 00:00 | . 251 | 1.223551 | 0.445588 | 00:00 | . 252 | 1.223324 | 0.446594 | 00:00 | . 253 | 1.223097 | 0.446623 | 00:00 | . 254 | 1.222870 | 0.447728 | 00:00 | . 255 | 1.222642 | 0.447877 | 00:00 | . 256 | 1.222415 | 0.448117 | 00:00 | . 257 | 1.222188 | 0.449032 | 00:00 | . 258 | 1.221961 | 0.449322 | 00:00 | . 259 | 1.221733 | 0.449238 | 00:00 | . 260 | 1.221505 | 0.451040 | 00:00 | . 261 | 1.221278 | 0.450359 | 00:00 | . 262 | 1.221051 | 0.452112 | 00:00 | . 263 | 1.220824 | 0.452225 | 00:00 | . 264 | 1.220597 | 0.453696 | 00:00 | . 265 | 1.220369 | 0.454094 | 00:00 | . 266 | 1.220141 | 0.454912 | 00:00 | . 267 | 1.219914 | 0.455107 | 00:00 | . 268 | 1.219687 | 0.455415 | 00:00 | . 269 | 1.219459 | 0.455917 | 00:00 | . 270 | 1.219232 | 0.456291 | 00:00 | . 271 | 1.219005 | 0.457516 | 00:00 | . 272 | 1.218778 | 0.458215 | 00:00 | . 273 | 1.218550 | 0.459798 | 00:00 | . 274 | 1.218323 | 0.460129 | 00:00 | . 275 | 1.218096 | 0.461005 | 00:00 | . 276 | 1.217869 | 0.460792 | 00:00 | . 277 | 1.217642 | 0.461096 | 00:00 | . 278 | 1.217414 | 0.460790 | 00:00 | . 279 | 1.217186 | 0.462483 | 00:00 | . 280 | 1.216958 | 0.462127 | 00:00 | . 281 | 1.216730 | 0.466005 | 00:00 | . 282 | 1.216504 | 0.464130 | 00:00 | . 283 | 1.216277 | 0.469921 | 00:00 | . 284 | 1.216050 | 0.463971 | 00:00 | . 285 | 1.215824 | 0.471405 | 00:00 | . 286 | 1.215599 | 0.463746 | 00:00 | . 287 | 1.215374 | 0.471046 | 00:00 | . 288 | 1.215147 | 0.466031 | 00:00 | . 289 | 1.214920 | 0.469181 | 00:00 | . 290 | 1.214693 | 0.471406 | 00:00 | . 291 | 1.214465 | 0.469302 | 00:00 | . 292 | 1.214239 | 0.475704 | 00:00 | . 293 | 1.214013 | 0.471744 | 00:00 | . 294 | 1.213787 | 0.475277 | 00:00 | . 295 | 1.213560 | 0.475393 | 00:00 | . 296 | 1.213333 | 0.472734 | 00:00 | . 297 | 1.213107 | 0.477125 | 00:00 | . 298 | 1.212881 | 0.474237 | 00:00 | . 299 | 1.212655 | 0.477554 | 00:00 | . 300 | 1.212428 | 0.477674 | 00:00 | . 301 | 1.212203 | 0.478424 | 00:00 | . 302 | 1.211978 | 0.481764 | 00:00 | . 303 | 1.211752 | 0.479665 | 00:00 | . 304 | 1.211527 | 0.483109 | 00:00 | . 305 | 1.211300 | 0.481590 | 00:00 | . 306 | 1.211075 | 0.482610 | 00:00 | . 307 | 1.210849 | 0.484192 | 00:00 | . 308 | 1.210624 | 0.482331 | 00:00 | . 309 | 1.210399 | 0.487119 | 00:00 | . 310 | 1.210175 | 0.483336 | 00:00 | . 311 | 1.209951 | 0.488953 | 00:00 | . 312 | 1.209726 | 0.486667 | 00:00 | . 313 | 1.209502 | 0.489473 | 00:00 | . 314 | 1.209278 | 0.490365 | 00:00 | . 315 | 1.209055 | 0.488710 | 00:00 | . 316 | 1.208831 | 0.493933 | 00:00 | . 317 | 1.208609 | 0.488504 | 00:00 | . 318 | 1.208385 | 0.495865 | 00:00 | . 319 | 1.208164 | 0.490756 | 00:00 | . 320 | 1.207942 | 0.495374 | 00:00 | . 321 | 1.207719 | 0.495526 | 00:00 | . 322 | 1.207496 | 0.493535 | 00:00 | . 323 | 1.207274 | 0.500878 | 00:00 | . 324 | 1.207053 | 0.492885 | 00:00 | . 325 | 1.206832 | 0.502528 | 00:00 | . 326 | 1.206610 | 0.497001 | 00:00 | . 327 | 1.206388 | 0.499801 | 00:00 | . 328 | 1.206167 | 0.504342 | 00:00 | . 329 | 1.205946 | 0.498521 | 00:00 | . 330 | 1.205726 | 0.507436 | 00:00 | . 331 | 1.205506 | 0.502286 | 00:00 | . 332 | 1.205286 | 0.504370 | 00:00 | . 333 | 1.205066 | 0.506807 | 00:00 | . 334 | 1.204845 | 0.502806 | 00:00 | . 335 | 1.204626 | 0.508645 | 00:00 | . 336 | 1.204406 | 0.505454 | 00:00 | . 337 | 1.204187 | 0.507372 | 00:00 | . 338 | 1.203967 | 0.511078 | 00:00 | . 339 | 1.203748 | 0.508682 | 00:00 | . 340 | 1.203528 | 0.515019 | 00:00 | . 341 | 1.203309 | 0.511679 | 00:00 | . 342 | 1.203090 | 0.515847 | 00:00 | . 343 | 1.202872 | 0.514210 | 00:00 | . 344 | 1.202654 | 0.513550 | 00:00 | . 345 | 1.202437 | 0.517338 | 00:00 | . 346 | 1.202219 | 0.513895 | 00:00 | . 347 | 1.202002 | 0.518733 | 00:00 | . 348 | 1.201786 | 0.517710 | 00:00 | . 349 | 1.201569 | 0.519124 | 00:00 | . 350 | 1.201353 | 0.523362 | 00:00 | . 351 | 1.201136 | 0.521150 | 00:00 | . 352 | 1.200921 | 0.526446 | 00:00 | . 353 | 1.200706 | 0.522027 | 00:00 | . 354 | 1.200491 | 0.526017 | 00:00 | . 355 | 1.200276 | 0.522019 | 00:00 | . 356 | 1.200061 | 0.525617 | 00:00 | . 357 | 1.199846 | 0.524996 | 00:00 | . 358 | 1.199632 | 0.526826 | 00:00 | . 359 | 1.199418 | 0.530623 | 00:00 | . 360 | 1.199204 | 0.529384 | 00:00 | . 361 | 1.198991 | 0.534076 | 00:00 | . 362 | 1.198778 | 0.529402 | 00:00 | . 363 | 1.198565 | 0.536225 | 00:00 | . 364 | 1.198352 | 0.531828 | 00:00 | . 365 | 1.198140 | 0.536218 | 00:00 | . 366 | 1.197927 | 0.537211 | 00:00 | . 367 | 1.197714 | 0.535652 | 00:00 | . 368 | 1.197502 | 0.542194 | 00:00 | . 369 | 1.197290 | 0.534898 | 00:00 | . 370 | 1.197079 | 0.546001 | 00:00 | . 371 | 1.196868 | 0.534406 | 00:00 | . 372 | 1.196657 | 0.546841 | 00:00 | . 373 | 1.196448 | 0.538652 | 00:00 | . 374 | 1.196237 | 0.543475 | 00:00 | . 375 | 1.196027 | 0.545992 | 00:00 | . 376 | 1.195816 | 0.540382 | 00:00 | . 377 | 1.195607 | 0.551180 | 00:00 | . 378 | 1.195398 | 0.543836 | 00:00 | . 379 | 1.195188 | 0.549081 | 00:00 | . 380 | 1.194979 | 0.552940 | 00:00 | . 381 | 1.194771 | 0.546051 | 00:00 | . 382 | 1.194563 | 0.556583 | 00:00 | . 383 | 1.194356 | 0.547764 | 00:00 | . 384 | 1.194149 | 0.554733 | 00:00 | . 385 | 1.193941 | 0.554931 | 00:00 | . 386 | 1.193734 | 0.551797 | 00:00 | . 387 | 1.193528 | 0.559369 | 00:00 | . 388 | 1.193321 | 0.554356 | 00:00 | . 389 | 1.193116 | 0.557717 | 00:00 | . 390 | 1.192910 | 0.559447 | 00:00 | . 391 | 1.192706 | 0.555653 | 00:00 | . 392 | 1.192500 | 0.563805 | 00:00 | . 393 | 1.192295 | 0.556521 | 00:00 | . 394 | 1.192092 | 0.564368 | 00:00 | . 395 | 1.191887 | 0.561668 | 00:00 | . 396 | 1.191683 | 0.560722 | 00:00 | . 397 | 1.191478 | 0.567270 | 00:00 | . 398 | 1.191274 | 0.559664 | 00:00 | . 399 | 1.191071 | 0.569009 | 00:00 | . 400 | 1.190868 | 0.563938 | 00:00 | . 401 | 1.190666 | 0.567402 | 00:00 | . 402 | 1.190463 | 0.573133 | 00:00 | . 403 | 1.190261 | 0.566651 | 00:00 | . 404 | 1.190060 | 0.576093 | 00:00 | . 405 | 1.189860 | 0.567995 | 00:00 | . 406 | 1.189659 | 0.571855 | 00:00 | . 407 | 1.189458 | 0.574249 | 00:00 | . 408 | 1.189258 | 0.569290 | 00:00 | . 409 | 1.189058 | 0.579131 | 00:00 | . 410 | 1.188859 | 0.572503 | 00:00 | . 411 | 1.188658 | 0.578302 | 00:00 | . 412 | 1.188460 | 0.576851 | 00:00 | . 413 | 1.188261 | 0.573910 | 00:00 | . 414 | 1.188061 | 0.581201 | 00:00 | . 415 | 1.187863 | 0.573142 | 00:00 | . 416 | 1.187665 | 0.583227 | 00:00 | . 417 | 1.187467 | 0.580256 | 00:00 | . 418 | 1.187269 | 0.582546 | 00:00 | . 419 | 1.187071 | 0.586348 | 00:00 | . 420 | 1.186874 | 0.579812 | 00:00 | . 421 | 1.186677 | 0.589364 | 00:00 | . 422 | 1.186480 | 0.580780 | 00:00 | . 423 | 1.186284 | 0.589222 | 00:00 | . 424 | 1.186088 | 0.587141 | 00:00 | . 425 | 1.185891 | 0.589203 | 00:00 | . 426 | 1.185696 | 0.591853 | 00:00 | . 427 | 1.185501 | 0.588281 | 00:00 | . 428 | 1.185305 | 0.593388 | 00:00 | . 429 | 1.185110 | 0.589403 | 00:00 | . 430 | 1.184916 | 0.595557 | 00:00 | . 431 | 1.184721 | 0.592521 | 00:00 | . 432 | 1.184529 | 0.601984 | 00:00 | . 433 | 1.184336 | 0.594591 | 00:00 | . 434 | 1.184142 | 0.605421 | 00:00 | . 435 | 1.183950 | 0.596454 | 00:00 | . 436 | 1.183757 | 0.604492 | 00:00 | . 437 | 1.183564 | 0.599748 | 00:00 | . 438 | 1.183372 | 0.601403 | 00:00 | . 439 | 1.183180 | 0.605842 | 00:00 | . 440 | 1.182988 | 0.603062 | 00:00 | . 441 | 1.182797 | 0.611140 | 00:00 | . 442 | 1.182606 | 0.604043 | 00:00 | . 443 | 1.182416 | 0.611879 | 00:00 | . 444 | 1.182226 | 0.604252 | 00:00 | . 445 | 1.182036 | 0.611922 | 00:00 | . 446 | 1.181846 | 0.607113 | 00:00 | . 447 | 1.181655 | 0.612432 | 00:00 | . 448 | 1.181467 | 0.613410 | 00:00 | . 449 | 1.181278 | 0.613533 | 00:00 | . 450 | 1.181088 | 0.619271 | 00:00 | . 451 | 1.180901 | 0.614651 | 00:00 | . 452 | 1.180712 | 0.623310 | 00:00 | . 453 | 1.180524 | 0.613269 | 00:00 | . 454 | 1.180337 | 0.624101 | 00:00 | . 455 | 1.180150 | 0.612796 | 00:00 | . 456 | 1.179964 | 0.625325 | 00:00 | . 457 | 1.179777 | 0.617129 | 00:00 | . 458 | 1.179590 | 0.625354 | 00:00 | . 459 | 1.179404 | 0.621866 | 00:00 | . 460 | 1.179218 | 0.624785 | 00:00 | . 461 | 1.179033 | 0.626110 | 00:00 | . 462 | 1.178848 | 0.625076 | 00:00 | . 463 | 1.178664 | 0.628602 | 00:00 | . 464 | 1.178480 | 0.628231 | 00:00 | . 465 | 1.178295 | 0.629565 | 00:00 | . 466 | 1.178110 | 0.634869 | 00:00 | . 467 | 1.177927 | 0.628839 | 00:00 | . 468 | 1.177743 | 0.639646 | 00:00 | . 469 | 1.177561 | 0.628106 | 00:00 | . 470 | 1.177379 | 0.642643 | 00:00 | . 471 | 1.177198 | 0.626533 | 00:00 | . 472 | 1.177018 | 0.645775 | 00:00 | . 473 | 1.176837 | 0.630790 | 00:00 | . 474 | 1.176656 | 0.645833 | 00:00 | . 475 | 1.176476 | 0.639144 | 00:00 | . 476 | 1.176294 | 0.642675 | 00:00 | . 477 | 1.176114 | 0.644251 | 00:00 | . 478 | 1.175933 | 0.639224 | 00:00 | . 479 | 1.175753 | 0.646021 | 00:00 | . 480 | 1.175574 | 0.638502 | 00:00 | . 481 | 1.175395 | 0.648855 | 00:00 | . 482 | 1.175216 | 0.641207 | 00:00 | . 483 | 1.175039 | 0.651341 | 00:00 | . 484 | 1.174861 | 0.647684 | 00:00 | . 485 | 1.174683 | 0.652326 | 00:00 | . 486 | 1.174505 | 0.653870 | 00:00 | . 487 | 1.174329 | 0.649032 | 00:00 | . 488 | 1.174153 | 0.655512 | 00:00 | . 489 | 1.173977 | 0.649586 | 00:00 | . 490 | 1.173801 | 0.654173 | 00:00 | . 491 | 1.173624 | 0.652167 | 00:00 | . 492 | 1.173448 | 0.655364 | 00:00 | . 493 | 1.173273 | 0.656568 | 00:00 | . 494 | 1.173098 | 0.658468 | 00:00 | . 495 | 1.172923 | 0.660450 | 00:00 | . 496 | 1.172747 | 0.658418 | 00:00 | . 497 | 1.172574 | 0.664447 | 00:00 | . 498 | 1.172400 | 0.655454 | 00:00 | . 499 | 1.172228 | 0.666339 | 00:00 | . 500 | 1.172055 | 0.654350 | 00:00 | . 501 | 1.171883 | 0.667965 | 00:00 | . 502 | 1.171710 | 0.660691 | 00:00 | . 503 | 1.171538 | 0.666292 | 00:00 | . 504 | 1.171365 | 0.669763 | 00:00 | . 505 | 1.171193 | 0.661788 | 00:00 | . 506 | 1.171022 | 0.676019 | 00:00 | . 507 | 1.170852 | 0.656674 | 00:00 | . 508 | 1.170684 | 0.678302 | 00:00 | . 509 | 1.170515 | 0.661348 | 00:00 | . 510 | 1.170346 | 0.669641 | 00:00 | . 511 | 1.170176 | 0.674612 | 00:00 | . 512 | 1.170005 | 0.663549 | 00:00 | . 513 | 1.169838 | 0.679929 | 00:00 | . 514 | 1.169668 | 0.670535 | 00:00 | . 515 | 1.169498 | 0.671963 | 00:00 | . 516 | 1.169330 | 0.680020 | 00:00 | . 517 | 1.169162 | 0.665240 | 00:00 | . 518 | 1.168995 | 0.679197 | 00:00 | . 519 | 1.168829 | 0.670004 | 00:00 | . 520 | 1.168662 | 0.674645 | 00:00 | . 521 | 1.168495 | 0.675399 | 00:00 | . 522 | 1.168327 | 0.675977 | 00:00 | . 523 | 1.168159 | 0.680865 | 00:00 | . 524 | 1.167992 | 0.681353 | 00:00 | . 525 | 1.167827 | 0.680745 | 00:00 | . 526 | 1.167661 | 0.685391 | 00:00 | . 527 | 1.167495 | 0.679892 | 00:00 | . 528 | 1.167331 | 0.687801 | 00:00 | . 529 | 1.167167 | 0.679404 | 00:00 | . 530 | 1.167005 | 0.689592 | 00:00 | . 531 | 1.166840 | 0.682430 | 00:00 | . 532 | 1.166679 | 0.689441 | 00:00 | . 533 | 1.166516 | 0.686591 | 00:00 | . 534 | 1.166354 | 0.690570 | 00:00 | . 535 | 1.166191 | 0.690022 | 00:00 | . 536 | 1.166030 | 0.688995 | 00:00 | . 537 | 1.165868 | 0.695726 | 00:00 | . 538 | 1.165707 | 0.692526 | 00:00 | . 539 | 1.165547 | 0.702132 | 00:00 | . 540 | 1.165386 | 0.699653 | 00:00 | . 541 | 1.165227 | 0.706975 | 00:00 | . 542 | 1.165067 | 0.704185 | 00:00 | . 543 | 1.164908 | 0.705872 | 00:00 | . 544 | 1.164748 | 0.704565 | 00:00 | . 545 | 1.164590 | 0.697399 | 00:00 | . 546 | 1.164433 | 0.709462 | 00:00 | . 547 | 1.164274 | 0.692216 | 00:00 | . 548 | 1.164118 | 0.717534 | 00:00 | . 549 | 1.163962 | 0.695129 | 00:00 | . 550 | 1.163807 | 0.712931 | 00:00 | . 551 | 1.163651 | 0.705726 | 00:00 | . 552 | 1.163493 | 0.702003 | 00:00 | . 553 | 1.163336 | 0.710318 | 00:00 | . 554 | 1.163179 | 0.698091 | 00:00 | . 555 | 1.163025 | 0.711031 | 00:00 | . 556 | 1.162869 | 0.706409 | 00:00 | . 557 | 1.162713 | 0.713703 | 00:00 | . 558 | 1.162558 | 0.719242 | 00:00 | . 559 | 1.162403 | 0.711609 | 00:00 | . 560 | 1.162249 | 0.724058 | 00:00 | . 561 | 1.162096 | 0.712843 | 00:00 | . 562 | 1.161943 | 0.721852 | 00:00 | . 563 | 1.161789 | 0.718676 | 00:00 | . 564 | 1.161636 | 0.721415 | 00:00 | . 565 | 1.161484 | 0.720994 | 00:00 | . 566 | 1.161332 | 0.720838 | 00:00 | . 567 | 1.161180 | 0.723023 | 00:00 | . 568 | 1.161029 | 0.721188 | 00:00 | . 569 | 1.160877 | 0.723265 | 00:00 | . 570 | 1.160725 | 0.724430 | 00:00 | . 571 | 1.160574 | 0.727131 | 00:00 | . 572 | 1.160422 | 0.727649 | 00:00 | . 573 | 1.160273 | 0.728649 | 00:00 | . 574 | 1.160122 | 0.727610 | 00:00 | . 575 | 1.159973 | 0.728769 | 00:00 | . 576 | 1.159824 | 0.731067 | 00:00 | . 577 | 1.159676 | 0.734913 | 00:00 | . 578 | 1.159526 | 0.735820 | 00:00 | . 579 | 1.159379 | 0.737612 | 00:00 | . 580 | 1.159229 | 0.735839 | 00:00 | . 581 | 1.159080 | 0.735314 | 00:00 | . 582 | 1.158932 | 0.733589 | 00:00 | . 583 | 1.158784 | 0.735477 | 00:00 | . 584 | 1.158638 | 0.732117 | 00:00 | . 585 | 1.158491 | 0.737441 | 00:00 | . 586 | 1.158345 | 0.734808 | 00:00 | . 587 | 1.158200 | 0.743212 | 00:00 | . 588 | 1.158056 | 0.740217 | 00:00 | . 589 | 1.157910 | 0.746061 | 00:00 | . 590 | 1.157764 | 0.745176 | 00:00 | . 591 | 1.157619 | 0.745762 | 00:00 | . 592 | 1.157475 | 0.744707 | 00:00 | . 593 | 1.157332 | 0.742506 | 00:00 | . 594 | 1.157188 | 0.748639 | 00:00 | . 595 | 1.157044 | 0.740185 | 00:00 | . 596 | 1.156901 | 0.757565 | 00:00 | . 597 | 1.156759 | 0.736161 | 00:00 | . 598 | 1.156619 | 0.771549 | 00:00 | . 599 | 1.156482 | 0.735059 | 00:00 | . 600 | 1.156345 | 0.769085 | 00:00 | . 601 | 1.156207 | 0.750762 | 00:00 | . 602 | 1.156066 | 0.744747 | 00:00 | . 603 | 1.155928 | 0.774248 | 00:00 | . 604 | 1.155791 | 0.742776 | 00:00 | . 605 | 1.155653 | 0.764062 | 00:00 | . 606 | 1.155515 | 0.768612 | 00:00 | . 607 | 1.155378 | 0.745709 | 00:00 | . 608 | 1.155242 | 0.772326 | 00:00 | . 609 | 1.155105 | 0.762058 | 00:00 | . 610 | 1.154967 | 0.749233 | 00:00 | . 611 | 1.154831 | 0.768939 | 00:00 | . 612 | 1.154693 | 0.753700 | 00:00 | . 613 | 1.154555 | 0.754060 | 00:00 | . 614 | 1.154418 | 0.769759 | 00:00 | . 615 | 1.154282 | 0.756170 | 00:00 | . 616 | 1.154146 | 0.766465 | 00:00 | . 617 | 1.154011 | 0.772657 | 00:00 | . 618 | 1.153876 | 0.769429 | 00:00 | . 619 | 1.153741 | 0.771619 | 00:00 | . 620 | 1.153608 | 0.770932 | 00:00 | . 621 | 1.153476 | 0.768476 | 00:00 | . 622 | 1.153342 | 0.770343 | 00:00 | . 623 | 1.153209 | 0.768920 | 00:00 | . 624 | 1.153077 | 0.772649 | 00:00 | . 625 | 1.152945 | 0.773119 | 00:00 | . 626 | 1.152812 | 0.771454 | 00:00 | . 627 | 1.152680 | 0.778261 | 00:00 | . 628 | 1.152548 | 0.776608 | 00:00 | . 629 | 1.152418 | 0.773290 | 00:00 | . 630 | 1.152286 | 0.780656 | 00:00 | . 631 | 1.152156 | 0.775731 | 00:00 | . 632 | 1.152025 | 0.779517 | 00:00 | . 633 | 1.151896 | 0.778083 | 00:00 | . 634 | 1.151767 | 0.775307 | 00:00 | . 635 | 1.151638 | 0.782973 | 00:00 | . 636 | 1.151511 | 0.772681 | 00:00 | . 637 | 1.151383 | 0.786697 | 00:00 | . 638 | 1.151256 | 0.781338 | 00:00 | . 639 | 1.151129 | 0.779945 | 00:00 | . 640 | 1.151001 | 0.796323 | 00:00 | . 641 | 1.150876 | 0.779720 | 00:00 | . 642 | 1.150750 | 0.793527 | 00:00 | . 643 | 1.150625 | 0.792330 | 00:00 | . 644 | 1.150499 | 0.773774 | 00:00 | . 645 | 1.150375 | 0.800118 | 00:00 | . 646 | 1.150253 | 0.781727 | 00:00 | . 647 | 1.150127 | 0.789161 | 00:00 | . 648 | 1.150002 | 0.807146 | 00:00 | . 649 | 1.149879 | 0.785683 | 00:00 | . 650 | 1.149758 | 0.801186 | 00:00 | . 651 | 1.149637 | 0.799043 | 00:00 | . 652 | 1.149514 | 0.784458 | 00:00 | . 653 | 1.149392 | 0.804605 | 00:00 | . 654 | 1.149269 | 0.793532 | 00:00 | . 655 | 1.149148 | 0.788827 | 00:00 | . 656 | 1.149027 | 0.810499 | 00:00 | . 657 | 1.148907 | 0.784906 | 00:00 | . 658 | 1.148789 | 0.797004 | 00:00 | . 659 | 1.148669 | 0.808318 | 00:00 | . 660 | 1.148550 | 0.790818 | 00:00 | . 661 | 1.148430 | 0.807112 | 00:00 | . 662 | 1.148311 | 0.807896 | 00:00 | . 663 | 1.148192 | 0.793612 | 00:00 | . 664 | 1.148074 | 0.814762 | 00:00 | . 665 | 1.147955 | 0.803445 | 00:00 | . 666 | 1.147837 | 0.797560 | 00:00 | . 667 | 1.147718 | 0.811713 | 00:00 | . 668 | 1.147601 | 0.799508 | 00:00 | . 669 | 1.147484 | 0.799374 | 00:00 | . 670 | 1.147368 | 0.814020 | 00:00 | . 671 | 1.147251 | 0.808156 | 00:00 | . 672 | 1.147136 | 0.812753 | 00:00 | . 673 | 1.147021 | 0.819477 | 00:00 | . 674 | 1.146906 | 0.804505 | 00:00 | . 675 | 1.146790 | 0.817322 | 00:00 | . 676 | 1.146675 | 0.806367 | 00:00 | . 677 | 1.146561 | 0.804483 | 00:00 | . 678 | 1.146447 | 0.817632 | 00:00 | . 679 | 1.146334 | 0.804266 | 00:00 | . 680 | 1.146220 | 0.818144 | 00:00 | . 681 | 1.146108 | 0.816939 | 00:00 | . 682 | 1.145994 | 0.809324 | 00:00 | . 683 | 1.145882 | 0.824353 | 00:00 | . 684 | 1.145771 | 0.814552 | 00:00 | . 685 | 1.145658 | 0.812293 | 00:00 | . 686 | 1.145546 | 0.823278 | 00:00 | . 687 | 1.145435 | 0.812532 | 00:00 | . 688 | 1.145323 | 0.817525 | 00:00 | . 689 | 1.145211 | 0.820862 | 00:00 | . 690 | 1.145103 | 0.814268 | 00:00 | . 691 | 1.144992 | 0.826711 | 00:00 | . 692 | 1.144881 | 0.825731 | 00:00 | . 693 | 1.144772 | 0.825377 | 00:00 | . 694 | 1.144664 | 0.831147 | 00:00 | . 695 | 1.144554 | 0.825554 | 00:00 | . 696 | 1.144444 | 0.822579 | 00:00 | . 697 | 1.144335 | 0.827216 | 00:00 | . 698 | 1.144226 | 0.818370 | 00:00 | . 699 | 1.144118 | 0.824985 | 00:00 | . 700 | 1.144011 | 0.827606 | 00:00 | . 701 | 1.143903 | 0.825293 | 00:00 | . 702 | 1.143797 | 0.824510 | 00:00 | . 703 | 1.143687 | 0.831842 | 00:00 | . 704 | 1.143579 | 0.819512 | 00:00 | . 705 | 1.143472 | 0.831834 | 00:00 | . 706 | 1.143366 | 0.830589 | 00:00 | . 707 | 1.143260 | 0.823436 | 00:00 | . 708 | 1.143155 | 0.841350 | 00:00 | . 709 | 1.143051 | 0.821013 | 00:00 | . 710 | 1.142948 | 0.841491 | 00:00 | . 711 | 1.142844 | 0.833130 | 00:00 | . 712 | 1.142738 | 0.830558 | 00:00 | . 713 | 1.142634 | 0.839617 | 00:00 | . 714 | 1.142530 | 0.829297 | 00:00 | . 715 | 1.142426 | 0.832571 | 00:00 | . 716 | 1.142321 | 0.838219 | 00:00 | . 717 | 1.142219 | 0.824259 | 00:00 | . 718 | 1.142117 | 0.849616 | 00:00 | . 719 | 1.142013 | 0.829544 | 00:00 | . 720 | 1.141912 | 0.837785 | 00:00 | . 721 | 1.141808 | 0.839404 | 00:00 | . 722 | 1.141706 | 0.824520 | 00:00 | . 723 | 1.141604 | 0.850135 | 00:00 | . 724 | 1.141504 | 0.831047 | 00:00 | . 725 | 1.141403 | 0.846186 | 00:00 | . 726 | 1.141299 | 0.846048 | 00:00 | . 727 | 1.141198 | 0.837446 | 00:00 | . 728 | 1.141097 | 0.848955 | 00:00 | . 729 | 1.140998 | 0.837740 | 00:00 | . 730 | 1.140897 | 0.840581 | 00:00 | . 731 | 1.140797 | 0.843217 | 00:00 | . 732 | 1.140696 | 0.836666 | 00:00 | . 733 | 1.140596 | 0.849162 | 00:00 | . 734 | 1.140497 | 0.838051 | 00:00 | . 735 | 1.140396 | 0.845237 | 00:00 | . 736 | 1.140297 | 0.843339 | 00:00 | . 737 | 1.140200 | 0.846230 | 00:00 | . 738 | 1.140100 | 0.844921 | 00:00 | . 739 | 1.140002 | 0.848239 | 00:00 | . 740 | 1.139903 | 0.843349 | 00:00 | . 741 | 1.139805 | 0.852105 | 00:00 | . 742 | 1.139708 | 0.842042 | 00:00 | . 743 | 1.139609 | 0.856012 | 00:00 | . 744 | 1.139512 | 0.842623 | 00:00 | . 745 | 1.139416 | 0.848598 | 00:00 | . 746 | 1.139319 | 0.849762 | 00:00 | . 747 | 1.139220 | 0.843101 | 00:00 | . 748 | 1.139124 | 0.856936 | 00:00 | . 749 | 1.139028 | 0.850956 | 00:00 | . 750 | 1.138933 | 0.857461 | 00:00 | . 751 | 1.138837 | 0.850585 | 00:00 | . 752 | 1.138741 | 0.859319 | 00:00 | . 753 | 1.138645 | 0.847639 | 00:00 | . 754 | 1.138551 | 0.863867 | 00:00 | . 755 | 1.138455 | 0.844789 | 00:00 | . 756 | 1.138359 | 0.864412 | 00:00 | . 757 | 1.138262 | 0.849402 | 00:00 | . 758 | 1.138168 | 0.854914 | 00:00 | . 759 | 1.138074 | 0.858879 | 00:00 | . 760 | 1.137979 | 0.853253 | 00:00 | . 761 | 1.137886 | 0.868428 | 00:00 | . 762 | 1.137792 | 0.849593 | 00:00 | . 763 | 1.137699 | 0.869901 | 00:00 | . 764 | 1.137607 | 0.850486 | 00:00 | . 765 | 1.137514 | 0.863039 | 00:00 | . 766 | 1.137419 | 0.854652 | 00:00 | . 767 | 1.137325 | 0.856614 | 00:00 | . 768 | 1.137231 | 0.861490 | 00:00 | . 769 | 1.137138 | 0.855539 | 00:00 | . 770 | 1.137045 | 0.865625 | 00:00 | . 771 | 1.136952 | 0.858192 | 00:00 | . 772 | 1.136857 | 0.865162 | 00:00 | . 773 | 1.136762 | 0.862942 | 00:00 | . 774 | 1.136669 | 0.863200 | 00:00 | . 775 | 1.136577 | 0.866388 | 00:00 | . 776 | 1.136485 | 0.860678 | 00:00 | . 777 | 1.136392 | 0.864243 | 00:00 | . 778 | 1.136300 | 0.855608 | 00:00 | . 779 | 1.136209 | 0.864398 | 00:00 | . 780 | 1.136120 | 0.860409 | 00:00 | . 781 | 1.136030 | 0.872384 | 00:00 | . 782 | 1.135939 | 0.862076 | 00:00 | . 783 | 1.135848 | 0.874728 | 00:00 | . 784 | 1.135755 | 0.861477 | 00:00 | . 785 | 1.135663 | 0.874420 | 00:00 | . 786 | 1.135571 | 0.861232 | 00:00 | . 787 | 1.135479 | 0.870913 | 00:00 | . 788 | 1.135388 | 0.868093 | 00:00 | . 789 | 1.135296 | 0.875822 | 00:00 | . 790 | 1.135203 | 0.873967 | 00:00 | . 791 | 1.135110 | 0.871325 | 00:00 | . 792 | 1.135015 | 0.876681 | 00:00 | . 793 | 1.134925 | 0.859543 | 00:00 | . 794 | 1.134835 | 0.879577 | 00:00 | . 795 | 1.134743 | 0.864079 | 00:00 | . 796 | 1.134653 | 0.892693 | 00:00 | . 797 | 1.134563 | 0.860914 | 00:00 | . 798 | 1.134474 | 0.892006 | 00:00 | . 799 | 1.134385 | 0.854810 | 00:00 | . 800 | 1.134295 | 0.877297 | 00:00 | . 801 | 1.134205 | 0.867235 | 00:00 | . 802 | 1.134112 | 0.863984 | 00:00 | . 803 | 1.134019 | 0.879986 | 00:00 | . 804 | 1.133928 | 0.861217 | 00:00 | . 805 | 1.133838 | 0.876992 | 00:00 | . 806 | 1.133745 | 0.869224 | 00:00 | . 807 | 1.133653 | 0.869163 | 00:00 | . 808 | 1.133562 | 0.874003 | 00:00 | . 809 | 1.133471 | 0.865148 | 00:00 | . 810 | 1.133381 | 0.873356 | 00:00 | . 811 | 1.133292 | 0.863060 | 00:00 | . 812 | 1.133201 | 0.868399 | 00:00 | . 813 | 1.133111 | 0.864882 | 00:00 | . 814 | 1.133021 | 0.867160 | 00:00 | . 815 | 1.132932 | 0.865521 | 00:00 | . 816 | 1.132843 | 0.873941 | 00:00 | . 817 | 1.132755 | 0.860558 | 00:00 | . 818 | 1.132668 | 0.879268 | 00:00 | . 819 | 1.132582 | 0.852869 | 00:00 | . 820 | 1.132495 | 0.872444 | 00:00 | . 821 | 1.132408 | 0.855299 | 00:00 | . 822 | 1.132323 | 0.862534 | 00:00 | . 823 | 1.132236 | 0.872384 | 00:00 | . 824 | 1.132149 | 0.853979 | 00:00 | . 825 | 1.132063 | 0.873976 | 00:00 | . 826 | 1.131977 | 0.853876 | 00:00 | . 827 | 1.131892 | 0.866198 | 00:00 | . 828 | 1.131807 | 0.870824 | 00:00 | . 829 | 1.131720 | 0.854757 | 00:00 | . 830 | 1.131633 | 0.873532 | 00:00 | . 831 | 1.131549 | 0.853658 | 00:00 | . 832 | 1.131464 | 0.869641 | 00:00 | . 833 | 1.131376 | 0.863078 | 00:00 | . 834 | 1.131289 | 0.861533 | 00:00 | . 835 | 1.131203 | 0.870369 | 00:00 | . 836 | 1.131117 | 0.859380 | 00:00 | . 837 | 1.131034 | 0.858565 | 00:00 | . 838 | 1.130949 | 0.868208 | 00:00 | . 839 | 1.130866 | 0.854680 | 00:00 | . 840 | 1.130783 | 0.874185 | 00:00 | . 841 | 1.130700 | 0.859076 | 00:00 | . 842 | 1.130616 | 0.863381 | 00:00 | . 843 | 1.130533 | 0.857904 | 00:00 | . 844 | 1.130450 | 0.857336 | 00:00 | . 845 | 1.130367 | 0.860589 | 00:00 | . 846 | 1.130286 | 0.871394 | 00:00 | . 847 | 1.130202 | 0.852711 | 00:00 | . 848 | 1.130119 | 0.870563 | 00:00 | . 849 | 1.130038 | 0.847779 | 00:00 | . 850 | 1.129956 | 0.860374 | 00:00 | . 851 | 1.129876 | 0.857340 | 00:00 | . 852 | 1.129794 | 0.850603 | 00:00 | . 853 | 1.129714 | 0.864460 | 00:00 | . 854 | 1.129635 | 0.854669 | 00:00 | . 855 | 1.129553 | 0.858434 | 00:00 | . 856 | 1.129472 | 0.864192 | 00:00 | . 857 | 1.129392 | 0.849015 | 00:00 | . 858 | 1.129312 | 0.867516 | 00:00 | . 859 | 1.129233 | 0.842211 | 00:00 | . 860 | 1.129155 | 0.862945 | 00:00 | . 861 | 1.129078 | 0.853798 | 00:00 | . 862 | 1.128999 | 0.858534 | 00:00 | . 863 | 1.128921 | 0.859560 | 00:00 | . 864 | 1.128842 | 0.857198 | 00:00 | . 865 | 1.128763 | 0.857788 | 00:00 | . 866 | 1.128684 | 0.856849 | 00:00 | . 867 | 1.128606 | 0.854766 | 00:00 | . 868 | 1.128528 | 0.859631 | 00:00 | . 869 | 1.128451 | 0.860161 | 00:00 | . 870 | 1.128372 | 0.853523 | 00:00 | . 871 | 1.128294 | 0.858132 | 00:00 | . 872 | 1.128217 | 0.848801 | 00:00 | . 873 | 1.128139 | 0.858670 | 00:00 | . 874 | 1.128064 | 0.853983 | 00:00 | . 875 | 1.127988 | 0.858677 | 00:00 | . 876 | 1.127911 | 0.857006 | 00:00 | . 877 | 1.127835 | 0.849795 | 00:00 | . 878 | 1.127759 | 0.854704 | 00:00 | . 879 | 1.127682 | 0.848892 | 00:00 | . 880 | 1.127607 | 0.855406 | 00:00 | . 881 | 1.127532 | 0.850048 | 00:00 | . 882 | 1.127455 | 0.848791 | 00:00 | . 883 | 1.127379 | 0.853477 | 00:00 | . 884 | 1.127305 | 0.840029 | 00:00 | . 885 | 1.127230 | 0.868410 | 00:00 | . 886 | 1.127156 | 0.831517 | 00:00 | . 887 | 1.127086 | 0.881237 | 00:00 | . 888 | 1.127015 | 0.835450 | 00:00 | . 889 | 1.126945 | 0.856970 | 00:00 | . 890 | 1.126871 | 0.860736 | 00:00 | . 891 | 1.126796 | 0.829224 | 00:00 | . 892 | 1.126725 | 0.863013 | 00:00 | . 893 | 1.126655 | 0.850852 | 00:00 | . 894 | 1.126581 | 0.837041 | 00:00 | . 895 | 1.126509 | 0.864583 | 00:00 | . 896 | 1.126438 | 0.842915 | 00:00 | . 897 | 1.126366 | 0.838824 | 00:00 | . 898 | 1.126293 | 0.864659 | 00:00 | . 899 | 1.126220 | 0.842312 | 00:00 | . 900 | 1.126149 | 0.850549 | 00:00 | . 901 | 1.126076 | 0.860747 | 00:00 | . 902 | 1.126004 | 0.835979 | 00:00 | . 903 | 1.125931 | 0.847959 | 00:00 | . 904 | 1.125860 | 0.851000 | 00:00 | . 905 | 1.125789 | 0.836149 | 00:00 | . 906 | 1.125719 | 0.850032 | 00:00 | . 907 | 1.125648 | 0.847336 | 00:00 | . 908 | 1.125576 | 0.837743 | 00:00 | . 909 | 1.125505 | 0.852608 | 00:00 | . 910 | 1.125436 | 0.846568 | 00:00 | . 911 | 1.125366 | 0.840082 | 00:00 | . 912 | 1.125297 | 0.852738 | 00:00 | . 913 | 1.125231 | 0.839086 | 00:00 | . 914 | 1.125161 | 0.844776 | 00:00 | . 915 | 1.125091 | 0.853013 | 00:00 | . 916 | 1.125024 | 0.843607 | 00:00 | . 917 | 1.124954 | 0.843370 | 00:00 | . 918 | 1.124885 | 0.851984 | 00:00 | . 919 | 1.124818 | 0.830260 | 00:00 | . 920 | 1.124753 | 0.848803 | 00:00 | . 921 | 1.124686 | 0.848179 | 00:00 | . 922 | 1.124618 | 0.836883 | 00:00 | . 923 | 1.124550 | 0.853833 | 00:00 | . 924 | 1.124483 | 0.839324 | 00:00 | . 925 | 1.124419 | 0.841535 | 00:00 | . 926 | 1.124353 | 0.842931 | 00:00 | . 927 | 1.124289 | 0.841324 | 00:00 | . 928 | 1.124222 | 0.846839 | 00:00 | . 929 | 1.124154 | 0.843471 | 00:00 | . 930 | 1.124089 | 0.840840 | 00:00 | . 931 | 1.124022 | 0.841792 | 00:00 | . 932 | 1.123956 | 0.837194 | 00:00 | . 933 | 1.123891 | 0.837308 | 00:00 | . 934 | 1.123827 | 0.844652 | 00:00 | . 935 | 1.123760 | 0.842046 | 00:00 | . 936 | 1.123690 | 0.852645 | 00:00 | . 937 | 1.123624 | 0.837106 | 00:00 | . 938 | 1.123557 | 0.836191 | 00:00 | . 939 | 1.123491 | 0.839347 | 00:00 | . 940 | 1.123427 | 0.828554 | 00:00 | . 941 | 1.123361 | 0.846440 | 00:00 | . 942 | 1.123297 | 0.841281 | 00:00 | . 943 | 1.123232 | 0.845126 | 00:00 | . 944 | 1.123168 | 0.840104 | 00:00 | . 945 | 1.123103 | 0.833093 | 00:00 | . 946 | 1.123038 | 0.829462 | 00:00 | . 947 | 1.122975 | 0.839022 | 00:00 | . 948 | 1.122910 | 0.827858 | 00:00 | . 949 | 1.122847 | 0.844970 | 00:00 | . 950 | 1.122783 | 0.829865 | 00:00 | . 951 | 1.122721 | 0.845319 | 00:00 | . 952 | 1.122656 | 0.830022 | 00:00 | . 953 | 1.122593 | 0.832491 | 00:00 | . 954 | 1.122528 | 0.837621 | 00:00 | . 955 | 1.122462 | 0.820146 | 00:00 | . 956 | 1.122397 | 0.844777 | 00:00 | . 957 | 1.122334 | 0.825796 | 00:00 | . 958 | 1.122272 | 0.832674 | 00:00 | . 959 | 1.122209 | 0.835724 | 00:00 | . 960 | 1.122144 | 0.825456 | 00:00 | . 961 | 1.122078 | 0.841224 | 00:00 | . 962 | 1.122014 | 0.825974 | 00:00 | . 963 | 1.121951 | 0.840021 | 00:00 | . 964 | 1.121888 | 0.831758 | 00:00 | . 965 | 1.121823 | 0.819274 | 00:00 | . 966 | 1.121762 | 0.837447 | 00:00 | . 967 | 1.121698 | 0.819602 | 00:00 | . 968 | 1.121633 | 0.839202 | 00:00 | . 969 | 1.121570 | 0.825377 | 00:00 | . 970 | 1.121507 | 0.825362 | 00:00 | . 971 | 1.121445 | 0.832869 | 00:00 | . 972 | 1.121384 | 0.808087 | 00:00 | . 973 | 1.121323 | 0.836934 | 00:00 | . 974 | 1.121263 | 0.815343 | 00:00 | . 975 | 1.121203 | 0.829066 | 00:00 | . 976 | 1.121140 | 0.831464 | 00:00 | . 977 | 1.121077 | 0.821343 | 00:00 | . 978 | 1.121016 | 0.826258 | 00:00 | . 979 | 1.120953 | 0.824040 | 00:00 | . 980 | 1.120890 | 0.817167 | 00:00 | . 981 | 1.120829 | 0.835620 | 00:00 | . 982 | 1.120770 | 0.811536 | 00:00 | . 983 | 1.120709 | 0.825223 | 00:00 | . 984 | 1.120647 | 0.814452 | 00:00 | . 985 | 1.120587 | 0.812379 | 00:00 | . 986 | 1.120528 | 0.823268 | 00:00 | . 987 | 1.120465 | 0.808463 | 00:00 | . 988 | 1.120403 | 0.828295 | 00:00 | . 989 | 1.120343 | 0.814847 | 00:00 | . 990 | 1.120281 | 0.814448 | 00:00 | . 991 | 1.120219 | 0.820980 | 00:00 | . 992 | 1.120160 | 0.804554 | 00:00 | . 993 | 1.120100 | 0.824731 | 00:00 | . 994 | 1.120041 | 0.805505 | 00:00 | . 995 | 1.119982 | 0.818074 | 00:00 | . 996 | 1.119921 | 0.816324 | 00:00 | . 997 | 1.119859 | 0.806917 | 00:00 | . 998 | 1.119800 | 0.816600 | 00:00 | . 999 | 1.119738 | 0.805386 | 00:00 | . . - loss들도 에폭별로 기록되어 있음 . lrnr.recorder.plot_loss() . - net_fastai에도 파라메터가 업데이트 되어있음 . # list(net1.parameters()) #비교용, cuda 없음. cpu학습 . 리스트를 확인해보면 device가 cuda임 | net_fastai 의 파라메터가 알아서 GPU로 옮겨져서 학습됨. | . - 플랏 . net_fastai.to(&quot;cpu&quot;) #같은 디바이스에 올려주기 plt.plot(X,y,&#39;.&#39;) plt.plot(X_tr,net_fastai(X_tr).data) plt.plot(X_val,net_fastai(X_val).data) . [&lt;matplotlib.lines.Line2D at 0x7f40582a9e80&gt;] . &#46300;&#46989;&#50500;&#50883; &#52628;&#44032;&#48260;&#51204; . - 네트워크 설계 (드랍아웃 추가) . torch.manual_seed(1) net_fastai = torch.nn.Sequential( torch.nn.Linear(in_features=1, out_features=512), torch.nn.ReLU(), torch.nn.Dropout(0.8), torch.nn.Linear(in_features=512, out_features=1)) #optimizer loss_fn=torch.nn.MSELoss() . - 러너오브젝트 (for문 대신돌려주는 오브젝트) . lrnr= Learner(dls,net_fastai,opt_func=Adam,loss_func=loss_fn) . - 에폭만 설정하고 바로 학습 . lrnr.fit(1000) . epoch train_loss valid_loss time . 0 | 1.247709 | 0.416773 | 00:00 | . 1 | 1.246509 | 0.416574 | 00:00 | . 2 | 1.250404 | 0.416343 | 00:00 | . 3 | 1.254794 | 0.415792 | 00:00 | . 4 | 1.255322 | 0.415081 | 00:00 | . 5 | 1.262187 | 0.414570 | 00:00 | . 6 | 1.257735 | 0.414416 | 00:00 | . 7 | 1.263794 | 0.414380 | 00:00 | . 8 | 1.273511 | 0.414440 | 00:00 | . 9 | 1.280515 | 0.414707 | 00:00 | . 10 | 1.281019 | 0.414791 | 00:00 | . 11 | 1.277477 | 0.414941 | 00:00 | . 12 | 1.281326 | 0.415325 | 00:00 | . 13 | 1.283238 | 0.415822 | 00:00 | . 14 | 1.288235 | 0.416455 | 00:00 | . 15 | 1.286561 | 0.416884 | 00:00 | . 16 | 1.287848 | 0.417369 | 00:00 | . 17 | 1.287952 | 0.417712 | 00:00 | . 18 | 1.286845 | 0.418420 | 00:00 | . 19 | 1.285719 | 0.419052 | 00:00 | . 20 | 1.285489 | 0.419077 | 00:00 | . 21 | 1.282936 | 0.418979 | 00:00 | . 22 | 1.278863 | 0.418753 | 00:00 | . 23 | 1.278564 | 0.418172 | 00:00 | . 24 | 1.278082 | 0.417707 | 00:00 | . 25 | 1.277656 | 0.417181 | 00:00 | . 26 | 1.275716 | 0.416697 | 00:00 | . 27 | 1.275740 | 0.416226 | 00:00 | . 28 | 1.274473 | 0.415754 | 00:00 | . 29 | 1.272055 | 0.415303 | 00:00 | . 30 | 1.269399 | 0.414931 | 00:00 | . 31 | 1.267568 | 0.414717 | 00:00 | . 32 | 1.268708 | 0.414700 | 00:00 | . 33 | 1.269534 | 0.414543 | 00:00 | . 34 | 1.268300 | 0.414521 | 00:00 | . 35 | 1.269248 | 0.414410 | 00:00 | . 36 | 1.269646 | 0.414477 | 00:00 | . 37 | 1.270952 | 0.414804 | 00:00 | . 38 | 1.270892 | 0.415224 | 00:00 | . 39 | 1.272188 | 0.415638 | 00:00 | . 40 | 1.269703 | 0.415989 | 00:00 | . 41 | 1.269088 | 0.416524 | 00:00 | . 42 | 1.268321 | 0.417287 | 00:00 | . 43 | 1.268703 | 0.417832 | 00:00 | . 44 | 1.268282 | 0.417918 | 00:00 | . 45 | 1.266276 | 0.417790 | 00:00 | . 46 | 1.263553 | 0.417657 | 00:00 | . 47 | 1.263615 | 0.417413 | 00:00 | . 48 | 1.261576 | 0.417289 | 00:00 | . 49 | 1.262501 | 0.416822 | 00:00 | . 50 | 1.262669 | 0.416575 | 00:00 | . 51 | 1.263989 | 0.416202 | 00:00 | . 52 | 1.262181 | 0.415931 | 00:00 | . 53 | 1.261245 | 0.415958 | 00:00 | . 54 | 1.262222 | 0.416057 | 00:00 | . 55 | 1.263220 | 0.416202 | 00:00 | . 56 | 1.263651 | 0.416522 | 00:00 | . 57 | 1.264915 | 0.417000 | 00:00 | . 58 | 1.265596 | 0.417375 | 00:00 | . 59 | 1.265338 | 0.417715 | 00:00 | . 60 | 1.263721 | 0.417727 | 00:00 | . 61 | 1.263320 | 0.417769 | 00:00 | . 62 | 1.262282 | 0.417662 | 00:00 | . 63 | 1.263302 | 0.417558 | 00:00 | . 64 | 1.263925 | 0.417435 | 00:00 | . 65 | 1.263306 | 0.417109 | 00:00 | . 66 | 1.265070 | 0.416881 | 00:00 | . 67 | 1.265900 | 0.416876 | 00:00 | . 68 | 1.266905 | 0.416927 | 00:00 | . 69 | 1.266407 | 0.417030 | 00:00 | . 70 | 1.265890 | 0.417082 | 00:00 | . 71 | 1.265325 | 0.416989 | 00:00 | . 72 | 1.263666 | 0.417082 | 00:00 | . 73 | 1.262054 | 0.417238 | 00:00 | . 74 | 1.261566 | 0.417476 | 00:00 | . 75 | 1.260620 | 0.417703 | 00:00 | . 76 | 1.261897 | 0.418082 | 00:00 | . 77 | 1.261749 | 0.418737 | 00:00 | . 78 | 1.261941 | 0.419250 | 00:00 | . 79 | 1.262153 | 0.419443 | 00:00 | . 80 | 1.261083 | 0.419892 | 00:00 | . 81 | 1.260877 | 0.420300 | 00:00 | . 82 | 1.260881 | 0.420634 | 00:00 | . 83 | 1.260611 | 0.420556 | 00:00 | . 84 | 1.261182 | 0.420179 | 00:00 | . 85 | 1.261799 | 0.419739 | 00:00 | . 86 | 1.262053 | 0.418980 | 00:00 | . 87 | 1.262166 | 0.418238 | 00:00 | . 88 | 1.262798 | 0.417276 | 00:00 | . 89 | 1.262232 | 0.416798 | 00:00 | . 90 | 1.263194 | 0.416513 | 00:00 | . 91 | 1.263328 | 0.416425 | 00:00 | . 92 | 1.265095 | 0.416034 | 00:00 | . 93 | 1.266157 | 0.415869 | 00:00 | . 94 | 1.266261 | 0.415672 | 00:00 | . 95 | 1.263877 | 0.415509 | 00:00 | . 96 | 1.263891 | 0.415363 | 00:00 | . 97 | 1.262329 | 0.415340 | 00:00 | . 98 | 1.261214 | 0.415388 | 00:00 | . 99 | 1.261933 | 0.415427 | 00:00 | . 100 | 1.262066 | 0.415477 | 00:00 | . 101 | 1.260834 | 0.415661 | 00:00 | . 102 | 1.260920 | 0.415843 | 00:00 | . 103 | 1.261979 | 0.416204 | 00:00 | . 104 | 1.263574 | 0.416485 | 00:00 | . 105 | 1.265077 | 0.416552 | 00:00 | . 106 | 1.265236 | 0.416406 | 00:00 | . 107 | 1.264936 | 0.416304 | 00:00 | . 108 | 1.264646 | 0.416048 | 00:00 | . 109 | 1.264111 | 0.415834 | 00:00 | . 110 | 1.263834 | 0.415436 | 00:00 | . 111 | 1.264093 | 0.414911 | 00:00 | . 112 | 1.264518 | 0.414563 | 00:00 | . 113 | 1.264700 | 0.414289 | 00:00 | . 114 | 1.263648 | 0.414201 | 00:00 | . 115 | 1.264825 | 0.414141 | 00:00 | . 116 | 1.264632 | 0.414121 | 00:00 | . 117 | 1.264080 | 0.414174 | 00:00 | . 118 | 1.263640 | 0.414178 | 00:00 | . 119 | 1.263799 | 0.414219 | 00:00 | . 120 | 1.265042 | 0.414404 | 00:00 | . 121 | 1.263601 | 0.414789 | 00:00 | . 122 | 1.264891 | 0.415351 | 00:00 | . 123 | 1.266022 | 0.416204 | 00:00 | . 124 | 1.267981 | 0.416924 | 00:00 | . 125 | 1.267447 | 0.417755 | 00:00 | . 126 | 1.267099 | 0.418382 | 00:00 | . 127 | 1.267934 | 0.418912 | 00:00 | . 128 | 1.268566 | 0.419321 | 00:00 | . 129 | 1.268937 | 0.419354 | 00:00 | . 130 | 1.268631 | 0.418889 | 00:00 | . 131 | 1.268273 | 0.418341 | 00:00 | . 132 | 1.267205 | 0.417776 | 00:00 | . 133 | 1.266688 | 0.417010 | 00:00 | . 134 | 1.266640 | 0.416189 | 00:00 | . 135 | 1.266217 | 0.415347 | 00:00 | . 136 | 1.266319 | 0.414858 | 00:00 | . 137 | 1.265830 | 0.414540 | 00:00 | . 138 | 1.264521 | 0.414375 | 00:00 | . 139 | 1.263912 | 0.414285 | 00:00 | . 140 | 1.263502 | 0.414189 | 00:00 | . 141 | 1.264484 | 0.414101 | 00:00 | . 142 | 1.265479 | 0.414077 | 00:00 | . 143 | 1.264585 | 0.414089 | 00:00 | . 144 | 1.264316 | 0.414102 | 00:00 | . 145 | 1.265761 | 0.414173 | 00:00 | . 146 | 1.265651 | 0.414231 | 00:00 | . 147 | 1.265169 | 0.414401 | 00:00 | . 148 | 1.266358 | 0.414761 | 00:00 | . 149 | 1.266374 | 0.415263 | 00:00 | . 150 | 1.266137 | 0.415870 | 00:00 | . 151 | 1.266129 | 0.416352 | 00:00 | . 152 | 1.264925 | 0.416598 | 00:00 | . 153 | 1.263303 | 0.416743 | 00:00 | . 154 | 1.262659 | 0.416976 | 00:00 | . 155 | 1.263261 | 0.416666 | 00:00 | . 156 | 1.264239 | 0.416108 | 00:00 | . 157 | 1.264639 | 0.415478 | 00:00 | . 158 | 1.264842 | 0.414909 | 00:00 | . 159 | 1.265105 | 0.414499 | 00:00 | . 160 | 1.264055 | 0.414295 | 00:00 | . 161 | 1.264879 | 0.414249 | 00:00 | . 162 | 1.264890 | 0.414264 | 00:00 | . 163 | 1.265351 | 0.414271 | 00:00 | . 164 | 1.264805 | 0.414297 | 00:00 | . 165 | 1.265167 | 0.414265 | 00:00 | . 166 | 1.265182 | 0.414342 | 00:00 | . 167 | 1.264417 | 0.414313 | 00:00 | . 168 | 1.265511 | 0.414292 | 00:00 | . 169 | 1.264897 | 0.414253 | 00:00 | . 170 | 1.265736 | 0.414218 | 00:00 | . 171 | 1.265734 | 0.414309 | 00:00 | . 172 | 1.266315 | 0.414512 | 00:00 | . 173 | 1.264638 | 0.414843 | 00:00 | . 174 | 1.264191 | 0.415250 | 00:00 | . 175 | 1.264216 | 0.415675 | 00:00 | . 176 | 1.263507 | 0.416121 | 00:00 | . 177 | 1.264040 | 0.416499 | 00:00 | . 178 | 1.262508 | 0.417083 | 00:00 | . 179 | 1.262619 | 0.417470 | 00:00 | . 180 | 1.261836 | 0.417943 | 00:00 | . 181 | 1.261497 | 0.418174 | 00:00 | . 182 | 1.261700 | 0.418123 | 00:00 | . 183 | 1.262835 | 0.417831 | 00:00 | . 184 | 1.263691 | 0.417461 | 00:00 | . 185 | 1.263615 | 0.416964 | 00:00 | . 186 | 1.265439 | 0.416293 | 00:00 | . 187 | 1.264978 | 0.415861 | 00:00 | . 188 | 1.266064 | 0.415267 | 00:00 | . 189 | 1.264621 | 0.414830 | 00:00 | . 190 | 1.263996 | 0.414660 | 00:00 | . 191 | 1.263160 | 0.414584 | 00:00 | . 192 | 1.262272 | 0.414610 | 00:00 | . 193 | 1.261728 | 0.414627 | 00:00 | . 194 | 1.260762 | 0.414624 | 00:00 | . 195 | 1.261583 | 0.414700 | 00:00 | . 196 | 1.260631 | 0.414726 | 00:00 | . 197 | 1.260009 | 0.414898 | 00:00 | . 198 | 1.259922 | 0.415110 | 00:00 | . 199 | 1.260204 | 0.415432 | 00:00 | . 200 | 1.260366 | 0.415886 | 00:00 | . 201 | 1.259810 | 0.416262 | 00:00 | . 202 | 1.259228 | 0.416203 | 00:00 | . 203 | 1.259732 | 0.416001 | 00:00 | . 204 | 1.259207 | 0.415584 | 00:00 | . 205 | 1.258797 | 0.415147 | 00:00 | . 206 | 1.257919 | 0.414856 | 00:00 | . 207 | 1.258286 | 0.414661 | 00:00 | . 208 | 1.258186 | 0.414535 | 00:00 | . 209 | 1.258093 | 0.414482 | 00:00 | . 210 | 1.258160 | 0.414433 | 00:00 | . 211 | 1.258657 | 0.414428 | 00:00 | . 212 | 1.258462 | 0.414475 | 00:00 | . 213 | 1.257737 | 0.414572 | 00:00 | . 214 | 1.258174 | 0.414649 | 00:00 | . 215 | 1.258845 | 0.414685 | 00:00 | . 216 | 1.258114 | 0.414656 | 00:00 | . 217 | 1.257602 | 0.414594 | 00:00 | . 218 | 1.258874 | 0.414503 | 00:00 | . 219 | 1.258517 | 0.414447 | 00:00 | . 220 | 1.259820 | 0.414451 | 00:00 | . 221 | 1.260607 | 0.414411 | 00:00 | . 222 | 1.259813 | 0.414492 | 00:00 | . 223 | 1.260235 | 0.414558 | 00:00 | . 224 | 1.259789 | 0.414516 | 00:00 | . 225 | 1.259950 | 0.414550 | 00:00 | . 226 | 1.260405 | 0.414591 | 00:00 | . 227 | 1.261202 | 0.414588 | 00:00 | . 228 | 1.261632 | 0.414580 | 00:00 | . 229 | 1.261354 | 0.414533 | 00:00 | . 230 | 1.260254 | 0.414480 | 00:00 | . 231 | 1.259879 | 0.414450 | 00:00 | . 232 | 1.261258 | 0.414395 | 00:00 | . 233 | 1.261665 | 0.414393 | 00:00 | . 234 | 1.261230 | 0.414525 | 00:00 | . 235 | 1.263110 | 0.414556 | 00:00 | . 236 | 1.263477 | 0.414654 | 00:00 | . 237 | 1.263715 | 0.414688 | 00:00 | . 238 | 1.264316 | 0.414695 | 00:00 | . 239 | 1.264218 | 0.414738 | 00:00 | . 240 | 1.265304 | 0.414724 | 00:00 | . 241 | 1.264983 | 0.414717 | 00:00 | . 242 | 1.264190 | 0.414725 | 00:00 | . 243 | 1.264251 | 0.414695 | 00:00 | . 244 | 1.262695 | 0.414709 | 00:00 | . 245 | 1.263777 | 0.414697 | 00:00 | . 246 | 1.262671 | 0.414687 | 00:00 | . 247 | 1.260595 | 0.414677 | 00:00 | . 248 | 1.260220 | 0.414678 | 00:00 | . 249 | 1.260192 | 0.414690 | 00:00 | . 250 | 1.260337 | 0.414770 | 00:00 | . 251 | 1.260437 | 0.414922 | 00:00 | . 252 | 1.260386 | 0.415048 | 00:00 | . 253 | 1.260807 | 0.415179 | 00:00 | . 254 | 1.260823 | 0.415388 | 00:00 | . 255 | 1.260450 | 0.415543 | 00:00 | . 256 | 1.259887 | 0.415564 | 00:00 | . 257 | 1.260744 | 0.415475 | 00:00 | . 258 | 1.260584 | 0.415363 | 00:00 | . 259 | 1.260102 | 0.415271 | 00:00 | . 260 | 1.260493 | 0.415210 | 00:00 | . 261 | 1.261114 | 0.415052 | 00:00 | . 262 | 1.261526 | 0.414940 | 00:00 | . 263 | 1.262378 | 0.414868 | 00:00 | . 264 | 1.262951 | 0.414882 | 00:00 | . 265 | 1.261851 | 0.414883 | 00:00 | . 266 | 1.261018 | 0.415026 | 00:00 | . 267 | 1.261060 | 0.415156 | 00:00 | . 268 | 1.260620 | 0.415468 | 00:00 | . 269 | 1.260654 | 0.415736 | 00:00 | . 270 | 1.261062 | 0.416084 | 00:00 | . 271 | 1.260498 | 0.416569 | 00:00 | . 272 | 1.259720 | 0.417042 | 00:00 | . 273 | 1.259454 | 0.417238 | 00:00 | . 274 | 1.260658 | 0.417230 | 00:00 | . 275 | 1.260823 | 0.417146 | 00:00 | . 276 | 1.261402 | 0.417071 | 00:00 | . 277 | 1.261193 | 0.416865 | 00:00 | . 278 | 1.261093 | 0.416369 | 00:00 | . 279 | 1.260752 | 0.415790 | 00:00 | . 280 | 1.259871 | 0.415371 | 00:00 | . 281 | 1.260295 | 0.415107 | 00:00 | . 282 | 1.261554 | 0.414920 | 00:00 | . 283 | 1.260544 | 0.414768 | 00:00 | . 284 | 1.261198 | 0.414729 | 00:00 | . 285 | 1.261943 | 0.414714 | 00:00 | . 286 | 1.262740 | 0.414759 | 00:00 | . 287 | 1.262938 | 0.414813 | 00:00 | . 288 | 1.263016 | 0.414816 | 00:00 | . 289 | 1.263043 | 0.414859 | 00:00 | . 290 | 1.262818 | 0.414990 | 00:00 | . 291 | 1.262254 | 0.415132 | 00:00 | . 292 | 1.260978 | 0.415321 | 00:00 | . 293 | 1.261604 | 0.415454 | 00:00 | . 294 | 1.261581 | 0.415558 | 00:00 | . 295 | 1.260821 | 0.415693 | 00:00 | . 296 | 1.260570 | 0.415885 | 00:00 | . 297 | 1.260560 | 0.415961 | 00:00 | . 298 | 1.261195 | 0.416049 | 00:00 | . 299 | 1.261400 | 0.416104 | 00:00 | . 300 | 1.261205 | 0.416170 | 00:00 | . 301 | 1.261355 | 0.416142 | 00:00 | . 302 | 1.259425 | 0.416087 | 00:00 | . 303 | 1.259368 | 0.415941 | 00:00 | . 304 | 1.258835 | 0.415830 | 00:00 | . 305 | 1.259706 | 0.415696 | 00:00 | . 306 | 1.259063 | 0.415560 | 00:00 | . 307 | 1.259507 | 0.415486 | 00:00 | . 308 | 1.259692 | 0.415500 | 00:00 | . 309 | 1.259614 | 0.415588 | 00:00 | . 310 | 1.258820 | 0.415622 | 00:00 | . 311 | 1.258813 | 0.415674 | 00:00 | . 312 | 1.258649 | 0.415670 | 00:00 | . 313 | 1.259172 | 0.415662 | 00:00 | . 314 | 1.259062 | 0.415642 | 00:00 | . 315 | 1.259079 | 0.415626 | 00:00 | . 316 | 1.259201 | 0.415620 | 00:00 | . 317 | 1.258573 | 0.415631 | 00:00 | . 318 | 1.257818 | 0.415716 | 00:00 | . 319 | 1.258032 | 0.415723 | 00:00 | . 320 | 1.258187 | 0.415761 | 00:00 | . 321 | 1.256670 | 0.415708 | 00:00 | . 322 | 1.256674 | 0.415683 | 00:00 | . 323 | 1.255771 | 0.415637 | 00:00 | . 324 | 1.256651 | 0.415628 | 00:00 | . 325 | 1.257723 | 0.415627 | 00:00 | . 326 | 1.258236 | 0.415562 | 00:00 | . 327 | 1.260004 | 0.415559 | 00:00 | . 328 | 1.261211 | 0.415498 | 00:00 | . 329 | 1.262287 | 0.415496 | 00:00 | . 330 | 1.262388 | 0.415534 | 00:00 | . 331 | 1.261569 | 0.415701 | 00:00 | . 332 | 1.261552 | 0.415993 | 00:00 | . 333 | 1.261779 | 0.416291 | 00:00 | . 334 | 1.261095 | 0.416576 | 00:00 | . 335 | 1.261457 | 0.416848 | 00:00 | . 336 | 1.260691 | 0.417188 | 00:00 | . 337 | 1.260889 | 0.417378 | 00:00 | . 338 | 1.261111 | 0.417348 | 00:00 | . 339 | 1.260750 | 0.417457 | 00:00 | . 340 | 1.260455 | 0.417173 | 00:00 | . 341 | 1.260324 | 0.416843 | 00:00 | . 342 | 1.259526 | 0.416447 | 00:00 | . 343 | 1.258970 | 0.416123 | 00:00 | . 344 | 1.258629 | 0.415814 | 00:00 | . 345 | 1.258803 | 0.415727 | 00:00 | . 346 | 1.258205 | 0.415667 | 00:00 | . 347 | 1.258080 | 0.415866 | 00:00 | . 348 | 1.257673 | 0.415949 | 00:00 | . 349 | 1.257884 | 0.415975 | 00:00 | . 350 | 1.257075 | 0.416021 | 00:00 | . 351 | 1.257156 | 0.416115 | 00:00 | . 352 | 1.256605 | 0.416163 | 00:00 | . 353 | 1.257001 | 0.416402 | 00:00 | . 354 | 1.257280 | 0.416327 | 00:00 | . 355 | 1.257479 | 0.416206 | 00:00 | . 356 | 1.258691 | 0.416209 | 00:00 | . 357 | 1.258769 | 0.416263 | 00:00 | . 358 | 1.258193 | 0.416180 | 00:00 | . 359 | 1.257267 | 0.416178 | 00:00 | . 360 | 1.256823 | 0.416168 | 00:00 | . 361 | 1.257244 | 0.416399 | 00:00 | . 362 | 1.257220 | 0.416601 | 00:00 | . 363 | 1.256693 | 0.416675 | 00:00 | . 364 | 1.256891 | 0.416459 | 00:00 | . 365 | 1.257268 | 0.416113 | 00:00 | . 366 | 1.257393 | 0.415814 | 00:00 | . 367 | 1.257830 | 0.415561 | 00:00 | . 368 | 1.257172 | 0.415421 | 00:00 | . 369 | 1.256837 | 0.415428 | 00:00 | . 370 | 1.256773 | 0.415465 | 00:00 | . 371 | 1.258097 | 0.415457 | 00:00 | . 372 | 1.256546 | 0.415501 | 00:00 | . 373 | 1.257718 | 0.415524 | 00:00 | . 374 | 1.256857 | 0.415532 | 00:00 | . 375 | 1.257733 | 0.415576 | 00:00 | . 376 | 1.258379 | 0.415652 | 00:00 | . 377 | 1.258506 | 0.415776 | 00:00 | . 378 | 1.259018 | 0.415857 | 00:00 | . 379 | 1.258604 | 0.415978 | 00:00 | . 380 | 1.258411 | 0.416004 | 00:00 | . 381 | 1.258609 | 0.416070 | 00:00 | . 382 | 1.258538 | 0.416041 | 00:00 | . 383 | 1.256528 | 0.416063 | 00:00 | . 384 | 1.257431 | 0.416094 | 00:00 | . 385 | 1.258207 | 0.416113 | 00:00 | . 386 | 1.259002 | 0.416143 | 00:00 | . 387 | 1.260184 | 0.416166 | 00:00 | . 388 | 1.260312 | 0.416236 | 00:00 | . 389 | 1.260052 | 0.416307 | 00:00 | . 390 | 1.260179 | 0.416382 | 00:00 | . 391 | 1.259186 | 0.416412 | 00:00 | . 392 | 1.259049 | 0.416487 | 00:00 | . 393 | 1.259521 | 0.416485 | 00:00 | . 394 | 1.259464 | 0.416400 | 00:00 | . 395 | 1.260071 | 0.416365 | 00:00 | . 396 | 1.259407 | 0.416304 | 00:00 | . 397 | 1.258750 | 0.416255 | 00:00 | . 398 | 1.258134 | 0.416256 | 00:00 | . 399 | 1.257712 | 0.416288 | 00:00 | . 400 | 1.257355 | 0.416328 | 00:00 | . 401 | 1.257647 | 0.416391 | 00:00 | . 402 | 1.257173 | 0.416378 | 00:00 | . 403 | 1.257945 | 0.416408 | 00:00 | . 404 | 1.258063 | 0.416465 | 00:00 | . 405 | 1.258375 | 0.416570 | 00:00 | . 406 | 1.257934 | 0.416629 | 00:00 | . 407 | 1.257860 | 0.416787 | 00:00 | . 408 | 1.255629 | 0.416957 | 00:00 | . 409 | 1.255875 | 0.417067 | 00:00 | . 410 | 1.256816 | 0.416962 | 00:00 | . 411 | 1.258186 | 0.416739 | 00:00 | . 412 | 1.258198 | 0.416604 | 00:00 | . 413 | 1.258041 | 0.416505 | 00:00 | . 414 | 1.258548 | 0.416443 | 00:00 | . 415 | 1.258546 | 0.416390 | 00:00 | . 416 | 1.258398 | 0.416387 | 00:00 | . 417 | 1.258750 | 0.416418 | 00:00 | . 418 | 1.257999 | 0.416412 | 00:00 | . 419 | 1.257713 | 0.416507 | 00:00 | . 420 | 1.257705 | 0.416573 | 00:00 | . 421 | 1.256348 | 0.416668 | 00:00 | . 422 | 1.255298 | 0.416765 | 00:00 | . 423 | 1.256077 | 0.416947 | 00:00 | . 424 | 1.256697 | 0.416968 | 00:00 | . 425 | 1.256511 | 0.417058 | 00:00 | . 426 | 1.257012 | 0.417285 | 00:00 | . 427 | 1.257987 | 0.417523 | 00:00 | . 428 | 1.256634 | 0.417687 | 00:00 | . 429 | 1.257175 | 0.417836 | 00:00 | . 430 | 1.257200 | 0.417980 | 00:00 | . 431 | 1.257025 | 0.417888 | 00:00 | . 432 | 1.257266 | 0.417586 | 00:00 | . 433 | 1.257151 | 0.417206 | 00:00 | . 434 | 1.258194 | 0.416839 | 00:00 | . 435 | 1.257728 | 0.416622 | 00:00 | . 436 | 1.256972 | 0.416526 | 00:00 | . 437 | 1.256459 | 0.416481 | 00:00 | . 438 | 1.257136 | 0.416417 | 00:00 | . 439 | 1.255609 | 0.416464 | 00:00 | . 440 | 1.255828 | 0.416546 | 00:00 | . 441 | 1.255814 | 0.416672 | 00:00 | . 442 | 1.255377 | 0.416684 | 00:00 | . 443 | 1.256022 | 0.416734 | 00:00 | . 444 | 1.255588 | 0.416620 | 00:00 | . 445 | 1.256709 | 0.416562 | 00:00 | . 446 | 1.256194 | 0.416580 | 00:00 | . 447 | 1.254689 | 0.416596 | 00:00 | . 448 | 1.255352 | 0.416582 | 00:00 | . 449 | 1.255635 | 0.416610 | 00:00 | . 450 | 1.254791 | 0.416706 | 00:00 | . 451 | 1.254713 | 0.416755 | 00:00 | . 452 | 1.253946 | 0.416835 | 00:00 | . 453 | 1.254879 | 0.416898 | 00:00 | . 454 | 1.255169 | 0.416919 | 00:00 | . 455 | 1.255179 | 0.416997 | 00:00 | . 456 | 1.254341 | 0.417182 | 00:00 | . 457 | 1.254584 | 0.417339 | 00:00 | . 458 | 1.254412 | 0.417416 | 00:00 | . 459 | 1.255029 | 0.417581 | 00:00 | . 460 | 1.254974 | 0.417766 | 00:00 | . 461 | 1.254050 | 0.417977 | 00:00 | . 462 | 1.253457 | 0.418088 | 00:00 | . 463 | 1.252406 | 0.418103 | 00:00 | . 464 | 1.253052 | 0.418131 | 00:00 | . 465 | 1.251714 | 0.418019 | 00:00 | . 466 | 1.252296 | 0.417907 | 00:00 | . 467 | 1.252897 | 0.417586 | 00:00 | . 468 | 1.252321 | 0.417249 | 00:00 | . 469 | 1.252079 | 0.416934 | 00:00 | . 470 | 1.253699 | 0.416780 | 00:00 | . 471 | 1.253219 | 0.416754 | 00:00 | . 472 | 1.253212 | 0.416811 | 00:00 | . 473 | 1.254611 | 0.416853 | 00:00 | . 474 | 1.255168 | 0.416941 | 00:00 | . 475 | 1.254923 | 0.417079 | 00:00 | . 476 | 1.254700 | 0.417303 | 00:00 | . 477 | 1.255456 | 0.417476 | 00:00 | . 478 | 1.256140 | 0.417635 | 00:00 | . 479 | 1.254780 | 0.417804 | 00:00 | . 480 | 1.254050 | 0.417717 | 00:00 | . 481 | 1.254216 | 0.417503 | 00:00 | . 482 | 1.254741 | 0.417370 | 00:00 | . 483 | 1.254952 | 0.417267 | 00:00 | . 484 | 1.254997 | 0.417240 | 00:00 | . 485 | 1.255848 | 0.417207 | 00:00 | . 486 | 1.256285 | 0.417211 | 00:00 | . 487 | 1.256887 | 0.417319 | 00:00 | . 488 | 1.257420 | 0.417401 | 00:00 | . 489 | 1.258119 | 0.417480 | 00:00 | . 490 | 1.257999 | 0.417519 | 00:00 | . 491 | 1.259391 | 0.417516 | 00:00 | . 492 | 1.258172 | 0.417473 | 00:00 | . 493 | 1.258994 | 0.417319 | 00:00 | . 494 | 1.258253 | 0.417279 | 00:00 | . 495 | 1.257434 | 0.417372 | 00:00 | . 496 | 1.259193 | 0.417519 | 00:00 | . 497 | 1.259749 | 0.417734 | 00:00 | . 498 | 1.259684 | 0.417978 | 00:00 | . 499 | 1.259063 | 0.418227 | 00:00 | . 500 | 1.259736 | 0.418191 | 00:00 | . 501 | 1.258454 | 0.418175 | 00:00 | . 502 | 1.257270 | 0.417963 | 00:00 | . 503 | 1.257249 | 0.417880 | 00:00 | . 504 | 1.258347 | 0.417808 | 00:00 | . 505 | 1.257908 | 0.417681 | 00:00 | . 506 | 1.256977 | 0.417540 | 00:00 | . 507 | 1.256562 | 0.417465 | 00:00 | . 508 | 1.257302 | 0.417368 | 00:00 | . 509 | 1.258234 | 0.417363 | 00:00 | . 510 | 1.257863 | 0.417353 | 00:00 | . 511 | 1.258002 | 0.417322 | 00:00 | . 512 | 1.257543 | 0.417338 | 00:00 | . 513 | 1.258104 | 0.417348 | 00:00 | . 514 | 1.258365 | 0.417369 | 00:00 | . 515 | 1.259673 | 0.417384 | 00:00 | . 516 | 1.259469 | 0.417371 | 00:00 | . 517 | 1.259273 | 0.417362 | 00:00 | . 518 | 1.259839 | 0.417379 | 00:00 | . 519 | 1.259408 | 0.417436 | 00:00 | . 520 | 1.258986 | 0.417493 | 00:00 | . 521 | 1.259778 | 0.417557 | 00:00 | . 522 | 1.260360 | 0.417607 | 00:00 | . 523 | 1.260575 | 0.417641 | 00:00 | . 524 | 1.259566 | 0.417628 | 00:00 | . 525 | 1.260778 | 0.417546 | 00:00 | . 526 | 1.259671 | 0.417437 | 00:00 | . 527 | 1.259122 | 0.417357 | 00:00 | . 528 | 1.259833 | 0.417370 | 00:00 | . 529 | 1.259550 | 0.417449 | 00:00 | . 530 | 1.258141 | 0.417584 | 00:00 | . 531 | 1.257117 | 0.417749 | 00:00 | . 532 | 1.258659 | 0.417658 | 00:00 | . 533 | 1.259609 | 0.417559 | 00:00 | . 534 | 1.259593 | 0.417412 | 00:00 | . 535 | 1.258892 | 0.417365 | 00:00 | . 536 | 1.257787 | 0.417395 | 00:00 | . 537 | 1.256745 | 0.417490 | 00:00 | . 538 | 1.257629 | 0.417655 | 00:00 | . 539 | 1.258589 | 0.417814 | 00:00 | . 540 | 1.258822 | 0.417800 | 00:00 | . 541 | 1.259192 | 0.417779 | 00:00 | . 542 | 1.258760 | 0.417824 | 00:00 | . 543 | 1.259815 | 0.417891 | 00:00 | . 544 | 1.259474 | 0.418028 | 00:00 | . 545 | 1.260403 | 0.418049 | 00:00 | . 546 | 1.260596 | 0.417842 | 00:00 | . 547 | 1.260703 | 0.417590 | 00:00 | . 548 | 1.260031 | 0.417332 | 00:00 | . 549 | 1.258422 | 0.417224 | 00:00 | . 550 | 1.257777 | 0.417150 | 00:00 | . 551 | 1.257236 | 0.417216 | 00:00 | . 552 | 1.256627 | 0.417315 | 00:00 | . 553 | 1.257114 | 0.417402 | 00:00 | . 554 | 1.256038 | 0.417420 | 00:00 | . 555 | 1.255992 | 0.417333 | 00:00 | . 556 | 1.256631 | 0.417248 | 00:00 | . 557 | 1.255195 | 0.417135 | 00:00 | . 558 | 1.254154 | 0.417122 | 00:00 | . 559 | 1.254753 | 0.417229 | 00:00 | . 560 | 1.254460 | 0.417409 | 00:00 | . 561 | 1.254844 | 0.417574 | 00:00 | . 562 | 1.254276 | 0.417761 | 00:00 | . 563 | 1.254521 | 0.418054 | 00:00 | . 564 | 1.254765 | 0.418376 | 00:00 | . 565 | 1.254545 | 0.418849 | 00:00 | . 566 | 1.255240 | 0.419076 | 00:00 | . 567 | 1.254727 | 0.419140 | 00:00 | . 568 | 1.254117 | 0.419143 | 00:00 | . 569 | 1.254685 | 0.418893 | 00:00 | . 570 | 1.254605 | 0.418584 | 00:00 | . 571 | 1.255417 | 0.418259 | 00:00 | . 572 | 1.256842 | 0.417955 | 00:00 | . 573 | 1.256608 | 0.417700 | 00:00 | . 574 | 1.256457 | 0.417581 | 00:00 | . 575 | 1.256952 | 0.417428 | 00:00 | . 576 | 1.256556 | 0.417320 | 00:00 | . 577 | 1.255948 | 0.417305 | 00:00 | . 578 | 1.256232 | 0.417338 | 00:00 | . 579 | 1.255656 | 0.417339 | 00:00 | . 580 | 1.254732 | 0.417326 | 00:00 | . 581 | 1.254624 | 0.417364 | 00:00 | . 582 | 1.255069 | 0.417387 | 00:00 | . 583 | 1.255514 | 0.417371 | 00:00 | . 584 | 1.256267 | 0.417424 | 00:00 | . 585 | 1.256683 | 0.417452 | 00:00 | . 586 | 1.256834 | 0.417501 | 00:00 | . 587 | 1.257035 | 0.417447 | 00:00 | . 588 | 1.256279 | 0.417448 | 00:00 | . 589 | 1.256109 | 0.417420 | 00:00 | . 590 | 1.255301 | 0.417432 | 00:00 | . 591 | 1.254050 | 0.417454 | 00:00 | . 592 | 1.253268 | 0.417429 | 00:00 | . 593 | 1.253519 | 0.417427 | 00:00 | . 594 | 1.252748 | 0.417372 | 00:00 | . 595 | 1.252638 | 0.417341 | 00:00 | . 596 | 1.253352 | 0.417339 | 00:00 | . 597 | 1.254823 | 0.417305 | 00:00 | . 598 | 1.255010 | 0.417288 | 00:00 | . 599 | 1.255095 | 0.417300 | 00:00 | . 600 | 1.255105 | 0.417285 | 00:00 | . 601 | 1.254501 | 0.417341 | 00:00 | . 602 | 1.253969 | 0.417323 | 00:00 | . 603 | 1.255027 | 0.417389 | 00:00 | . 604 | 1.254061 | 0.417496 | 00:00 | . 605 | 1.253574 | 0.417684 | 00:00 | . 606 | 1.254685 | 0.417714 | 00:00 | . 607 | 1.254056 | 0.417617 | 00:00 | . 608 | 1.254647 | 0.417501 | 00:00 | . 609 | 1.254047 | 0.417355 | 00:00 | . 610 | 1.254412 | 0.417225 | 00:00 | . 611 | 1.254192 | 0.417116 | 00:00 | . 612 | 1.254154 | 0.416999 | 00:00 | . 613 | 1.253608 | 0.416884 | 00:00 | . 614 | 1.252986 | 0.416823 | 00:00 | . 615 | 1.254104 | 0.416799 | 00:00 | . 616 | 1.254848 | 0.416818 | 00:00 | . 617 | 1.256397 | 0.416812 | 00:00 | . 618 | 1.256382 | 0.416881 | 00:00 | . 619 | 1.255967 | 0.416983 | 00:00 | . 620 | 1.255186 | 0.417103 | 00:00 | . 621 | 1.254529 | 0.417178 | 00:00 | . 622 | 1.253507 | 0.417180 | 00:00 | . 623 | 1.253557 | 0.417170 | 00:00 | . 624 | 1.252744 | 0.417183 | 00:00 | . 625 | 1.252467 | 0.417335 | 00:00 | . 626 | 1.253113 | 0.417502 | 00:00 | . 627 | 1.253735 | 0.417656 | 00:00 | . 628 | 1.253027 | 0.417686 | 00:00 | . 629 | 1.253529 | 0.417830 | 00:00 | . 630 | 1.254242 | 0.417834 | 00:00 | . 631 | 1.254006 | 0.417763 | 00:00 | . 632 | 1.254943 | 0.417716 | 00:00 | . 633 | 1.255651 | 0.417695 | 00:00 | . 634 | 1.254264 | 0.417794 | 00:00 | . 635 | 1.255637 | 0.417828 | 00:00 | . 636 | 1.255834 | 0.417958 | 00:00 | . 637 | 1.256925 | 0.418171 | 00:00 | . 638 | 1.256941 | 0.418457 | 00:00 | . 639 | 1.257372 | 0.418614 | 00:00 | . 640 | 1.257380 | 0.418848 | 00:00 | . 641 | 1.257553 | 0.419050 | 00:00 | . 642 | 1.258051 | 0.419347 | 00:00 | . 643 | 1.258726 | 0.419728 | 00:00 | . 644 | 1.258703 | 0.420287 | 00:00 | . 645 | 1.259233 | 0.420595 | 00:00 | . 646 | 1.259492 | 0.421041 | 00:00 | . 647 | 1.259388 | 0.421211 | 00:00 | . 648 | 1.259060 | 0.421273 | 00:00 | . 649 | 1.259425 | 0.421335 | 00:00 | . 650 | 1.259399 | 0.420994 | 00:00 | . 651 | 1.258782 | 0.420668 | 00:00 | . 652 | 1.259525 | 0.420266 | 00:00 | . 653 | 1.259607 | 0.419924 | 00:00 | . 654 | 1.259405 | 0.419725 | 00:00 | . 655 | 1.258337 | 0.419336 | 00:00 | . 656 | 1.258083 | 0.419112 | 00:00 | . 657 | 1.257674 | 0.418870 | 00:00 | . 658 | 1.257254 | 0.418719 | 00:00 | . 659 | 1.256844 | 0.418699 | 00:00 | . 660 | 1.255691 | 0.418674 | 00:00 | . 661 | 1.255406 | 0.418651 | 00:00 | . 662 | 1.254959 | 0.418722 | 00:00 | . 663 | 1.255317 | 0.418769 | 00:00 | . 664 | 1.253713 | 0.418796 | 00:00 | . 665 | 1.254047 | 0.418845 | 00:00 | . 666 | 1.253414 | 0.418934 | 00:00 | . 667 | 1.252725 | 0.419075 | 00:00 | . 668 | 1.252363 | 0.419308 | 00:00 | . 669 | 1.252075 | 0.419438 | 00:00 | . 670 | 1.252151 | 0.419428 | 00:00 | . 671 | 1.252124 | 0.419560 | 00:00 | . 672 | 1.250017 | 0.419637 | 00:00 | . 673 | 1.250373 | 0.419722 | 00:00 | . 674 | 1.250739 | 0.419954 | 00:00 | . 675 | 1.250482 | 0.420195 | 00:00 | . 676 | 1.251180 | 0.420441 | 00:00 | . 677 | 1.250756 | 0.420122 | 00:00 | . 678 | 1.250522 | 0.419882 | 00:00 | . 679 | 1.249588 | 0.419433 | 00:00 | . 680 | 1.250952 | 0.419075 | 00:00 | . 681 | 1.250829 | 0.418629 | 00:00 | . 682 | 1.250966 | 0.418387 | 00:00 | . 683 | 1.251599 | 0.418235 | 00:00 | . 684 | 1.252123 | 0.418105 | 00:00 | . 685 | 1.251732 | 0.418010 | 00:00 | . 686 | 1.252659 | 0.417995 | 00:00 | . 687 | 1.253269 | 0.418003 | 00:00 | . 688 | 1.253756 | 0.418070 | 00:00 | . 689 | 1.254092 | 0.418135 | 00:00 | . 690 | 1.253780 | 0.418148 | 00:00 | . 691 | 1.255441 | 0.418290 | 00:00 | . 692 | 1.255950 | 0.418471 | 00:00 | . 693 | 1.255347 | 0.418591 | 00:00 | . 694 | 1.255267 | 0.418585 | 00:00 | . 695 | 1.254356 | 0.418510 | 00:00 | . 696 | 1.254368 | 0.418439 | 00:00 | . 697 | 1.254296 | 0.418406 | 00:00 | . 698 | 1.254683 | 0.418314 | 00:00 | . 699 | 1.255351 | 0.418372 | 00:00 | . 700 | 1.256074 | 0.418487 | 00:00 | . 701 | 1.257236 | 0.418587 | 00:00 | . 702 | 1.257251 | 0.418653 | 00:00 | . 703 | 1.257116 | 0.418739 | 00:00 | . 704 | 1.256438 | 0.418791 | 00:00 | . 705 | 1.257506 | 0.418792 | 00:00 | . 706 | 1.256480 | 0.418693 | 00:00 | . 707 | 1.257963 | 0.418721 | 00:00 | . 708 | 1.258377 | 0.418618 | 00:00 | . 709 | 1.257895 | 0.418553 | 00:00 | . 710 | 1.257440 | 0.418464 | 00:00 | . 711 | 1.256983 | 0.418386 | 00:00 | . 712 | 1.256140 | 0.418346 | 00:00 | . 713 | 1.255827 | 0.418219 | 00:00 | . 714 | 1.255166 | 0.418074 | 00:00 | . 715 | 1.254865 | 0.418011 | 00:00 | . 716 | 1.254496 | 0.418001 | 00:00 | . 717 | 1.255271 | 0.418005 | 00:00 | . 718 | 1.253770 | 0.417955 | 00:00 | . 719 | 1.252702 | 0.417983 | 00:00 | . 720 | 1.251531 | 0.417898 | 00:00 | . 721 | 1.252870 | 0.417888 | 00:00 | . 722 | 1.252389 | 0.417853 | 00:00 | . 723 | 1.252741 | 0.417848 | 00:00 | . 724 | 1.254278 | 0.417847 | 00:00 | . 725 | 1.255494 | 0.417830 | 00:00 | . 726 | 1.255504 | 0.417871 | 00:00 | . 727 | 1.255512 | 0.417854 | 00:00 | . 728 | 1.255251 | 0.417919 | 00:00 | . 729 | 1.256331 | 0.417931 | 00:00 | . 730 | 1.257599 | 0.418054 | 00:00 | . 731 | 1.257723 | 0.418341 | 00:00 | . 732 | 1.257198 | 0.418810 | 00:00 | . 733 | 1.259164 | 0.419271 | 00:00 | . 734 | 1.260187 | 0.419527 | 00:00 | . 735 | 1.259421 | 0.419677 | 00:00 | . 736 | 1.260312 | 0.419772 | 00:00 | . 737 | 1.260244 | 0.419768 | 00:00 | . 738 | 1.260135 | 0.419598 | 00:00 | . 739 | 1.259702 | 0.419515 | 00:00 | . 740 | 1.258342 | 0.419450 | 00:00 | . 741 | 1.258506 | 0.419550 | 00:00 | . 742 | 1.258918 | 0.419634 | 00:00 | . 743 | 1.258832 | 0.419847 | 00:00 | . 744 | 1.259233 | 0.419851 | 00:00 | . 745 | 1.258753 | 0.419878 | 00:00 | . 746 | 1.259147 | 0.419706 | 00:00 | . 747 | 1.259107 | 0.419455 | 00:00 | . 748 | 1.258659 | 0.419398 | 00:00 | . 749 | 1.257553 | 0.419165 | 00:00 | . 750 | 1.257354 | 0.419028 | 00:00 | . 751 | 1.256456 | 0.418977 | 00:00 | . 752 | 1.256247 | 0.418882 | 00:00 | . 753 | 1.256017 | 0.418729 | 00:00 | . 754 | 1.256718 | 0.418628 | 00:00 | . 755 | 1.256175 | 0.418585 | 00:00 | . 756 | 1.256170 | 0.418705 | 00:00 | . 757 | 1.257845 | 0.418671 | 00:00 | . 758 | 1.256669 | 0.418630 | 00:00 | . 759 | 1.257259 | 0.418635 | 00:00 | . 760 | 1.256543 | 0.418580 | 00:00 | . 761 | 1.256610 | 0.418517 | 00:00 | . 762 | 1.256764 | 0.418472 | 00:00 | . 763 | 1.257801 | 0.418474 | 00:00 | . 764 | 1.258007 | 0.418379 | 00:00 | . 765 | 1.257721 | 0.418301 | 00:00 | . 766 | 1.256297 | 0.418329 | 00:00 | . 767 | 1.257098 | 0.418366 | 00:00 | . 768 | 1.257081 | 0.418339 | 00:00 | . 769 | 1.256290 | 0.418409 | 00:00 | . 770 | 1.256938 | 0.418409 | 00:00 | . 771 | 1.256607 | 0.418265 | 00:00 | . 772 | 1.256893 | 0.418163 | 00:00 | . 773 | 1.255576 | 0.418121 | 00:00 | . 774 | 1.255781 | 0.418045 | 00:00 | . 775 | 1.256092 | 0.417921 | 00:00 | . 776 | 1.255717 | 0.417888 | 00:00 | . 777 | 1.256148 | 0.417900 | 00:00 | . 778 | 1.257146 | 0.417964 | 00:00 | . 779 | 1.257630 | 0.418007 | 00:00 | . 780 | 1.257343 | 0.418076 | 00:00 | . 781 | 1.257887 | 0.418149 | 00:00 | . 782 | 1.257479 | 0.418271 | 00:00 | . 783 | 1.257531 | 0.418370 | 00:00 | . 784 | 1.257016 | 0.418578 | 00:00 | . 785 | 1.257205 | 0.418773 | 00:00 | . 786 | 1.258113 | 0.419069 | 00:00 | . 787 | 1.258588 | 0.419256 | 00:00 | . 788 | 1.257640 | 0.419372 | 00:00 | . 789 | 1.256643 | 0.419506 | 00:00 | . 790 | 1.255288 | 0.419415 | 00:00 | . 791 | 1.256897 | 0.419371 | 00:00 | . 792 | 1.257112 | 0.419275 | 00:00 | . 793 | 1.257971 | 0.419206 | 00:00 | . 794 | 1.257432 | 0.419216 | 00:00 | . 795 | 1.257355 | 0.419011 | 00:00 | . 796 | 1.256506 | 0.419157 | 00:00 | . 797 | 1.256506 | 0.419027 | 00:00 | . 798 | 1.255643 | 0.418919 | 00:00 | . 799 | 1.255393 | 0.418940 | 00:00 | . 800 | 1.254678 | 0.418918 | 00:00 | . 801 | 1.254200 | 0.418850 | 00:00 | . 802 | 1.253886 | 0.418741 | 00:00 | . 803 | 1.254084 | 0.418604 | 00:00 | . 804 | 1.253742 | 0.418609 | 00:00 | . 805 | 1.253409 | 0.418722 | 00:00 | . 806 | 1.253756 | 0.418975 | 00:00 | . 807 | 1.254492 | 0.419137 | 00:00 | . 808 | 1.253721 | 0.419245 | 00:00 | . 809 | 1.254305 | 0.419398 | 00:00 | . 810 | 1.252965 | 0.419336 | 00:00 | . 811 | 1.252414 | 0.419296 | 00:00 | . 812 | 1.252219 | 0.419170 | 00:00 | . 813 | 1.253034 | 0.419227 | 00:00 | . 814 | 1.254304 | 0.419014 | 00:00 | . 815 | 1.253733 | 0.418821 | 00:00 | . 816 | 1.254755 | 0.418619 | 00:00 | . 817 | 1.254404 | 0.418533 | 00:00 | . 818 | 1.253698 | 0.418500 | 00:00 | . 819 | 1.253306 | 0.418461 | 00:00 | . 820 | 1.253673 | 0.418413 | 00:00 | . 821 | 1.253855 | 0.418475 | 00:00 | . 822 | 1.252897 | 0.418555 | 00:00 | . 823 | 1.252822 | 0.418595 | 00:00 | . 824 | 1.252622 | 0.418691 | 00:00 | . 825 | 1.252916 | 0.418865 | 00:00 | . 826 | 1.252318 | 0.419072 | 00:00 | . 827 | 1.252828 | 0.419530 | 00:00 | . 828 | 1.252752 | 0.419867 | 00:00 | . 829 | 1.252373 | 0.419997 | 00:00 | . 830 | 1.251364 | 0.420107 | 00:00 | . 831 | 1.251843 | 0.419962 | 00:00 | . 832 | 1.251352 | 0.419714 | 00:00 | . 833 | 1.251852 | 0.419556 | 00:00 | . 834 | 1.251665 | 0.419518 | 00:00 | . 835 | 1.251825 | 0.419675 | 00:00 | . 836 | 1.251403 | 0.419708 | 00:00 | . 837 | 1.250961 | 0.419663 | 00:00 | . 838 | 1.250765 | 0.419703 | 00:00 | . 839 | 1.253064 | 0.419598 | 00:00 | . 840 | 1.252290 | 0.419426 | 00:00 | . 841 | 1.252441 | 0.419128 | 00:00 | . 842 | 1.252413 | 0.418691 | 00:00 | . 843 | 1.253026 | 0.418347 | 00:00 | . 844 | 1.253847 | 0.417974 | 00:00 | . 845 | 1.252718 | 0.417671 | 00:00 | . 846 | 1.252363 | 0.417399 | 00:00 | . 847 | 1.252967 | 0.417206 | 00:00 | . 848 | 1.253104 | 0.417160 | 00:00 | . 849 | 1.251515 | 0.417115 | 00:00 | . 850 | 1.250911 | 0.417152 | 00:00 | . 851 | 1.250758 | 0.417228 | 00:00 | . 852 | 1.251940 | 0.417301 | 00:00 | . 853 | 1.251687 | 0.417374 | 00:00 | . 854 | 1.252200 | 0.417515 | 00:00 | . 855 | 1.250863 | 0.417651 | 00:00 | . 856 | 1.250320 | 0.417737 | 00:00 | . 857 | 1.250827 | 0.418038 | 00:00 | . 858 | 1.252078 | 0.418172 | 00:00 | . 859 | 1.250976 | 0.418215 | 00:00 | . 860 | 1.252277 | 0.418200 | 00:00 | . 861 | 1.253607 | 0.418286 | 00:00 | . 862 | 1.253394 | 0.418352 | 00:00 | . 863 | 1.254361 | 0.418411 | 00:00 | . 864 | 1.252356 | 0.418308 | 00:00 | . 865 | 1.252000 | 0.418331 | 00:00 | . 866 | 1.253731 | 0.418407 | 00:00 | . 867 | 1.253585 | 0.418304 | 00:00 | . 868 | 1.253058 | 0.418292 | 00:00 | . 869 | 1.252240 | 0.418205 | 00:00 | . 870 | 1.252290 | 0.417972 | 00:00 | . 871 | 1.251787 | 0.417695 | 00:00 | . 872 | 1.251186 | 0.417537 | 00:00 | . 873 | 1.250453 | 0.417415 | 00:00 | . 874 | 1.249308 | 0.417343 | 00:00 | . 875 | 1.248041 | 0.417316 | 00:00 | . 876 | 1.248971 | 0.417350 | 00:00 | . 877 | 1.249282 | 0.417515 | 00:00 | . 878 | 1.250003 | 0.417745 | 00:00 | . 879 | 1.249622 | 0.417942 | 00:00 | . 880 | 1.249009 | 0.418141 | 00:00 | . 881 | 1.248481 | 0.418244 | 00:00 | . 882 | 1.248315 | 0.418388 | 00:00 | . 883 | 1.248033 | 0.418676 | 00:00 | . 884 | 1.248412 | 0.419054 | 00:00 | . 885 | 1.248294 | 0.419440 | 00:00 | . 886 | 1.248723 | 0.419592 | 00:00 | . 887 | 1.251087 | 0.419717 | 00:00 | . 888 | 1.251092 | 0.419801 | 00:00 | . 889 | 1.252259 | 0.420052 | 00:00 | . 890 | 1.251849 | 0.420108 | 00:00 | . 891 | 1.251352 | 0.419950 | 00:00 | . 892 | 1.251564 | 0.419784 | 00:00 | . 893 | 1.251999 | 0.419522 | 00:00 | . 894 | 1.252160 | 0.419590 | 00:00 | . 895 | 1.252530 | 0.419786 | 00:00 | . 896 | 1.252711 | 0.419808 | 00:00 | . 897 | 1.253477 | 0.419810 | 00:00 | . 898 | 1.253455 | 0.419924 | 00:00 | . 899 | 1.254670 | 0.419965 | 00:00 | . 900 | 1.255481 | 0.419944 | 00:00 | . 901 | 1.254356 | 0.419817 | 00:00 | . 902 | 1.254913 | 0.419632 | 00:00 | . 903 | 1.253532 | 0.419487 | 00:00 | . 904 | 1.253255 | 0.419097 | 00:00 | . 905 | 1.252708 | 0.419036 | 00:00 | . 906 | 1.252561 | 0.419068 | 00:00 | . 907 | 1.252680 | 0.418976 | 00:00 | . 908 | 1.252149 | 0.418756 | 00:00 | . 909 | 1.250993 | 0.418537 | 00:00 | . 910 | 1.251960 | 0.418393 | 00:00 | . 911 | 1.252674 | 0.418296 | 00:00 | . 912 | 1.251747 | 0.418233 | 00:00 | . 913 | 1.251824 | 0.418156 | 00:00 | . 914 | 1.251219 | 0.418109 | 00:00 | . 915 | 1.253065 | 0.418052 | 00:00 | . 916 | 1.253257 | 0.417989 | 00:00 | . 917 | 1.253341 | 0.418080 | 00:00 | . 918 | 1.253126 | 0.418063 | 00:00 | . 919 | 1.253038 | 0.418357 | 00:00 | . 920 | 1.251756 | 0.418506 | 00:00 | . 921 | 1.251067 | 0.418785 | 00:00 | . 922 | 1.250499 | 0.419286 | 00:00 | . 923 | 1.250409 | 0.419860 | 00:00 | . 924 | 1.249175 | 0.420018 | 00:00 | . 925 | 1.251091 | 0.419976 | 00:00 | . 926 | 1.250902 | 0.419806 | 00:00 | . 927 | 1.249775 | 0.419615 | 00:00 | . 928 | 1.251549 | 0.419364 | 00:00 | . 929 | 1.252027 | 0.419200 | 00:00 | . 930 | 1.252853 | 0.419226 | 00:00 | . 931 | 1.251084 | 0.419071 | 00:00 | . 932 | 1.249387 | 0.418813 | 00:00 | . 933 | 1.249429 | 0.418544 | 00:00 | . 934 | 1.249426 | 0.418112 | 00:00 | . 935 | 1.249481 | 0.417916 | 00:00 | . 936 | 1.250262 | 0.417585 | 00:00 | . 937 | 1.249950 | 0.417351 | 00:00 | . 938 | 1.249791 | 0.417287 | 00:00 | . 939 | 1.251363 | 0.417105 | 00:00 | . 940 | 1.250923 | 0.417015 | 00:00 | . 941 | 1.252700 | 0.416803 | 00:00 | . 942 | 1.253147 | 0.416706 | 00:00 | . 943 | 1.251844 | 0.416613 | 00:00 | . 944 | 1.252427 | 0.416528 | 00:00 | . 945 | 1.250976 | 0.416559 | 00:00 | . 946 | 1.250111 | 0.416549 | 00:00 | . 947 | 1.249341 | 0.416541 | 00:00 | . 948 | 1.250865 | 0.416483 | 00:00 | . 949 | 1.251180 | 0.416449 | 00:00 | . 950 | 1.251580 | 0.416432 | 00:00 | . 951 | 1.252134 | 0.416476 | 00:00 | . 952 | 1.251618 | 0.416570 | 00:00 | . 953 | 1.252212 | 0.416700 | 00:00 | . 954 | 1.252755 | 0.416778 | 00:00 | . 955 | 1.253621 | 0.416887 | 00:00 | . 956 | 1.252054 | 0.416982 | 00:00 | . 957 | 1.252360 | 0.417189 | 00:00 | . 958 | 1.252055 | 0.417252 | 00:00 | . 959 | 1.252631 | 0.417193 | 00:00 | . 960 | 1.252747 | 0.416961 | 00:00 | . 961 | 1.251930 | 0.416676 | 00:00 | . 962 | 1.251813 | 0.416634 | 00:00 | . 963 | 1.252264 | 0.416584 | 00:00 | . 964 | 1.251811 | 0.416528 | 00:00 | . 965 | 1.252234 | 0.416431 | 00:00 | . 966 | 1.251217 | 0.416465 | 00:00 | . 967 | 1.250181 | 0.416496 | 00:00 | . 968 | 1.249270 | 0.416629 | 00:00 | . 969 | 1.247950 | 0.416647 | 00:00 | . 970 | 1.248172 | 0.416650 | 00:00 | . 971 | 1.249254 | 0.416647 | 00:00 | . 972 | 1.249677 | 0.416722 | 00:00 | . 973 | 1.250601 | 0.416646 | 00:00 | . 974 | 1.251258 | 0.416676 | 00:00 | . 975 | 1.252234 | 0.416820 | 00:00 | . 976 | 1.251912 | 0.417014 | 00:00 | . 977 | 1.252149 | 0.417206 | 00:00 | . 978 | 1.252563 | 0.417480 | 00:00 | . 979 | 1.252951 | 0.417634 | 00:00 | . 980 | 1.252083 | 0.417879 | 00:00 | . 981 | 1.252725 | 0.418452 | 00:00 | . 982 | 1.252368 | 0.419144 | 00:00 | . 983 | 1.252005 | 0.419863 | 00:00 | . 984 | 1.252184 | 0.420550 | 00:00 | . 985 | 1.251891 | 0.421087 | 00:00 | . 986 | 1.253375 | 0.421186 | 00:00 | . 987 | 1.253336 | 0.420905 | 00:00 | . 988 | 1.253251 | 0.420384 | 00:00 | . 989 | 1.253053 | 0.419786 | 00:00 | . 990 | 1.252888 | 0.419180 | 00:00 | . 991 | 1.253548 | 0.418379 | 00:00 | . 992 | 1.254290 | 0.417547 | 00:00 | . 993 | 1.253823 | 0.416934 | 00:00 | . 994 | 1.253618 | 0.416620 | 00:00 | . 995 | 1.253373 | 0.416484 | 00:00 | . 996 | 1.254487 | 0.416502 | 00:00 | . 997 | 1.254675 | 0.416632 | 00:00 | . 998 | 1.256227 | 0.416708 | 00:00 | . 999 | 1.256344 | 0.416772 | 00:00 | . . - loss들도 에폭별로 기록되어 있음 . - 학습 중 오류가 나서 다시 시작했더니 - 자에 가까운 모양으로 그래프가 나왔다 . lrnr.recorder.plot_loss() . - net_fastai에도 파라메터가 업데이트 되어있음 . . 리스트를 확인해보면 net_fastai 의 파라메터가 알아서 GPU로 옮겨져서 학습됨. | . - 플랏 . net_fastai.to(&quot;cpu&quot;) plt.plot(X,y,&#39;.&#39;) plt.plot(X_tr,net_fastai(X_tr).data) plt.plot(X_val,net_fastai(X_val).data) . [&lt;matplotlib.lines.Line2D at 0x7f4058464a90&gt;] . CPU vs GPU &#49884;&#44036;&#48708;&#44368; . import time . time.time() #초단위 시간을 보여줌 . 1641220642.7487211 . CPU (512) . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . t1=time.time() for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() t2=time.time() . t2-t1 . 0.28043293952941895 . GPU (512) . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Linear(in_features=512,out_features=1)) net.to(&quot;cuda:0&quot;) X=X.to(&quot;cuda:0&quot;) y=y.to(&quot;cuda:0&quot;) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . t1=time.time() for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() t2=time.time() . t2-t1 . 0.44712090492248535 . - ?? CPU가 더 빠르다!! . CPU (20480) . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=20480), torch.nn.ReLU(), torch.nn.Linear(in_features=20480,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . t1=time.time() for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() t2=time.time() . t2-t1 . 1.9087340831756592 . GPU (20480) . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=20480), torch.nn.ReLU(), torch.nn.Linear(in_features=20480,out_features=1)) net.to(&quot;cuda:0&quot;) X=X.to(&quot;cuda:0&quot;) y=y.to(&quot;cuda:0&quot;) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . t1=time.time() for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() t2=time.time() . t2-t1 . 0.45605039596557617 . CPU (204800) . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=204800), torch.nn.ReLU(), torch.nn.Linear(in_features=204800,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . t1=time.time() for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() t2=time.time() . t2-t1 . 51.90764856338501 . GPU (204800) . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=204800), torch.nn.ReLU(), torch.nn.Linear(in_features=204800,out_features=1)) net.to(&quot;cuda:0&quot;) X=X.to(&quot;cuda:0&quot;) y=y.to(&quot;cuda:0&quot;) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . t1=time.time() for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() t2=time.time() . t2-t1 . 1.4674291610717773 . - 사이즈가 큰 네트워크일수록 GPU가 더 좋다! . &#49689;&#51228; . - 현재 작업하고 있는 컴퓨터에서 아래코드를 실행후 시간을 출력하여 스샷제출 . CPU (512) . torch.manual_seed(5) X=torch.linspace(0,1,100).reshape(100,1) y=torch.randn(100).reshape(100,1)*0.01 . torch.manual_seed(1) # 초기가중치를 똑같이 net=torch.nn.Sequential( torch.nn.Linear(in_features=1,out_features=512), torch.nn.ReLU(), torch.nn.Linear(in_features=512,out_features=1)) optimizer= torch.optim.Adam(net.parameters()) loss_fn= torch.nn.MSELoss() . t1=time.time() for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(yhat,y) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() t2=time.time() . t2-t1 . 0.26400113105773926 .",
            "url": "https://kimha02.github.io/ham/python/2021/10/19/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9419%EC%9D%BC.html",
            "relUrl": "/python/2021/10/19/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9419%EC%9D%BC.html",
            "date": " • Oct 19, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "(6주차) 10월14일",
            "content": ". 아이디어 : 어떻게 해야 메모리를 줄일 수 있을까? | . import . import torch from fastai.vision.all import * . Dataset . X=torch.tensor([3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]) y=torch.tensor([1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]) . X,y . (tensor([3., 4., 5., 6., 7., 8., 9.]), tensor([1., 0., 1., 0., 1., 1., 0.])) . ds=torch.utils.data.TensorDataset(X,y) . ds ## 그냥 텐서들의 pair . &lt;torch.utils.data.dataset.TensorDataset at 0x7efb9214f1f0&gt; . ds.tensors . (tensor([3., 4., 5., 6., 7., 8., 9.]), tensor([1., 0., 1., 0., 1., 1., 0.])) . DataLoader . - 데이터를 가져와 여러 개의 그룹으로 나눈 후 반복 작업하는 것을 수월하게 해주는 DataLoader . - 배치사이즈=2(데이터가 2개 들어갈 수 있음), 셔플= True, . dl=torch.utils.data.DataLoader(ds,batch_size=2,shuffle=True) . dl . &lt;torch.utils.data.dataloader.DataLoader at 0x7efb9232eac0&gt; . dir(dl) . [&#39;_DataLoader__initialized&#39;, &#39;_DataLoader__multiprocessing_context&#39;, &#39;_IterableDataset_len_called&#39;, &#39;__annotations__&#39;, &#39;__class__&#39;, &#39;__class_getitem__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__len__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__orig_bases__&#39;, &#39;__parameters__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__slots__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_auto_collation&#39;, &#39;_dataset_kind&#39;, &#39;_get_iterator&#39;, &#39;_index_sampler&#39;, &#39;_is_protocol&#39;, &#39;_iterator&#39;, &#39;batch_sampler&#39;, &#39;batch_size&#39;, &#39;check_worker_number_rationality&#39;, &#39;collate_fn&#39;, &#39;dataset&#39;, &#39;drop_last&#39;, &#39;generator&#39;, &#39;multiprocessing_context&#39;, &#39;num_workers&#39;, &#39;persistent_workers&#39;, &#39;pin_memory&#39;, &#39;prefetch_factor&#39;, &#39;sampler&#39;, &#39;timeout&#39;, &#39;worker_init_fn&#39;] . dl은 배치(batch_데이터의 묶음)를 만드는 기능이 있어보임 | . dl.dataset.tensors . (tensor([3., 4., 5., 6., 7., 8., 9.]), tensor([1., 0., 1., 0., 1., 1., 0.])) . for xx,yy in dl: print(xx,yy) . tensor([9., 3., 4.]) tensor([0., 1., 0.]) tensor([6., 5., 7.]) tensor([0., 1., 1.]) tensor([8.]) tensor([1.]) . - 배치사이즈=2, 셔플= False . dl=torch.utils.data.DataLoader(ds,batch_size=2,shuffle=False) . for xx,yy in dl: print(xx,yy) . tensor([3., 4.]) tensor([1., 0.]) tensor([5., 6.]) tensor([1., 0.]) tensor([7., 8.]) tensor([1., 1.]) tensor([9.]) tensor([0.]) . - 배치사이즈=3, 셔플= True - 랜덤하게 계속 섞임 . dl=torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True) . for xx,yy in dl: print(xx,yy) . tensor([8., 9., 3.]) tensor([1., 0., 1.]) tensor([6., 4., 5.]) tensor([0., 0., 1.]) tensor([7.]) tensor([1.]) . MNIST 3/7 &#50696;&#51228; . - 미니배치로 이전 예제를 실행하여 비교해보자 . - 우선 텐서로 이루어진 X,y를 만들자. . path = untar_data(URLs.MNIST_SAMPLE) #데이터 다운로드 . threes=(path/&#39;train&#39;/&#39;3&#39;).ls() sevens=(path/&#39;train&#39;/&#39;7&#39;).ls() . seven_tensor = torch.stack([tensor(Image.open(i)) for i in sevens]).float()/255 #리스트를 텐서로! three_tensor = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255 . three_tensor.shape, seven_tensor.shape . (torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28])) . X=torch.vstack([seven_tensor,three_tensor]).reshape(12396,-1) #vstack으로 합치고 reshape y=torch.tensor([0.0]*6265 + [1.0]*6131).reshape(12396,1) #0을 seven_tensor만큼, 1을 three_tensor만큼 만들어서 tensor로 바꿔준다 . X.shape, y.shape . (torch.Size([12396, 784]), torch.Size([12396, 1])) . 784=28*28임. 이미지로 된 것을 풀어서 나열한 것 . - dataset=(X,y) 를 만들자. . ds=torch.utils.data.TensorDataset(X,y) . ds . &lt;torch.utils.data.dataset.TensorDataset at 0x7efb939861c0&gt; . ds.tensors . (tensor([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]), tensor([[0.], [0.], [0.], ..., [1.], [1.], [1.]])) . - dataloader를 만들자. . 2048개씩 묶고 무작위로 계속 섞인다 . dl=torch.utils.data.DataLoader(ds,batch_size=2048,shuffle=True) . - 네트워크(아키텍처), 손실함수, 옵티마이저 . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=784,out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30,out_features=1) #torch.nn.Sigmoid() #BCEWithLogitsLoss에 포함되어있으니 주석처리 ) loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . - 저번시간 복습 . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss= loss_fn(yhat,y) ## 3 : 미분 loss.backward() ## 4 : 업데이트 optimizer.step() net.zero_grad() . plt.plot(yhat.data,&#39;.&#39;) #잘안나왔다-&gt;sigmoid취해주자! . [&lt;matplotlib.lines.Line2D at 0x7efb9386ab50&gt;] . f=torch.nn.Sigmoid() plt.plot(f(yhat.data),&#39;.&#39;) #우리가 원하는 0,1 모양으로 나옴 . [&lt;matplotlib.lines.Line2D at 0x7efb922b14c0&gt;] . - 미니배치활용 . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=784,out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30,out_features=1) #torch.nn.Sigmoid() ) loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . 네트워크 파라메터 다시 초기화 | . 12396 / 2048 . 6.052734375 . 총 7개의 미니배치가 만들어질것임 $ to$ 따라서 파라메터를 업데이트하는 횟수는 7 $ times$ epoc 임 (실제적으로는 6 $ times$ epoc) | . 200/6 . 33.333333333333336 . 동일하게 200번 정도 수행하고 싶음. | 1번 에폭이 돌 때마다 6번을 반복함(6*X=200이 되면 좋겠음) | X=33.333...대충 33번 정도? | . for epoc in range(33): for xx,yy in dl: ### 총 7번돌면 끝나는 for ## 1 yyhat=net(xx) ## 2 loss= loss_fn(yyhat,yy) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(yyhat.data,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efb814caf40&gt;] . 이게 왜이러지?? | . - 배치사이즈를 다시 확인해보자. . for xx,yy in dl: print(xx.shape,yy.shape) . torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([2048, 784]) torch.Size([2048, 1]) torch.Size([108, 784]) torch.Size([108, 1]) . - 마지막이 108개이므로 108개의 y만 그려짐 . 확인해보자 | . - 2048개의 데이터를 써서 parameter를 바꿔왔고, 마지막만 108개를 사용함. . list(net.parameters()) . [Parameter containing: tensor([[ 0.0184, -0.0158, -0.0069, ..., 0.0068, -0.0041, 0.0025], [-0.0274, -0.0224, -0.0309, ..., -0.0029, 0.0013, -0.0167], [ 0.0282, -0.0095, -0.0340, ..., -0.0141, 0.0056, -0.0335], ..., [ 0.0267, 0.0186, -0.0326, ..., 0.0047, -0.0072, -0.0301], [-0.0190, 0.0291, 0.0221, ..., 0.0067, 0.0206, 0.0151], [ 0.0226, 0.0331, 0.0182, ..., 0.0150, 0.0278, -0.0073]], requires_grad=True), Parameter containing: tensor([-0.0119, 0.0269, 0.0336, -0.0091, 0.1124, 0.0174, 0.0163, -0.0248, 0.0344, 0.0378, -0.0179, 0.0448, 0.0205, 0.0758, 0.0097, 0.0005, 0.0353, 0.0356, 0.0543, 0.0156, 0.0577, 0.0128, 0.0486, 0.0669, -0.0036, -0.0301, 0.1002, 0.0440, 0.0642, 0.0564], requires_grad=True), Parameter containing: tensor([[ 0.2202, 0.1959, 0.2053, 0.1672, -0.2607, -0.0727, -0.1659, 0.1090, -0.2555, -0.2506, 0.1318, -0.1846, 0.1062, -0.1006, -0.2849, 0.1306, 0.1898, 0.2527, -0.1435, 0.2091, -0.2595, 0.1951, -0.1899, -0.1756, 0.1217, 0.1742, -0.1170, 0.1343, -0.1668, -0.1572]], requires_grad=True), Parameter containing: tensor([-0.0992], requires_grad=True)] . - 만약 잘 추정되었다면 아래의 결과가 잘 나와야겠지? . net(X) . tensor([[-7.6275], [-0.9907], [-8.1248], ..., [ 7.8302], [11.8567], [ 9.7307]], grad_fn=&lt;AddmmBackward&gt;) . plt.plot(net(X).data,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efb939cfbb0&gt;] . - 2048개 정도만 대충학습해도 동일 반복횟수에 대하여 거의 대등한 효율이 나옴 . - GPU에 있는 메모리로 12396개의 데이터를 모두 보내지 않아도 괜찮겠다 $ to$ 그래픽카드의 메모리를 얼마나 큰 것으로 살지는 자료의 크기와는 상관없다. . - net.parameters()에 저장된 값들은 그대로 GPU로 가야만한다. $ to$ 그래픽카드의 메모리를 얼마나 큰것으로 살지는 모형의 복잡도와 관련이 있다. . 컴퓨터사는방법 . 메모리: $n$이 큰 자료를 다룰수록 메모리가 커야한다. | GPU의 메모리: 모형의 복잡도가 커질수록 GPU의 메모리가 커야한다. | . &#49689;&#51228; . - batchsize=1024로 바꾼후 학습해보고 결과를 관찰할것 . dl=torch.utils.data.DataLoader(ds,batch_size=1024,shuffle=True) . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=784,out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30,out_features=1) #torch.nn.Sigmoid() #BCEWithLogitsLoss에 포함되어있으니 주석처리 ) loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss= loss_fn(yhat,y) ## 3 : 미분 loss.backward() ## 4 : 업데이트 optimizer.step() net.zero_grad() . f=torch.nn.Sigmoid() plt.plot(f(yhat.data),&#39;.&#39;) #우리가 원하는 0,1 모양으로 나옴 . [&lt;matplotlib.lines.Line2D at 0x7efb9235e280&gt;] . 미니 배치 | . 12396 / 1024 . 12.10546875 . 200/12 . 16.666666666666668 . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=784,out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30,out_features=1) #torch.nn.Sigmoid() ) loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . for epoc in range(16): for xx,yy in dl: ### 총 12번돌면 끝나는 for ## 1 yyhat=net(xx) ## 2 loss= loss_fn(yyhat,yy) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . len(yyhat) . 108 . for xx,yy in dl: print(xx.shape,yy.shape) . torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([1024, 784]) torch.Size([1024, 1]) torch.Size([108, 784]) torch.Size([108, 1]) . plt.plot(yyhat.data,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efb93b1cbb0&gt;] . plt.plot(net(X).data,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efb93aff6d0&gt;] .",
            "url": "https://kimha02.github.io/ham/python/2021/10/14/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9414%EC%9D%BC.html",
            "relUrl": "/python/2021/10/14/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9414%EC%9D%BC.html",
            "date": " • Oct 14, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "(5주차) 10월12일",
            "content": ". MSEloss &#50752; BCEloss &#48708;&#44368;_10/07 &#49689;&#51228; &#44288;&#47144; . &#49552;&#49892;&#54632;&#49688;&#51032; &#47784;&#50577;&#48708;&#44368; . import torch import numpy as np import matplotlib.pyplot as plt . torch.manual_seed(1) X=torch.linspace(-1,1,2000).reshape(2000,1) w0=-1.0 w1=5.0 u=w0+X*w1 v=torch.exp(u)/(1+torch.exp(u)) y=torch.bernoulli(v) . plt.scatter(X,y,alpha=0.01) plt.plot(X,v) . [&lt;matplotlib.lines.Line2D at 0x7f87aed1da30&gt;] . _w0= np.arange(-10,3,0.05) _w1= np.arange(-1,10,0.05) . _w0, _w1 =np.meshgrid(_w0,_w1,indexing=&#39;ij&#39;) . _w0=_w0.reshape(-1) _w1=_w1.reshape(-1) . 위 코드는 _w0=_w0.reshape(260220) _w1=_w1.reshape(260220) 와 같다. | . def lossfn_crossenp(w0,w1): yhat=torch.exp( w0+w1*X) / (1+torch.exp( w0+w1*X)) loss= - torch.mean (y*torch.log(yhat)+(1-y)*torch.log(1-yhat)) return loss.tolist() . def lossfn_mse(w0,w1): yhat=torch.exp( w0+w1*X) / (1+torch.exp( w0+w1*X)) loss= torch.mean((y-yhat)**2) return loss.tolist() . _l1=list(map(lossfn_crossenp,_w0,_w1)) #_w0,_w1각 행들을 lossfn으로 계산하여 결과를 리스트로 출력 _l2=list(map(lossfn_mse,_w0,_w1)) . fig = plt.figure() ax1=fig.add_subplot(1,2,1,projection=&#39;3d&#39;) ax2=fig.add_subplot(1,2,2,projection=&#39;3d&#39;) ax1.elev=15 ax2.elev=15 ax1.azim=75 ax2.azim=75 fig.set_figheight(15) fig.set_figwidth(15) . ax1.scatter(_w0,_w1,_l1,s=0.01) #Crossenp ax2.scatter(_w0,_w1,_l2,s=0.01) #MSE . &lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f87aec489a0&gt; . 우리가 찾고 싶은 값 표시하기 | . _w0[np.argmin(_l1)],_w1[np.argmin(_l1)] . (-0.9999999999998721, 5.150000000000006) . _w0[np.argmin(_l2)],_w1[np.argmin(_l2)] . (-0.9999999999998721, 5.100000000000005) . ax1.scatter(_w0[np.argmin(_l1)],_w1[np.argmin(_l1)],np.min(_l1),s=200,marker=&#39;*&#39;) ax2.scatter(_w0[np.argmin(_l2)],_w1[np.argmin(_l2)],np.min(_l2),s=200,marker=&#39;*&#39;) . &lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f87aec09ca0&gt; . 그림완성~ | . fig . &#50500;&#53412;&#53581;&#52376;, &#50741;&#54000;&#47560;&#51060;&#51200; . l1=torch.nn.Linear(in_features=1,out_features=1,bias=True) a1=torch.nn.Sigmoid() net=torch.nn.Sequential(l1,a1) optimizer=torch.optim.SGD(net.parameters(),lr=0.05) . &#52488;&#44592;&#44050; $(w_0,w_1)=(-3,-1)$&#51012; &#45824;&#51077;&#54616;&#44256; &#49688;&#47156;&#44284;&#51221;&#51012; animation&#51004;&#47196; &#44288;&#52272;&#54616;&#51088;. . - 파라메터 초기값 $(w_0,w_1)=(-3,-1)$로 설정 . l1.bias.data, l1.weight.data #형태를 확인 . (tensor([-3.]), tensor([[-1.]])) . l1.bias.data=torch.tensor([-3.0]) l1.weight.data=torch.tensor([[-1.0]]) #초기값 대입 . l1.bias.data, l1.weight.data . (tensor([-3.]), tensor([[-1.]])) . - BCEloss를 이용하여 학습+기록 . - 먼저 저장할 리스트를 만들어주고 - 마지막에 결과를 저장하기 위한 코드를 넣어준다. - item으로 텐서 형태가 아닌 값만 저장하고, - append로 누적 . w0_bce=[] w1_bce=[] loss_bce=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= - torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_bce.append(l1.bias.data.item()) w1_bce.append(l1.weight.data.item()) loss_bce.append(loss.item()) . l1.bias.data,l1.weight.data . (tensor([-0.6726]), tensor([[3.3696]])) . - 파라메터 초기값 $(w_0,w_1)=(-3,-1)$로 설정 . l1.bias.data, l1.weight.data . (tensor([-0.6726]), tensor([[3.3696]])) . l1.bias.data=torch.tensor([-3.0]) l1.weight.data=torch.tensor([[-1.0]]) . l1.bias.data, l1.weight.data . (tensor([-3.]), tensor([[-1.]])) . - MSEloss를 이용하여 학습+기록 . w0_mse=[] w1_mse=[] loss_mse=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= torch.mean((y-yhat)**2) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_mse.append(l1.bias.data.item()) w1_mse.append(l1.weight.data.item()) loss_mse.append(loss.item()) . l1.bias.data,l1.weight.data . (tensor([-0.9688]), tensor([[0.7116]])) . - plot . from matplotlib import animation plt.rcParams[&quot;animation.html&quot;] = &quot;jshtml&quot; . fig = plt.figure() ax1= fig.add_subplot(2,2,1,projection=&#39;3d&#39;) ax2= fig.add_subplot(2,2,2,projection=&#39;3d&#39;) ax3= fig.add_subplot(2,2,3) ax4= fig.add_subplot(2,2,4) ax1.elev = 15 ax2.elev = 15 ax1.azim = 75 ax2.azim = 75 fig.set_figheight(15) fig.set_figwidth(15) ### init plot ax1.scatter(_w0,_w1,_l1,s=0.05) ax2.scatter(_w0,_w1,_l2,s=0.05) ax1.scatter(-3,-1,lossfn_crossenp(-3,-1),color=&#39;gray&#39;) ## bceloss ax1.scatter(-1,5.1,lossfn_crossenp(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## bceloss ax2.scatter(-3,-1,lossfn_mse(-3,-1),color=&#39;gray&#39;) ## mseloss ax2.scatter(-1,5.1,lossfn_mse(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## mseloss ax3.scatter(X,y,alpha=0.01) ax3.plot(X,v,&#39;--&#39;) line3, = ax3.plot(X,1/(1+torch.exp(-w0_bce[0]-w1_bce[0]*X)),&#39;--&#39;) ax4.scatter(X,y,alpha=0.01) ax4.plot(X,v,&#39;--&#39;) line4, = ax4.plot(X,1/(1+torch.exp(-w0_mse[0]-w1_mse[0]*X)),&#39;--&#39;) ### animation def animate(i): ax1.scatter(w0_bce[i],w1_bce[i],lossfn_crossenp(w0_bce[i],w1_bce[i]),color=&#39;gray&#39;) ax2.scatter(w0_mse[i],w1_mse[i],lossfn_mse(w0_mse[i],w1_mse[i]),color=&#39;gray&#39;) line3.set_ydata(1/(1+torch.exp(-w0_bce[i]-w1_bce[i]*X))) line4.set_ydata(1/(1+torch.exp(-w0_mse[i]-w1_mse[i]*X))) return line3,line4 ani = animation.FuncAnimation(fig, animate, frames=50) plt.close() ani . &lt;/input&gt; Once Loop Reflect &#52488;&#44592;&#44050; $(w_0,w_1)=(-10,-1)$&#51012; &#45824;&#51077;&#54616;&#44256; &#49688;&#47156;&#44284;&#51221;&#51012; animation&#51004;&#47196; &#44288;&#52272;&#54616;&#51088;. . - 파라메터 초기값 $(w_0,w_1)=(-10,-1)$로 설정 . l1.bias.data, l1.weight.data . (tensor([-0.9688]), tensor([[0.7116]])) . l1.bias.data=torch.tensor([-10.0]) l1.weight.data=torch.tensor([[-1.0]]) . l1.bias.data, l1.weight.data . (tensor([-10.]), tensor([[-1.]])) . - BCEloss를 이용하여 학습+기록 . w0_bce=[] w1_bce=[] loss_bce=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= - torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_bce.append(l1.bias.data.item()) w1_bce.append(l1.weight.data.item()) loss_bce.append(loss.item()) . l1.bias.data,l1.weight.data . (tensor([-0.8302]), tensor([[4.0263]])) . - 파라메터 초기값 $(w_0,w_1)=(-10,-1)$로 설정 . l1.bias.data, l1.weight.data . (tensor([-0.8302]), tensor([[4.0263]])) . l1.bias.data=torch.tensor([-10.0]) l1.weight.data=torch.tensor([[-1.0]]) . l1.bias.data, l1.weight.data . (tensor([-10.]), tensor([[-1.]])) . - MSEloss를 이용하여 학습+기록 . w0_mse=[] w1_mse=[] loss_mse=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= torch.mean((y-yhat)**2) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_mse.append(l1.bias.data.item()) w1_mse.append(l1.weight.data.item()) loss_mse.append(loss.item()) . l1.bias.data,l1.weight.data . (tensor([-9.9990]), tensor([[-0.9995]])) . - plot . fig = plt.figure() ax1= fig.add_subplot(2,2,1,projection=&#39;3d&#39;) ax2= fig.add_subplot(2,2,2,projection=&#39;3d&#39;) ax3= fig.add_subplot(2,2,3) ax4= fig.add_subplot(2,2,4) ax1.elev = 15 ax2.elev = 15 ax1.azim = 75 ax2.azim = 75 fig.set_figheight(15) fig.set_figwidth(15) ### init plot ax1.scatter(_w0,_w1,_l1,s=0.05) ax2.scatter(_w0,_w1,_l2,s=0.05) ax1.scatter(-10,-1,lossfn_crossenp(-10,-1),color=&#39;gray&#39;) ## bceloss ax1.scatter(-1,5.1,lossfn_crossenp(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## bceloss ax2.scatter(-10,-1,lossfn_mse(-10,-1),color=&#39;gray&#39;) ## mseloss ax2.scatter(-1,5.1,lossfn_mse(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## mseloss ax3.scatter(X,y,alpha=0.01) ax3.plot(X,v,&#39;--&#39;) line3, = ax3.plot(X,1/(1+torch.exp(-w0_bce[0]-w1_bce[0]*X)),&#39;--&#39;) ax4.scatter(X,y,alpha=0.01) ax4.plot(X,v,&#39;--&#39;) line4, = ax4.plot(X,1/(1+torch.exp(-w0_mse[0]-w1_mse[0]*X)),&#39;--&#39;) ### animation def animate(i): ax1.scatter(w0_bce[i],w1_bce[i],lossfn_crossenp(w0_bce[i],w1_bce[i]),color=&#39;gray&#39;) ax2.scatter(w0_mse[i],w1_mse[i],lossfn_mse(w0_mse[i],w1_mse[i]),color=&#39;gray&#39;) line3.set_ydata(1/(1+torch.exp(-w0_bce[i]-w1_bce[i]*X))) line4.set_ydata(1/(1+torch.exp(-w0_mse[i]-w1_mse[i]*X))) return line3,line4 ani = animation.FuncAnimation(fig, animate, frames=50) plt.close() ani . &lt;/input&gt; Once Loop Reflect 결과를 보면, crossenp는 초기값 근처에 경사가 있어서 적합이 잘 이루어지는 반면 MSE는 경사가 없어 움직이지 못함. | crossenp와 같은 형태를 convex라고 하며, 아래로 볼록한 2차함수가 1차원에서 convex함수임. | loss function을 convex한 형태로 하면 학습이 쉬워진다! | . 로지스틱 같은 경우에는 binary crossenp가 더 좋다! . Adam &#50741;&#54000;&#47560;&#51060;&#51200;, $(w_0,w_1)=(-3,-1)$ . Adam 옵티마이저는 기존 방법들을 합쳐준.. 좀 더 빨리 학습을 쉽게! | . - 옵티마이저 재설정 . optimizer=torch.optim.Adam(net.parameters(),lr=0.05) . - 파라메터 초기값 $(w_0,w_1)=(-3,-1)$로 설정 . l1.bias.data, l1.weight.data . (tensor([-9.9850]), tensor([[-0.9896]])) . l1.bias.data=torch.tensor([-3.0]) l1.weight.data=torch.tensor([[-1.0]]) . l1.bias.data, l1.weight.data . (tensor([-3.]), tensor([[-1.]])) . - BCEloss를 사용하여 학습 + 기록 . w0_bce=[] w1_bce=[] loss_bce=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= - torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_bce.append(l1.bias.data.item()) w1_bce.append(l1.weight.data.item()) loss_bce.append(loss.item()) . - 파라메터 초기값 $(w_0,w_1)=(-3,-1)$로 설정 . l1.bias.data, l1.weight.data . (tensor([-1.0201]), tensor([[5.1584]])) . l1.bias.data=torch.tensor([-3.0]) l1.weight.data=torch.tensor([[-1.0]]) . l1.bias.data, l1.weight.data . (tensor([-3.]), tensor([[-1.]])) . - MSEloss를 사용하여 학습+기록 . w0_mse=[] w1_mse=[] loss_mse=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= torch.mean((y-yhat)**2) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_mse.append(l1.bias.data.item()) w1_mse.append(l1.weight.data.item()) loss_mse.append(loss.item()) . fig = plt.figure() ax1= fig.add_subplot(2,2,1,projection=&#39;3d&#39;) ax2= fig.add_subplot(2,2,2,projection=&#39;3d&#39;) ax3= fig.add_subplot(2,2,3) ax4= fig.add_subplot(2,2,4) ax1.elev = 15 ax2.elev = 15 ax1.azim = 75 ax2.azim = 75 fig.set_figheight(15) fig.set_figwidth(15) ### init plot ax1.scatter(_w0,_w1,_l1,s=0.05) ax2.scatter(_w0,_w1,_l2,s=0.05) ax1.scatter(-3,-1,lossfn_crossenp(-3,-1),color=&#39;gray&#39;) ## bceloss ax1.scatter(-1,5.1,lossfn_crossenp(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## bceloss ax2.scatter(-3,-1,lossfn_mse(-3,-1),color=&#39;gray&#39;) ## mseloss ax2.scatter(-1,5.1,lossfn_mse(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## mseloss ax3.scatter(X,y,alpha=0.01) ax3.plot(X,v,&#39;--&#39;) line3, = ax3.plot(X,1/(1+torch.exp(-w0_bce[0]-w1_bce[0]*X)),&#39;--&#39;) ax4.scatter(X,y,alpha=0.01) ax4.plot(X,v,&#39;--&#39;) line4, = ax4.plot(X,1/(1+torch.exp(-w0_mse[0]-w1_mse[0]*X)),&#39;--&#39;) ### animation def animate(i): ax1.scatter(w0_bce[i],w1_bce[i],lossfn_crossenp(w0_bce[i],w1_bce[i]),color=&#39;gray&#39;) ax2.scatter(w0_mse[i],w1_mse[i],lossfn_mse(w0_mse[i],w1_mse[i]),color=&#39;gray&#39;) line3.set_ydata(1/(1+torch.exp(-w0_bce[i]-w1_bce[i]*X))) line4.set_ydata(1/(1+torch.exp(-w0_mse[i]-w1_mse[i]*X))) return line3,line4 ani = animation.FuncAnimation(fig, animate, frames=50) plt.close() ani . &lt;/input&gt; Once Loop Reflect Adam &#50741;&#54000;&#47560;&#51060;&#51200;, $(w_0,w_1)=(-10,-1)$ . - 옵티마이저 재설정 . optimizer=torch.optim.Adam(net.parameters(),lr=0.05) . - 파라메터 초기값 $(w_0,w_1)=(-10,-1)$로 설정 . l1.bias.data, l1.weight.data . (tensor([-0.9995]), tensor([[5.0790]])) . l1.bias.data=torch.tensor([-10.0]) l1.weight.data=torch.tensor([[-1.0]]) . l1.bias.data, l1.weight.data . (tensor([-10.]), tensor([[-1.]])) . - BCEloss를 사용하여 학습 + 기록 . w0_bce=[] w1_bce=[] loss_bce=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= - torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_bce.append(l1.bias.data.item()) w1_bce.append(l1.weight.data.item()) loss_bce.append(loss.item()) . - 파라메터 초기값 $(w_0,w_1)=(-10,-1)$로 설정 . l1.bias.data, l1.weight.data . (tensor([-1.0243]), tensor([[5.1769]])) . l1.bias.data=torch.tensor([-10.0]) l1.weight.data=torch.tensor([[-1.0]]) . l1.bias.data, l1.weight.data . (tensor([-10.]), tensor([[-1.]])) . - MSEloss를 사용하여 학습+기록 . w0_mse=[] w1_mse=[] loss_mse=[] for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss= torch.mean((y-yhat)**2) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() ## 5 if epoc%20 == 0: w0_mse.append(l1.bias.data.item()) w1_mse.append(l1.weight.data.item()) loss_mse.append(loss.item()) . fig = plt.figure() ax1= fig.add_subplot(2,2,1,projection=&#39;3d&#39;) ax2= fig.add_subplot(2,2,2,projection=&#39;3d&#39;) ax3= fig.add_subplot(2,2,3) ax4= fig.add_subplot(2,2,4) ax1.elev = 15 ax2.elev = 15 ax1.azim = 75 ax2.azim = 75 fig.set_figheight(15) fig.set_figwidth(15) ### init plot ax1.scatter(_w0,_w1,_l1,s=0.05) ax2.scatter(_w0,_w1,_l2,s=0.05) ax1.scatter(-10,-1,lossfn_crossenp(-10,-1),color=&#39;gray&#39;) ## bceloss ax1.scatter(-1,5.1,lossfn_crossenp(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## bceloss ax2.scatter(-10,-1,lossfn_mse(-10,-1),color=&#39;gray&#39;) ## mseloss ax2.scatter(-1,5.1,lossfn_mse(-1,5.1),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## mseloss ax3.scatter(X,y,alpha=0.01) ax3.plot(X,v,&#39;--&#39;) line3, = ax3.plot(X,1/(1+torch.exp(-w0_bce[0]-w1_bce[0]*X)),&#39;--&#39;) ax4.scatter(X,y,alpha=0.01) ax4.plot(X,v,&#39;--&#39;) line4, = ax4.plot(X,1/(1+torch.exp(-w0_mse[0]-w1_mse[0]*X)),&#39;--&#39;) ### animation def animate(i): ax1.scatter(w0_bce[i],w1_bce[i],lossfn_crossenp(w0_bce[i],w1_bce[i]),color=&#39;gray&#39;) ax2.scatter(w0_mse[i],w1_mse[i],lossfn_mse(w0_mse[i],w1_mse[i]),color=&#39;gray&#39;) line3.set_ydata(1/(1+torch.exp(-w0_bce[i]-w1_bce[i]*X))) line4.set_ydata(1/(1+torch.exp(-w0_mse[i]-w1_mse[i]*X))) return line3,line4 ani = animation.FuncAnimation(fig, animate, frames=50) plt.close() ani . &lt;/input&gt; Once Loop Reflect Adam을 사용해도 MSE는 적합되지 않는 것을 확인할 수 있음 | . &#47784;&#54805;&#51032; &#54364;&#54788;&#47141;: &#50780; &#49888;&#44221;&#47581;&#51008; &#44618;&#50612;&#51276;&#45716;&#44032;? . &#45331;&#51008; &#49888;&#44221;&#47581; (&#54616;&#45208;&#51032; &#51008;&#45769;&#52789; + &#52649;&#48516;&#55176; &#53360; &#45432;&#46300;&#47484; &#44032;&#51652; &#49888;&#44221;&#47581;) . - (universal approximation theorem) 하나의 은닉층과 충분히 큰 노드를 가진 신경망은 거의 모든 함수를 근사할 수 있다. . - 핵심아이디어: (node1=선형+비선형) + (node2=선형+비선형) $ to$ locally compact basis $ to$ 구불구불하게 다 맞출수가 있다. . 선형변환을 무한번 선형변환해도 결과는 그냥 선형변환이다 $ to$ 모든 range에 값이 있는 basis $ to$ 표현력이 약하다. (한쪽을 맞추면 다른쪽을 맞추기 힘듬) | 하지만 아주 단순한 비선형변환을 섞기만 해도 표현력이 비약적으로 상승한다. | . - 트릭은 비선형변환 . &#44536;&#47111;&#45796;&#47732; &#50780; &#45331;&#51008; &#49888;&#44221;&#47581;&#51012; &#50416;&#51648; &#50506;&#45716;&#44032;? . - 안전한 대답 (그리고 쓸모없는 대답): 실험적으로 깊은 신경망이 더 효과적임이 입증되었다. . - 좀 더 고민을 해본 대답 . 넓은신경망보다 깊은신경망이 파라메터수 대비 복잡도를 더 쉽게 올릴수 있다. | 넓은신경망보다 깊은신경망이 오버피팅 이슈를 피하기 쉽다. | . - 내 생각 . 깊은 신경망은 계층적인 모형이다. | 즉 깊은 신경망은 여러스케일로 자료를 관찰한다. | . . Pytoch MLP (MNIST 3,7) . import torch from fastai.vision.all import * . import graphviz . def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+ s + &#39;;}&#39;) . data . - download data (숫자 손글씨 데이터) . path = untar_data(URLs.MNIST_SAMPLE) . . 100.14% [3219456/3214948 00:09&lt;00:00] path.ls() . (#3) [Path(&#39;/home/khy/.fastai/data/mnist_sample/train&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/valid&#39;),Path(&#39;/home/khy/.fastai/data/mnist_sample/labels.csv&#39;)] . - list 형태로 데이터 받아오기 . threes=(path/&#39;train&#39;/&#39;3&#39;).ls() sevens=(path/&#39;train&#39;/&#39;7&#39;).ls() . - list $ to$ image . Image.open(threes[4]) . - image $ to$ tensor . tensor(Image.open(threes[4])) . tensor([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 211, 254, 254, 241, 144, 144, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 247, 253, 253, 253, 254, 253, 253, 247, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 253, 236, 154, 154, 154, 223, 253, 253, 244, 171, 52, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 241, 95, 0, 0, 0, 7, 54, 229, 253, 253, 141, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 23, 253, 253, 250, 65, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 199, 253, 253, 206, 22, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 75, 199, 241, 253, 253, 245, 78, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 45, 113, 155, 241, 254, 253, 253, 250, 185, 22, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 51, 188, 211, 253, 253, 253, 253, 254, 253, 253, 238, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 253, 253, 253, 253, 206, 253, 253, 253, 208, 24, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 10, 183, 183, 111, 111, 29, 0, 0, 0, 135, 253, 254, 70, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 214, 253, 227, 15, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 253, 253, 22, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 90, 250, 253, 234, 17, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 166, 244, 253, 253, 79, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 45, 122, 236, 253, 253, 238, 108, 5, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 81, 145, 69, 155, 155, 215, 253, 253, 255, 253, 236, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 176, 253, 253, 253, 253, 253, 253, 253, 177, 99, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 13, 42, 143, 230, 200, 143, 110, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8) . 여기에서 tensor는 파이토치가 아니라 fastai에서 구현한 함수임 | . - 여러개의 리스트를 모두 텐서로 바꿔보자. . seven_tensor = torch.stack([tensor(Image.open(i)) for i in sevens]).float()/255 three_tensor = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255 . - $X$와 $y$를 만들자. . seven_tensor.shape, three_tensor.shape . (torch.Size([6265, 28, 28]), torch.Size([6131, 28, 28])) . y=torch.tensor([0.0]*6265+ [1.0]*6131).reshape(12396,1) . X=torch.vstack([seven_tensor,three_tensor]).reshape(12396,-1) . X.shape, y.shape . (torch.Size([12396, 784]), torch.Size([12396, 1])) . &#47784;&#54805; . ${ bf X} to { bf WX+b} to f({ bf WX+b}) to dots to { bf y}$ . ${ bf X}=12396 times 784$ matrix | ${ bf y}=12396 times 1$ (col) vector | . - 모델을 어떻게 구성할것인가? . 아키텍처: 적당히 깊게... + 적당히 넓게... + 표현력이 충분하면서도 + 과적합은 일어나지 않도록.. (저도 잘 몰라요) | 손실함수: BCEloss | 옵티마이저: Adam | . - 교재의 모형 . gv(&#39;&#39;&#39; splines=line subgraph cluster_1{ style=filled; color=lightgrey; &quot;x1&quot; &quot;x2&quot; &quot;..&quot; &quot;x784&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;x1&quot; -&gt; &quot;node1&quot; &quot;x2&quot; -&gt; &quot;node1&quot; &quot;..&quot; -&gt; &quot;node1&quot; &quot;x784&quot; -&gt; &quot;node1&quot; &quot;x1&quot; -&gt; &quot;node2&quot; &quot;x2&quot; -&gt; &quot;node2&quot; &quot;..&quot; -&gt; &quot;node2&quot; &quot;x784&quot; -&gt; &quot;node2&quot; &quot;x1&quot; -&gt; &quot;...&quot; &quot;x2&quot; -&gt; &quot;...&quot; &quot;..&quot; -&gt; &quot;...&quot; &quot;x784&quot; -&gt; &quot;...&quot; &quot;x1&quot; -&gt; &quot;node30&quot; &quot;x2&quot; -&gt; &quot;node30&quot; &quot;..&quot; -&gt; &quot;node30&quot; &quot;x784&quot; -&gt; &quot;node30&quot; label = &quot;Layer 1: ReLU&quot; } subgraph cluster_3{ style=filled; color=lightgrey; &quot;node1&quot; -&gt; &quot;y&quot; &quot;node2&quot; -&gt; &quot;y&quot; &quot;...&quot; -&gt; &quot;y&quot; &quot;node30&quot; -&gt; &quot;y&quot; label = &quot;Layer 2: Sigmoid&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: ReLU cluster_3 Layer 2: Sigmoid x1 x1 node1 node1 x1&#45;&gt;node1 node2 node2 x1&#45;&gt;node2 ... ... x1&#45;&gt;... node30 node30 x1&#45;&gt;node30 x2 x2 x2&#45;&gt;node1 x2&#45;&gt;node2 x2&#45;&gt;... x2&#45;&gt;node30 .. .. ..&#45;&gt;node1 ..&#45;&gt;node2 ..&#45;&gt;... ..&#45;&gt;node30 x784 x784 x784&#45;&gt;node1 x784&#45;&gt;node2 x784&#45;&gt;... x784&#45;&gt;node30 y y node1&#45;&gt;y node2&#45;&gt;y ...&#45;&gt;y node30&#45;&gt;y &#54400;&#51060;1 . - 그럼 이제 풀어보자. (아키텍처만 만들어주면 금방구현한다.) . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=28*28, out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30, out_features=1), torch.nn.Sigmoid() ) optimizer=torch.optim.Adam(net.parameters()) . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss= -torch.mean(y*torch.log(yhat)+(1-y)*torch.log(1-yhat)) ## BCEloss ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . list(net.parameters()) . [Parameter containing: tensor([[ 0.0184, -0.0158, -0.0069, ..., 0.0068, -0.0041, 0.0025], [-0.0274, -0.0224, -0.0309, ..., -0.0029, 0.0013, -0.0167], [ 0.0282, -0.0095, -0.0340, ..., -0.0141, 0.0056, -0.0335], ..., [ 0.0267, 0.0186, -0.0326, ..., 0.0047, -0.0072, -0.0301], [-0.0190, 0.0291, 0.0221, ..., 0.0067, 0.0206, 0.0151], [ 0.0226, 0.0331, 0.0182, ..., 0.0150, 0.0278, -0.0073]], requires_grad=True), Parameter containing: tensor([-0.0098, 0.0315, 0.0363, -0.0093, 0.1433, 0.0175, 0.0139, -0.0237, 0.0323, 0.0351, -0.0125, 0.0443, 0.0176, 0.0745, 0.0098, 0.0042, 0.0361, 0.0394, 0.0534, 0.0175, 0.0567, 0.0148, 0.0459, 0.0648, 0.0009, -0.0279, 0.0972, 0.0478, 0.0612, 0.0504], requires_grad=True), Parameter containing: tensor([[ 0.2154, 0.1926, 0.2019, 0.1671, -0.1840, -0.0726, -0.1608, 0.1046, -0.2522, -0.2444, 0.1257, -0.1815, 0.1002, -0.0963, -0.3047, 0.1256, 0.1862, 0.2499, -0.1381, 0.2051, -0.2633, 0.1915, -0.1853, -0.1719, 0.1156, 0.1573, -0.1129, 0.1308, -0.1625, -0.1472]], requires_grad=True), Parameter containing: tensor([-0.1153], requires_grad=True)] . plt.plot(y) plt.plot(yhat.data,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f7afe971910&gt;] . ypred=yhat&gt;0.5 . sum(ypred==y)/12396 . tensor([0.9893]) . &#54400;&#51060;2: torch&#50640; &#45236;&#51109;&#46108; &#49552;&#49892;&#54632;&#49688; &#51060;&#50857; . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=28*28, out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30, out_features=1), #torch.nn.Sigmoid() ) loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . for epoc in range(200): ## 1 yhat=net(X) ## 2 loss= loss_fn(yhat,y) ## BCEloss ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . list(net.parameters()) . [Parameter containing: tensor([[ 0.0184, -0.0158, -0.0069, ..., 0.0068, -0.0041, 0.0025], [-0.0274, -0.0224, -0.0309, ..., -0.0029, 0.0013, -0.0167], [ 0.0282, -0.0095, -0.0340, ..., -0.0141, 0.0056, -0.0335], ..., [ 0.0267, 0.0186, -0.0326, ..., 0.0047, -0.0072, -0.0301], [-0.0190, 0.0291, 0.0221, ..., 0.0067, 0.0206, 0.0151], [ 0.0226, 0.0331, 0.0182, ..., 0.0150, 0.0278, -0.0073]], requires_grad=True), Parameter containing: tensor([-0.0098, 0.0315, 0.0363, -0.0093, 0.1433, 0.0175, 0.0139, -0.0237, 0.0323, 0.0351, -0.0125, 0.0443, 0.0176, 0.0745, 0.0098, 0.0042, 0.0361, 0.0394, 0.0534, 0.0175, 0.0567, 0.0148, 0.0459, 0.0648, 0.0009, -0.0279, 0.0972, 0.0478, 0.0612, 0.0504], requires_grad=True), Parameter containing: tensor([[ 0.2154, 0.1926, 0.2019, 0.1671, -0.1840, -0.0726, -0.1608, 0.1046, -0.2522, -0.2444, 0.1257, -0.1815, 0.1002, -0.0963, -0.3047, 0.1256, 0.1862, 0.2499, -0.1381, 0.2051, -0.2633, 0.1915, -0.1853, -0.1719, 0.1156, 0.1573, -0.1129, 0.1308, -0.1625, -0.1472]], requires_grad=True), Parameter containing: tensor([-0.1153], requires_grad=True)] . plt.plot(y) plt.plot(yhat.data,&#39;.&#39;) #linear까지의 출력결과 . [&lt;matplotlib.lines.Line2D at 0x7f7b42275190&gt;] . f=torch.nn.Sigmoid() plt.plot(y) plt.plot(f(yhat.data),&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f7b421dc7f0&gt;] . &#54400;&#51060;3: torch&#50640; &#45236;&#51109;&#46108; &#49552;&#49892;&#54632;&#49688; &#51060;&#50857; + GPU . torch.manual_seed(1) net = torch.nn.Sequential( torch.nn.Linear(in_features=28*28, out_features=30), torch.nn.ReLU(), torch.nn.Linear(in_features=30, out_features=1), #torch.nn.Sigmoid() ) . net.to(&quot;cuda:0&quot;) . Sequential( (0): Linear(in_features=784, out_features=30, bias=True) (1): ReLU() (2): Linear(in_features=30, out_features=1, bias=True) ) . X_gpu=X.to(&quot;cuda:0&quot;) y_gpu=y.to(&quot;cuda:0&quot;) . loss_fn=torch.nn.BCEWithLogitsLoss() optimizer=torch.optim.Adam(net.parameters()) . for epoc in range(200): ## 1 yhat_gpu=net(X_gpu) #gpu들어감 ## 2 loss= loss_fn(yhat_gpu,y_gpu) ## BCEloss ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . list(net.parameters()) . [Parameter containing: tensor([[ 0.0184, -0.0158, -0.0069, ..., 0.0068, -0.0041, 0.0025], [-0.0274, -0.0224, -0.0309, ..., -0.0029, 0.0013, -0.0167], [ 0.0282, -0.0095, -0.0340, ..., -0.0141, 0.0056, -0.0335], ..., [ 0.0267, 0.0186, -0.0326, ..., 0.0047, -0.0072, -0.0301], [-0.0190, 0.0291, 0.0221, ..., 0.0067, 0.0206, 0.0151], [ 0.0226, 0.0331, 0.0182, ..., 0.0150, 0.0278, -0.0073]], device=&#39;cuda:0&#39;, requires_grad=True), Parameter containing: tensor([-0.0232, 0.0182, 0.0252, -0.0093, 0.2708, 0.0200, 0.0254, -0.0593, 0.0420, 0.0473, -0.0465, 0.0567, -0.0344, 0.1220, 0.0489, -0.0193, 0.0169, 0.0271, 0.0673, -0.0004, 0.0825, -0.0003, 0.0569, 0.0752, -0.0576, -0.0861, 0.1160, 0.0289, 0.0739, 0.0685], device=&#39;cuda:0&#39;, requires_grad=True), Parameter containing: tensor([[ 0.2332, 0.2046, 0.2206, 0.1671, -0.3161, -0.0859, -0.1700, 0.1338, -0.2611, -0.2576, 0.1549, -0.1942, 0.1244, -0.1284, -0.5729, 0.1537, 0.2009, 0.2612, -0.1523, 0.2224, -0.3029, 0.2121, -0.1965, -0.1840, 0.1571, 0.2136, -0.1243, 0.1470, -0.1755, -0.1663]], device=&#39;cuda:0&#39;, requires_grad=True), Parameter containing: tensor([-0.1322], device=&#39;cuda:0&#39;, requires_grad=True)] .",
            "url": "https://kimha02.github.io/ham/python/2021/10/12/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%9412%EC%9D%BC.html",
            "relUrl": "/python/2021/10/12/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%9412%EC%9D%BC.html",
            "date": " • Oct 12, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "(5주차) 10월7일",
            "content": ". Logistic regression . import torch import matplotlib.pyplot as plt . Example . - 현실에서 이런 경우가 많음 . $x$가 커질수록 (혹은 작아질수록) 성공확률이 증가함. | . - 이러한 모형은 아래와 같이 설계할 수 있음 &lt; 외우세요!!! . $y_i sim Ber( pi_i), quad $ where $ pi_i = frac{ exp(w_0+w_1x_i)}{1+ exp(w_0+w_1x_i)}$ . | $ hat{y}_i= frac{ exp( hat{w}_0+ hat{w}_1x_i)}{1+ exp( hat{w}_0+ hat{w}_1x_i)}= frac{1}{1+ exp(- hat{w}_0- hat{w}_1x_i)}$ . | $loss= - sum_{i=1}^{n} big(y_i log( hat{y}_i)+(1-y_i) log(1- hat{y}_i) big)$ &lt; 외우세요!! . | . - 예제시작 . X=torch.linspace(-1,1,2000).reshape(2000,1) w0= - 1 w1= 5 u = w0+X*w1 v = torch.exp(u)/(1+torch.exp(u)) # v=πi y = torch.bernoulli(v) . plt.scatter(X,y,alpha=0.05) plt.plot(X,v,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcab105eac0&gt;] . - 다이어그램으로 표현하면 . import graphviz . def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39; + s + &#39;; }&#39;) . gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; &quot;X&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;X&quot; -&gt; &quot;X@W&quot;[label=&quot;@W&quot;] &quot;X@W&quot; -&gt; &quot;Sigmoid(X@W)=yhat&quot;[label=&quot;Sigmoid&quot;] label = &quot;Layer 1&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1 X X X@W X@W X&#45;&gt;X@W @W Sigmoid(X@W)=yhat Sigmoid(X@W)=yhat X@W&#45;&gt;Sigmoid(X@W)=yhat Sigmoid gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; X label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; X -&gt; &quot;node1=yhat&quot; label = &quot;Layer 1: Sigmoid&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: Sigmoid X X node1=yhat node1=yhat X&#45;&gt;node1=yhat - 아키텍처, 손실함수, 옵티마이저 . torch.manual_seed(43052) l1=torch.nn.Linear(in_features=1,out_features=1,bias=True) a1=torch.nn.Sigmoid() net=torch.nn.Sequential(l1,a1) #위의 두 개를 sequential로 이어준다 #loss = torch.mean((y-yhat)**2) &lt; 이러면 안됩니다!!! optimizer=torch.optim.SGD(net.parameters(),lr=0.05) . plt.scatter(X,y,alpha=0.01) plt.plot(X,net(X).data,&#39;--&#39;) plt.plot(X,v,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcab0f2a550&gt;] . - step1~4 . for epoc in range(10000): ## 1 yhat=net(X) ## 2 loss=-torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . list(net.parameters()) . [Parameter containing: tensor([[5.2584]], requires_grad=True), Parameter containing: tensor([-0.9848], requires_grad=True)] . plt.scatter(X,y,alpha=0.01) plt.plot(X,net(X).data,&#39;--&#39;) plt.plot(X,v,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcaa876bd60&gt;] . . &#49689;&#51228; . loss를 mse로 바꿔서 돌려볼것 . torch.manual_seed(43052) l1=torch.nn.Linear(in_features=1,out_features=1,bias=True) a1=torch.nn.Sigmoid() net=torch.nn.Sequential(l1,a1) #loss = torch.mean((y-yhat)**2) optimizer=torch.optim.SGD(net.parameters(),lr=0.05) . for epoc in range(10000): ## 1 yhat=net(X) ## 2 loss = torch.mean((y-yhat)**2) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . list(net.parameters()) . [Parameter containing: tensor([[4.4528]], requires_grad=True), Parameter containing: tensor([-0.8084], requires_grad=True)] . plt.scatter(X,y,alpha=0.01) plt.plot(X,net(X).data,&#39;--&#39;) plt.plot(X,v,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcaa85d90a0&gt;] .",
            "url": "https://kimha02.github.io/ham/python/2021/10/07/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%947%EC%9D%BC.html",
            "relUrl": "/python/2021/10/07/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%947%EC%9D%BC.html",
            "date": " • Oct 7, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "(4주차) 10월5일",
            "content": ". Import . import torch import numpy as np import matplotlib.pyplot as plt . graphviz setting . import graphviz . 설치가 되어있지 않다면 아래를 실행할것 | . !conda install -c conda-forge python-graphviz . ref: https://anaconda.org/conda-forge/python-graphviz | . - 다이어그램을 그리기 위한 준비 . def gv(s): return graphviz.Source(&#39;digraph G{ rankdir=&quot;LR&quot;&#39;+s + &#39;; }&#39;) . &#50696;&#51228;1: &#49440;&#54805;&#47784;&#54805; . - $y_i= w_0+w_1 x_i + epsilon_i Longrightarrow hat{y}_i = hat{w}_0+ hat{w}_1 x_i$ . $ epsilon_i sim N(0,1)$ | . gv(&#39;&#39;&#39; &quot;1&quot; -&gt; &quot;w0 + x*w1&quot;[label=&quot;* w0&quot;] &quot;x&quot; -&gt; &quot;w0 + x*w1&quot; [label=&quot;* w1&quot;] &quot;w0 + x*w1&quot; -&gt; &quot;yhat&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G 1 1 w0 + x*w1 w0 + x*w1 1&#45;&gt;w0 + x*w1 * w0 yhat yhat w0 + x*w1&#45;&gt;yhat indentity x x x&#45;&gt;w0 + x*w1 * w1 gv(&#39;&#39;&#39; &quot;X&quot; -&gt; &quot;X@W, bias=False&quot;[label=&quot;@W&quot;] ; &quot;X@W, bias=False&quot; -&gt; &quot;yhat&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G X X X@W, bias=False X@W, bias=False X&#45;&gt;X@W, bias=False @W yhat yhat X@W, bias=False&#45;&gt;yhat indentity gv(&#39;&#39;&#39; &quot;x&quot; -&gt; &quot;x*w, bias=True&quot;[label=&quot;*w&quot;] ; &quot;x*w, bias=True&quot; -&gt; &quot;yhat&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G x x x*w, bias=True x*w, bias=True x&#45;&gt;x*w, bias=True *w yhat yhat x*w, bias=True&#45;&gt;yhat indentity &#50696;&#51228;2: polynomial regression . $y_i=w_0+w_1x_i + w_2 x_i^2 + w_3 x_i^3 + epsilon_i$ . gv(&#39;&#39;&#39; &quot;X&quot; -&gt; &quot;X@W, bias=True&quot;[label=&quot;@W&quot;] &quot;X@W, bias=True&quot; -&gt; &quot;yhat&quot;[label=&quot;indentity&quot;] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G X X X@W, bias=True X@W, bias=True X&#45;&gt;X@W, bias=True @W yhat yhat X@W, bias=True&#45;&gt;yhat indentity 위와 바뀐 점 . ${ bf X} = begin{bmatrix} x_1 &amp; x_1^2 &amp; x_1^3 x_2 &amp; x_2^2 &amp; x_2^3 dots &amp; dots &amp; dots x_n &amp; x_n^2 &amp; x_n^3 end{bmatrix}, quad { bf W} = begin{bmatrix} w_1 w_2 w_3 end{bmatrix}$. | . &#49884;&#48044;&#47112;&#51060;&#49496; &#50672;&#49845; . - 모형 . torch.manual_seed(43052) x,_ = torch.randn(100).sort() X=torch.vstack([x,x**2,x**3]).T W=torch.tensor([[4.0],[3.0],[-2.0]]) bias=1.0 ϵ=torch.randn(100,1) #random normal y=X@W+bias + ϵ . plt.plot(X[:,0],y,&#39;.&#39;) #plt.plot(X[:,0],X@W+bias,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98f71eb520&gt;] . - 아키텍처 . net = torch.nn.Linear(in_features=3,out_features=1,bias=True) . - 손실함수 . loss_fn=torch.nn.MSELoss() . - 옵티마이저 . optimizer= torch.optim.SGD(net.parameters(),lr=0.01) . - step1~4 . for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(y,yhat) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . list(net.parameters()) . [Parameter containing: tensor([[ 3.7411, 2.8648, -1.9074]], requires_grad=True), Parameter containing: tensor([1.0239], requires_grad=True)] . plt.plot(X[:,0],y,&#39;.&#39;) plt.plot(X[:,0],yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee9b62e0&gt;] . &#50696;&#51228;3: piece-wise linear regression . - 모델 . _x = np.linspace(-1,1,100).tolist() _f = lambda x: x*1+np.random.normal()*0.3 if x&lt;0 else x*3.5 +np.random.normal()*0.3 _y = list(map(_f,_x)) . plt.plot(_x,_y,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee916dc0&gt;] . 결과 : 값이 음수인 점들은 기울기가 1인 직선 주위로 분포, 값이 양수인 점들은 기울기가 3인 직선 위주로 분포 . X=torch.tensor(_x).reshape(100,1) y=torch.tensor(_y).reshape(100,1) . 리스트를 벡터로 바꿔준다 . &#54400;&#51060;1 . - 아키텍처 + 손실함수(MSE) + 옵티마이저(SGD) . net=torch.nn.Linear(in_features=1,out_features=1,bias=True) #True는 절편항 있음, False는 없음 loss_fn = torch.nn.MSELoss() optimizer = torch.optim.SGD(net.parameters(),lr=0.1) . - step1~4 . for epoc in range(10000): ## 1 yhat=net(X) ## 2 loss=loss_fn(y,yhat) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . plt.plot(X,y,&#39;.&#39;) plt.plot(X,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee89b0a0&gt;] . - 실패: 그리고 epoc을 10억번 반복해도 이건 실패할 모형임 . 왜? 모델자체가 틀렸음. | 모델의 표현력이 너무 부족하다. $ to$ underfitting | . &#54400;&#51060;2 (&#48708;&#49440;&#54805; &#54876;&#49457;&#54868;&#54632;&#49688;&#47484; &#46020;&#51077;) . - 비선형활성화함수를 도입하자. (네트워크수정) . torch.manual_seed(1) layer1 = torch.nn.Linear(in_features=1,out_features=1,bias=False) activation1 = torch.nn.ReLU() layer2 = torch.nn.Linear(in_features=1,out_features=1,bias=False) net2 = torch.nn.Sequential(layer1,activation1,layer2) . _x=np.linspace(-1,1,100) plt.plot(_x,_x) plt.plot(_x,activation1(torch.tensor(_x))) . [&lt;matplotlib.lines.Line2D at 0x7f98ee808a30&gt;] . - 표현력 확인 . plt.plot(X,y,&#39;.&#39;) plt.plot(X,net2(X).data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee78b4c0&gt;] . - 옵티마이저2 : 네트워크에 있는 parameter 업그레이트해줌 . optimizer2 = torch.optim.SGD(net2.parameters(),lr=0.1) . - step1~4 . for epoc in range(1000): ## 1 yhat=net2(X) ## 2 loss=loss_fn(y,yhat) ## 3 loss.backward() ## 4 optimizer2.step() net2.zero_grad() . - result . plt.plot(X,y,&#39;.&#39;) plt.plot(X,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee77d040&gt;] . - discussion . 이것 역시 수백억번 epoc을 반복해도 이 이상 적합하기 힘들다. $ to$ 모형의 표현력이 낮다. | 해결책: 주황색점선이 2개 있다면 어떨까? | . &#54400;&#51060;3 (&#45432;&#46300;&#49688; &#52628;&#44032;) . - 아키텍처 + 옵티마이저 . torch.manual_seed(1) ## 초기가중치를 동일하게 layer1 = torch.nn.Linear(in_features=1,out_features=2,bias=False) activation1 = torch.nn.ReLU() #비선형변환 layer2 = torch.nn.Linear(in_features=2,out_features=1,bias=False) net3 = torch.nn.Sequential(layer1,activation1,layer2) optimizer3= torch.optim.SGD(net3.parameters(),lr=0.1) . plt.plot(X,y,&#39;.&#39;) plt.plot(X,net3(X).data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee542a00&gt;] . - Step 1~4 . for epoc in range(1000): ## 1 yhat=net3(X) ## 2 loss=loss_fn(y,yhat) ## 3 loss.backward() ## 4 optimizer3.step() net3.zero_grad() . - result . plt.plot(X,y,&#39;.&#39;) plt.plot(X,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee5c7eb0&gt;] . - discussion . list(net3.parameters()) . [Parameter containing: tensor([[ 0.5153], [-0.4414]], requires_grad=True), Parameter containing: tensor([[-0.1371, 0.3319]], requires_grad=True)] . 파라메터확인 | . W1=(layer1.weight.data).T W2=(layer2.weight.data).T W1,W2 . (tensor([[ 0.5153, -0.4414]]), tensor([[-0.1371], [ 0.3319]])) . 파라메터 저장 | . - 어떻게 적합이 이렇게 우수하게 되었는지 따져보자. . u1=X@W1 plt.plot(u1) #plt.plot(X@W1) . [&lt;matplotlib.lines.Line2D at 0x7f98ee529e50&gt;, &lt;matplotlib.lines.Line2D at 0x7f98ee529e80&gt;] . v1=activation1(u1) plt.plot(v1) #plt.plot(activation1(X@W1)) . [&lt;matplotlib.lines.Line2D at 0x7f98ee49b040&gt;, &lt;matplotlib.lines.Line2D at 0x7f98ee49b070&gt;] . _yhat=v1@W2 plt.plot(X,y,&#39;.&#39;) plt.plot(X,_yhat,&#39;--&#39;) #plt.plot(X,activation1(X@W1)@W2,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee473bb0&gt;] . &#51104;&#44624;&#50836;&#50557; (&#49888;&#44221;&#47581;) . - 계산과정 . (1) $X to X@W^{(1)} to ReLU(X@W^{(1)}) to ReLU(X@W^{(1)})@W^{(2)}=yhat$ . $X: n times 1$ | $W^{(0)}: 1 times 2$ | $W^{(1)}: 2 times 1$ | . gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; &quot;X&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;X&quot; -&gt; &quot;X@W1&quot;[label=&quot;@W1&quot;] &quot;X@W1&quot; -&gt; &quot;ReLU(X@W1)&quot;[label=&quot;ReLU&quot;] label = &quot;Layer 1&quot; } subgraph cluster_3{ style=filled; color=lightgrey; &quot;ReLU(X@W1)&quot; -&gt; &quot;ReLU(X@W1)@W2:=yhat&quot;[label=&quot;@W2&quot;] label = &quot;Layer 2&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1 cluster_3 Layer 2 X X X@W1 X@W1 X&#45;&gt;X@W1 @W1 ReLU(X@W1) ReLU(X@W1) X@W1&#45;&gt;ReLU(X@W1) ReLU ReLU(X@W1)@W2:=yhat ReLU(X@W1)@W2:=yhat ReLU(X@W1)&#45;&gt;ReLU(X@W1)@W2:=yhat @W2 (2) 아래와 같이 표현할 수도 있다. . gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; &quot;X&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;X&quot; -&gt; &quot;u1[:,0]&quot;[label=&quot;*W1[0,0]&quot;] &quot;X&quot; -&gt; &quot;u1[:,1]&quot;[label=&quot;*W1[0,1]&quot;] &quot;u1[:,0]&quot; -&gt; &quot;v1[:,0]&quot;[label=&quot;Relu&quot;] &quot;u1[:,1]&quot; -&gt; &quot;v1[:,1]&quot;[label=&quot;Relu&quot;] label = &quot;Layer 1&quot; } subgraph cluster_3{ style=filled; color=lightgrey; &quot;v1[:,0]&quot; -&gt; &quot;yhat&quot;[label=&quot;*W2[0,0]&quot;] &quot;v1[:,1]&quot; -&gt; &quot;yhat&quot;[label=&quot;*W2[1,0]&quot;] label = &quot;Layer 2&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1 cluster_3 Layer 2 X X u1[:,0] u1[:,0] X&#45;&gt;u1[:,0] *W1[0,0] u1[:,1] u1[:,1] X&#45;&gt;u1[:,1] *W1[0,1] v1[:,0] v1[:,0] u1[:,0]&#45;&gt;v1[:,0] Relu v1[:,1] v1[:,1] u1[:,1]&#45;&gt;v1[:,1] Relu yhat yhat v1[:,0]&#45;&gt;yhat *W2[0,0] v1[:,1]&#45;&gt;yhat *W2[1,0] gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; &quot;X&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;X&quot; -&gt; &quot;node1&quot; &quot;X&quot; -&gt; &quot;node2&quot; label = &quot;Layer 1: ReLU&quot; } subgraph cluster_3{ style=filled; color=lightgrey; &quot;node1&quot; -&gt; &quot;yhat&quot; &quot;node2&quot; -&gt; &quot;yhat&quot; label = &quot;Layer 2&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: ReLU cluster_3 Layer 2 X X node1 node1 X&#45;&gt;node1 node2 node2 X&#45;&gt;node2 yhat yhat node1&#45;&gt;yhat node2&#45;&gt;yhat - 위와 같은 다이어그램을 적용하면 예제1은 아래와 같이 표현가능 . gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; &quot;1&quot; &quot;x&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;1&quot; -&gt; &quot;node1=yhat&quot; &quot;x&quot; -&gt; &quot;node1=yhat&quot; label = &quot;Layer 1: Identity&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: Identity 1 1 node1=yhat node1=yhat 1&#45;&gt;node1=yhat x x x&#45;&gt;node1=yhat gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; &quot;x&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;x&quot; -&gt; &quot;node1=yhat&quot; label = &quot;Layer 1: Identity&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: Identity x x node1=yhat node1=yhat x&#45;&gt;node1=yhat - 예제2의 아키텍처 . gv(&#39;&#39;&#39; subgraph cluster_1{ style=filled; color=lightgrey; &quot;x&quot; &quot;x**2&quot; &quot;x**3&quot; label = &quot;Layer 0&quot; } subgraph cluster_2{ style=filled; color=lightgrey; &quot;x&quot; -&gt; &quot;node1=yhat&quot; &quot;x**2&quot; -&gt; &quot;node1=yhat&quot; &quot;x**3&quot; -&gt; &quot;node1=yhat&quot; label = &quot;Layer 1: Identity&quot; } &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G cluster_1 Layer 0 cluster_2 Layer 1: Identity x x node1=yhat node1=yhat x&#45;&gt;node1=yhat x**2 x**2 x**2&#45;&gt;node1=yhat x**3 x**3 x**3&#45;&gt;node1=yhat &#54400;&#51060;3&#51060; &#49892;&#54056;&#54624; &#49688;&#46020; &#51080;&#51020; . - 아키텍처 + 옵티마이저 . torch.manual_seed(40352) ## 초기가중치를 동일하게 layer1 = torch.nn.Linear(in_features=1,out_features=2,bias=False) activation1 = torch.nn.ReLU() layer2 = torch.nn.Linear(in_features=2,out_features=1,bias=False) net3 = torch.nn.Sequential(layer1,activation1,layer2) optimizer3= torch.optim.SGD(net3.parameters(),lr=0.1) . plt.plot(X,y,&#39;.&#39;) plt.plot(X,net3(X).data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee3e78e0&gt;] . - Step 1~4 . for epoc in range(10000): ## 1 yhat=net3(X) ## 2 loss=loss_fn(y,yhat) ## 3 loss.backward() ## 4 optimizer3.step() net3.zero_grad() . - result . plt.plot(X,y,&#39;.&#39;) plt.plot(X,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee35d2e0&gt;] . - 왜 가중치가 변하지 않는가? (이것보다 더 좋은 fitting이 있음을 우리는 이미 알고있는데..) . W1=(layer1.weight.data).T W2=(layer2.weight.data).T W1,W2 . (tensor([[6.5313e-04, 1.8310e+00]]), tensor([[0.0721], [1.9088]])) . u1=X@W1 plt.plot(u1) #plt.plot(X@W1) . [&lt;matplotlib.lines.Line2D at 0x7f98ee2c6700&gt;, &lt;matplotlib.lines.Line2D at 0x7f98ee2c6730&gt;] . v1=activation1(u1) plt.plot(v1) #plt.plot(activation1(X@W1)) . [&lt;matplotlib.lines.Line2D at 0x7f98ee2bc130&gt;, &lt;matplotlib.lines.Line2D at 0x7f98ee2bc160&gt;] . _yhat=v1@W2 plt.plot(X,y,&#39;.&#39;) plt.plot(X,_yhat,&#39;--&#39;) #plt.plot(X,activation1(X@W1)@W2,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee225a30&gt;] . - 고약한 상황에 빠졌음. . &#54400;&#51060;4: &#45331;&#51008; &#49888;&#44221;&#47581; . - Custom Activation Function . def mooyaho(input): return torch.sigmoid(200*input) class MOOYAHO(torch.nn.Module): def __init__(self): super().__init__() # init the base class def forward(self, input): return mooyaho(input) # simply apply already implemented SiLU . _x=torch.linspace(-10,10,100) plt.plot(_x,mooyaho(_x)) . [&lt;matplotlib.lines.Line2D at 0x7f98ee197460&gt;] . - 아키텍처 . torch.manual_seed(1) # 초기가중치를 똑같이 하기 위해서.. layer1=torch.nn.Linear(in_features=1,out_features=500,bias=True) activation1=MOOYAHO() layer2=torch.nn.Linear(in_features=500,out_features=1,bias=True) net4=torch.nn.Sequential(layer1,activation1,layer2) optimizer4=torch.optim.SGD(net4.parameters(),lr=0.001) . plt.plot(X,y,&#39;.&#39;) plt.plot(X,net4(X).data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ee105dc0&gt;] . - step1~4 . for epoc in range(5000): # 1 yhat=net4(X) # 2 loss=loss_fn(yhat,y) # 3 loss.backward() # 4 optimizer4.step() net4.zero_grad() . - result . plt.plot(X,y,&#39;.&#39;) plt.plot(X,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ec0f38b0&gt;] . - 넓은 신경망은 과적합을 하는 경우가 종종있다. . - 무엇이든 맞출 수 있음 . torch.manual_seed(43052) __X = torch.linspace(-1,1,100).reshape(100,1) __y = torch.randn(100,1) . plt.plot(__X,__y,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98ec061be0&gt;] . torch.manual_seed(1) # 초기가중치를 똑같이 하기 위해서.. layer1=torch.nn.Linear(in_features=1,out_features=500,bias=True) activation1=MOOYAHO() layer2=torch.nn.Linear(in_features=500,out_features=1,bias=True) net4=torch.nn.Sequential(layer1,activation1,layer2) optimizer4=torch.optim.SGD(net4.parameters(),lr=0.001) . - step1~4 . for epoc in range(5000): # 1 __yhat=net4(__X) # 2 loss=loss_fn(__yhat,__y) # 3 loss.backward() # 4 optimizer4.step() net4.zero_grad() . - result . plt.plot(__X,__y,) plt.plot(__X,__yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98c6f9d340&gt;] . loss_fn(__y,__y*0), loss_fn(__y,__yhat.data) . (tensor(1.1437), tensor(0.7460)) . &#49689;&#51228; . - 예제2: polynomial regression 에서 . optimizer= torch.optim.SGD(net.parameters(),lr=0.01) . 대신에 . optimizer= torch.optim.SGD(net.parameters(),lr=0.1) . 로 변경하여 학습하고 결과를 관찰할것. . &#49884;&#48044;&#47112;&#51060;&#49496; &#50672;&#49845; . - 모형 . torch.manual_seed(43052) x,_ = torch.randn(100).sort() X=torch.vstack([x,x**2,x**3]).T W=torch.tensor([[4.0],[3.0],[-2.0]]) bias=1.0 ϵ=torch.randn(100,1) #random normal y=X@W+bias + ϵ . plt.plot(X[:,0],y,&#39;.&#39;) #plt.plot(X[:,0],X@W+bias,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98c6f072e0&gt;] . - 아키텍처 . net = torch.nn.Linear(in_features=3,out_features=1,bias=True) . - 손실함수 . loss_fn=torch.nn.MSELoss() . - 옵티마이저 . optimizer= torch.optim.SGD(net.parameters(),lr=0.1) . - step1~4 . for epoc in range(1000): ## 1 yhat=net(X) ## 2 loss=loss_fn(y,yhat) ## 3 loss.backward() ## 4 optimizer.step() net.zero_grad() . list(net.parameters()) . [Parameter containing: tensor([[nan, nan, nan]], requires_grad=True), Parameter containing: tensor([nan], requires_grad=True)] . plt.plot(X[:,0],y,&#39;.&#39;) plt.plot(X[:,0],yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f98c6e3ce80&gt;] . 설명: 위와 같은 결과가 나온 이유는 lr을 너무 크게 줘서(보폭이 커서) 값을 지나쳐 우리가 찾는 모수를 추정해주지 못함..? .",
            "url": "https://kimha02.github.io/ham/python/2021/10/05/(4%EC%A3%BC%EC%B0%A8)-10%EC%9B%945%EC%9D%BC.html",
            "relUrl": "/python/2021/10/05/(4%EC%A3%BC%EC%B0%A8)-10%EC%9B%945%EC%9D%BC.html",
            "date": " • Oct 5, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "(4주차) 9월30일",
            "content": ". import torch import numpy as np . Data . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . torch.manual_seed(43052) n=100 ones= torch.ones(n) x,_ = torch.randn(n).sort() X = torch.vstack([ones,x]).T W = torch.tensor([2.5,4]) ϵ = torch.randn(n)*0.5 y = X@W + ϵ ytrue = X@W . step1~2 &#50836;&#50557; . &#48169;&#48277;1: &#47784;&#45944;&#51012; &#51649;&#51217;&#49440;&#50616; + loss&#54632;&#49688;&#46020; &#51649;&#51217;&#49440;&#50616; . What1=torch.tensor([-5.0,10.0],requires_grad=True) yhat1=X@What1 loss1=torch.mean((y-yhat1)**2) loss1 . tensor(85.8769, grad_fn=&lt;MeanBackward0&gt;) . &#48169;&#48277;2: &#47784;&#45944;&#49885;&#51012; torch.nn&#51004;&#47196; &#49440;&#50616; (bias=False) + loss &#51649;&#51217;&#49440;&#50616; . net2=torch.nn.Linear(in_features=2,out_features=1,bias=False) net2.weight.data= torch.tensor([[-5.0,10.0]]) yhat2=net2(X) loss2=torch.mean((y.reshape(100,1)-yhat2)**2) loss2 . tensor(85.8769, grad_fn=&lt;MeanBackward0&gt;) . &#48169;&#48277;3: &#47784;&#45944;&#49885;&#51012; torch.nn&#51004;&#47196; &#49440;&#50616; (bias=True) + loss &#51649;&#51217;&#49440;&#50616; . net3=torch.nn.Linear(in_features=1,out_features=1,bias=True) net3.weight.data= torch.tensor([[10.0]]) net3.bias.data= torch.tensor([[-5.0]]) yhat3=net3(x.reshape(100,1)) loss3=torch.mean((y.reshape(100,1)-yhat3)**2) loss3 . tensor(85.8769, grad_fn=&lt;MeanBackward0&gt;) . &#48169;&#48277;4: &#47784;&#45944;&#49885;&#51012; &#51649;&#51217;&#49440;&#50616; + loss&#54632;&#49688;&#45716; torch.nn.MSELoss() . What4=torch.tensor([-5.0,10.0],requires_grad=True) yhat4=X@What4 lossfn=torch.nn.MSELoss() loss4=lossfn(y,yhat4) loss4 . tensor(85.8769, grad_fn=&lt;MseLossBackward&gt;) . &#48169;&#48277;5: &#47784;&#45944;&#49885;&#51012; torch.nn&#51004;&#47196; &#49440;&#50616; (bias=False) + loss&#54632;&#49688;&#45716; torch.nn.MSELoss() . net5=torch.nn.Linear(in_features=2,out_features=1,bias=False) net5.weight.data= torch.tensor([[-5.0,10.0]]) yhat5=net5(X) #lossfn=torch.nn.MSELoss() loss5=lossfn(y.reshape(100,1),yhat5) loss5 . tensor(85.8769, grad_fn=&lt;MseLossBackward&gt;) . &#48169;&#48277;6: &#47784;&#45944;&#49885;&#51012; torch.nn&#51004;&#47196; &#49440;&#50616; (bias=True) + loss&#54632;&#49688;&#45716; torch.nn.MSELoss() . net6=torch.nn.Linear(in_features=1,out_features=1,bias=True) net6.weight.data= torch.tensor([[10.0]]) net6.bias.data= torch.tensor([[-5.0]]) yhat6=net6(x.reshape(100,1)) loss6=lossfn(y.reshape(100,1),yhat6) loss6 . tensor(85.8769, grad_fn=&lt;MseLossBackward&gt;) . step3: derivation . loss1 . loss1.backward() . RuntimeError Traceback (most recent call last) /tmp/ipykernel_53586/3131771210.py in &lt;module&gt; -&gt; 1 loss1.backward() ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs) 253 create_graph=create_graph, 254 inputs=inputs) --&gt; 255 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs) 256 257 def register_hook(self, hook): ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs) 145 retain_graph = create_graph 146 --&gt; 147 Variable._execution_engine.run_backward( 148 tensors, grad_tensors_, retain_graph, create_graph, inputs, 149 allow_unreachable=True, accumulate_grad=True) # allow_unreachable flag RuntimeError: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward. . What1.grad.data . tensor([-13.4225, 11.8893]) . 이것이 손계산을 통한 이론적인 미분값과 일치함은 이전시간에 확인하였음. | . loss2 . loss2.backward() . net2.weight.grad . tensor([[-13.4225, 11.8893]]) . loss3 . loss3.backward() . net3.bias.grad,net3.weight.grad . (tensor([[-13.4225]]), tensor([[11.8893]])) . loss4 . loss4.backward() . What4.grad.data . tensor([-13.4225, 11.8893]) . loss5 . loss5.backward() . net5.weight.grad . tensor([[-13.4225, 11.8893]]) . loss6 . loss6.backward() . net6.bias.grad,net6.weight.grad . (tensor([[-13.4225]]), tensor([[11.8893]])) . step4: update . loss1 . What1.data ## update 전 . tensor([-5., 10.]) . lr=0.1 What1.data = What1.data - lr*What1.grad.data ## update 후 What1 . tensor([-3.6577, 8.8111], requires_grad=True) . loss2 . net2.weight.data . tensor([[-5., 10.]]) . optmz2 = torch.optim.SGD(net2.parameters(),lr=0.1) . optmz2.step() ## update . net2.weight.data ## update 후 . tensor([[-2.3155, 7.6221]]) . loss3 . net3.bias.data,net3.weight.data . (tensor([[-5.]]), tensor([[10.]])) . optmz3 = torch.optim.SGD(net3.parameters(),lr=0.1) . optmz3.step() . net3.bias.data,net3.weight.data . (tensor([[-3.6577]]), tensor([[8.8111]])) . list(net3.parameters()) . [Parameter containing: tensor([[8.8111]], requires_grad=True), Parameter containing: tensor([[-3.6577]], requires_grad=True)] . loss4 . What4.data ## update 전 . tensor([-5., 10.]) . lr=0.1 What4.data = What4.data - lr*What4.grad.data ## update 후 What4 . tensor([-3.6577, 8.8111], requires_grad=True) . loss5 . net5.weight.data . tensor([[-5., 10.]]) . optmz5 = torch.optim.SGD(net5.parameters(),lr=0.1) . optmz5.step() ## update . net5.weight.data ## update 후 . tensor([[-3.6577, 8.8111]]) . loss6 . net6.bias.data,net6.weight.data . (tensor([[-5.]]), tensor([[10.]])) . optmz6 = torch.optim.SGD(net6.parameters(),lr=0.1) . optmz6.step() . net6.bias.data,net6.weight.data . (tensor([[-3.6577]]), tensor([[8.8111]])) . step1~4&#47484; &#48152;&#48373;&#54616;&#47732;&#46108;&#45796;. . loss5를 보면 | . net=torch.nn.Linear(in_features=2,out_features=1,bias=False) ## 모형정의 optmz=torch.optim.SGD(net.parameters(),lr=0.1) mseloss=torch.nn.MSELoss() for epoc in range(100): # step1: yhat yhat=net(X) ## yhat 계산 # step2: loss loss=mseloss(y.reshape(100,1),yhat) # step3: derivation loss.backward() # step4: update optmz.step() optmz.zero_grad() ## 외우세요.. #기울기를 초기화해준다 . list(net.parameters()) . [Parameter containing: tensor([[2.4459, 4.0043]], requires_grad=True)] . &#49689;&#51228; . 아래를 실행해보고 결과를 관찰하라. . net=torch.nn.Linear(in_features=2,out_features=1,bias=False) ## 모형정의 optmz=torch.optim.SGD(net.parameters(),lr=0.1) mseloss=torch.nn.MSELoss() for epoc in range(100): # step1: yhat yhat=net(X) ## yhat 계산 # step2: loss loss=mseloss(y.reshape(100,1),yhat) # step3: derivation loss.backward() # step4: update optmz.step() . net=torch.nn.Linear(in_features=2,out_features=1,bias=False) ## 모형정의 optmz=torch.optim.SGD(net.parameters(),lr=0.1) mseloss=torch.nn.MSELoss() for epoc in range(100): # step1: yhat yhat=net(X) ## yhat 계산 # step2: loss loss=mseloss(y.reshape(100,1),yhat) # step3: derivation loss.backward() # step4: update optmz.step() . list(net.parameters()) . [Parameter containing: tensor([[ 0.4027, -0.7099]], requires_grad=True)] .",
            "url": "https://kimha02.github.io/ham/python/2021/09/30/(4%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "relUrl": "/python/2021/09/30/(4%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "date": " • Sep 30, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "(3주차) 9월28일",
            "content": ". Import . import torch import numpy as np . Data . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . torch.manual_seed(43052) n=100 ones= torch.ones(n) x,_ = torch.randn(n).sort() X = torch.vstack([ones,x]).T W = torch.tensor([2.5,4]) ϵ = torch.randn(n)*0.5 y = X@W + ϵ ytrue = X@W . &#51060;&#51204;&#48169;&#48277;&#50836;&#50557; . - step1: yhat . - step2: loss . - step3: derivation . - step4: update . . step1: yhat . - feedforward 신경망을 설계하는 과정 . - 이 단계가 잘 완료되었다면, 임의의 ${ bf hat{W}}$을 넣었을 때 $ bf hat{y}$를 계산할 수 있어야 함 . &#48169;&#48277;1: &#51649;&#51217;&#49440;&#50616; (&#45236;&#44032; &#44277;&#49885;&#51012; &#50508;&#44256; &#51080;&#50612;&#50556; &#54620;&#45796;) . What=torch.tensor([-5.0,10.0],requires_grad=True) #미분 꼬리표=requires_grad=True 기억하기! . yhat1=X@What . yhat1 . tensor([-29.8211, -28.6215, -24.9730, -21.2394, -19.7919, -19.6354, -19.5093, -19.4352, -18.7223, -18.0793, -16.9040, -16.0918, -16.0536, -15.8746, -14.4690, -14.3193, -13.6426, -12.8578, -12.5486, -12.4213, -11.9484, -11.1034, -10.8296, -10.6210, -10.5064, -10.0578, -9.8063, -9.7380, -9.7097, -9.6756, -8.8736, -8.7195, -8.6880, -8.1592, -7.7752, -7.7716, -7.7339, -7.7208, -7.6677, -7.1551, -7.0004, -6.8163, -6.7081, -6.5655, -6.4480, -6.3612, -6.0566, -5.6031, -5.5589, -5.2137, -4.3446, -4.3165, -3.8047, -3.5801, -3.4793, -3.4325, -2.3545, -2.3440, -1.8434, -1.7799, -1.5386, -1.0161, -0.8103, 0.4426, 0.5794, 0.9125, 1.1483, 1.4687, 1.4690, 1.5234, 1.6738, 2.0592, 2.1414, 2.8221, 3.1536, 3.6682, 4.2907, 4.8037, 4.8531, 4.9414, 5.3757, 5.3926, 5.6973, 6.0239, 6.1261, 6.5317, 7.2891, 8.4032, 8.4936, 9.2794, 9.9943, 10.0310, 10.4369, 11.7886, 15.8323, 17.4440, 18.9350, 21.0560, 21.0566, 21.6324], grad_fn=&lt;MvBackward&gt;) . (&#9733;) &#48169;&#48277;2: torch.nn.Linear() &#49324;&#50857; . - nn안에 linear라는 클래스가 있음 . net = torch.nn.Linear(in_features=2 ,out_features=1, bias=False) . net.weight.data . tensor([[0.3320, 0.1982]]) . net.weight.data=torch.tensor([[-5.0,10.0]]) . net.weight.data . tensor([[-5., 10.]]) . net(X) . tensor([[-29.8211], [-28.6215], [-24.9730], [-21.2394], [-19.7919], [-19.6354], [-19.5093], [-19.4352], [-18.7223], [-18.0793], [-16.9040], [-16.0918], [-16.0536], [-15.8746], [-14.4690], [-14.3193], [-13.6426], [-12.8578], [-12.5486], [-12.4213], [-11.9484], [-11.1034], [-10.8296], [-10.6210], [-10.5064], [-10.0578], [ -9.8063], [ -9.7380], [ -9.7097], [ -9.6756], [ -8.8736], [ -8.7195], [ -8.6880], [ -8.1592], [ -7.7752], [ -7.7716], [ -7.7339], [ -7.7208], [ -7.6677], [ -7.1551], [ -7.0004], [ -6.8163], [ -6.7081], [ -6.5655], [ -6.4480], [ -6.3612], [ -6.0566], [ -5.6031], [ -5.5589], [ -5.2137], [ -4.3446], [ -4.3165], [ -3.8047], [ -3.5801], [ -3.4793], [ -3.4325], [ -2.3545], [ -2.3440], [ -1.8434], [ -1.7799], [ -1.5386], [ -1.0161], [ -0.8103], [ 0.4426], [ 0.5794], [ 0.9125], [ 1.1483], [ 1.4687], [ 1.4690], [ 1.5234], [ 1.6738], [ 2.0592], [ 2.1414], [ 2.8221], [ 3.1536], [ 3.6682], [ 4.2907], [ 4.8037], [ 4.8531], [ 4.9414], [ 5.3757], [ 5.3926], [ 5.6973], [ 6.0239], [ 6.1261], [ 6.5317], [ 7.2891], [ 8.4032], [ 8.4936], [ 9.2794], [ 9.9943], [ 10.0310], [ 10.4369], [ 11.7886], [ 15.8323], [ 17.4440], [ 18.9350], [ 21.0560], [ 21.0566], [ 21.6324]], grad_fn=&lt;MmBackward&gt;) . yhat2=net(X) . &#48169;&#48277;3: torch.nn.Linear()&#49324;&#50857;, bias=True . net = torch.nn.Linear(in_features=1 ,out_features=1, bias=True) . - 입력차원을 1로 했기 때문에 net.weight.data 값이 1개만 나온다 - 또 bias를 전과 다르게 True로 줘서 아래 bias.data도 가능하다 . net.weight.data . tensor([[0.3480]]) . net.weight.data=torch.tensor([[10.0]]) . net.bias.data=torch.tensor([-5.0]) . net.weight,net.bias . (Parameter containing: tensor([[10.]], requires_grad=True), Parameter containing: tensor([-5.], requires_grad=True)) . net(x) #차원오류 . RuntimeError Traceback (most recent call last) /tmp/ipykernel_43749/925514741.py in &lt;module&gt; -&gt; 1 net(x) #차원오류 ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs) 1049 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks 1050 or _global_forward_hooks or _global_forward_pre_hooks): -&gt; 1051 return forward_call(*input, **kwargs) 1052 # Do not call functions when jit is used 1053 full_backward_hooks, non_full_backward_hooks = [], [] ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/modules/linear.py in forward(self, input) 94 95 def forward(self, input: Tensor) -&gt; Tensor: &gt; 96 return F.linear(input, self.weight, self.bias) 97 98 def extra_repr(self) -&gt; str: ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/nn/functional.py in linear(input, weight, bias) 1845 if has_torch_function_variadic(input, weight): 1846 return handle_torch_function(linear, (input, weight), input, weight, bias=bias) -&gt; 1847 return torch._C._nn.linear(input, weight, bias) 1848 1849 RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x100 and 1x1) . net(x.reshape(100,1)) #shape을 바꿔준다 . tensor([[-29.8211], [-28.6215], [-24.9730], [-21.2394], [-19.7919], [-19.6354], [-19.5093], [-19.4352], [-18.7223], [-18.0793], [-16.9040], [-16.0918], [-16.0536], [-15.8746], [-14.4690], [-14.3193], [-13.6426], [-12.8578], [-12.5486], [-12.4213], [-11.9484], [-11.1034], [-10.8296], [-10.6210], [-10.5064], [-10.0578], [ -9.8063], [ -9.7380], [ -9.7097], [ -9.6756], [ -8.8736], [ -8.7195], [ -8.6880], [ -8.1592], [ -7.7752], [ -7.7716], [ -7.7339], [ -7.7208], [ -7.6677], [ -7.1551], [ -7.0004], [ -6.8163], [ -6.7081], [ -6.5655], [ -6.4480], [ -6.3612], [ -6.0566], [ -5.6031], [ -5.5589], [ -5.2137], [ -4.3446], [ -4.3165], [ -3.8047], [ -3.5801], [ -3.4793], [ -3.4325], [ -2.3545], [ -2.3440], [ -1.8434], [ -1.7799], [ -1.5386], [ -1.0161], [ -0.8103], [ 0.4426], [ 0.5794], [ 0.9125], [ 1.1483], [ 1.4687], [ 1.4690], [ 1.5234], [ 1.6738], [ 2.0592], [ 2.1414], [ 2.8221], [ 3.1536], [ 3.6682], [ 4.2907], [ 4.8037], [ 4.8531], [ 4.9414], [ 5.3757], [ 5.3926], [ 5.6973], [ 6.0239], [ 6.1261], [ 6.5317], [ 7.2891], [ 8.4032], [ 8.4936], [ 9.2794], [ 9.9943], [ 10.0310], [ 10.4369], [ 11.7886], [ 15.8323], [ 17.4440], [ 18.9350], [ 21.0560], [ 21.0566], [ 21.6324]], grad_fn=&lt;AddmmBackward&gt;) . . step2: loss . &#48169;&#48277;1: &#49552;&#49892;&#54632;&#49688;&#47484; &#51649;&#51217;&#51221;&#51032;&#54616;&#45716; &#48169;&#48277; . loss=torch.mean((y-yhat1)**2) loss . tensor(85.8769, grad_fn=&lt;MeanBackward0&gt;) . loss=torch.mean((y-yhat2)**2) loss . tensor(176.2661, grad_fn=&lt;MeanBackward0&gt;) . 왜 다르지? | . y-yhat2 . tensor([[ 21.2791, 23.2444, 23.8716, ..., 42.9194, 42.3679, 43.6551], [ 20.0794, 22.0448, 22.6719, ..., 41.7197, 41.1683, 42.4555], [ 16.4309, 18.3962, 19.0234, ..., 38.0712, 37.5197, 38.8070], ..., [-29.5981, -27.6328, -27.0056, ..., -7.9578, -8.5093, -7.2220], [-29.5986, -27.6333, -27.0062, ..., -7.9583, -8.5098, -7.2226], [-30.1744, -28.2091, -27.5820, ..., -8.5341, -9.0856, -7.7984]], grad_fn=&lt;SubBackward0&gt;) . (y-yhat2).shape . torch.Size([100, 100]) . y는 길이가 100인 벡터, yhat2는 100X1 matrix임 | 2개가 계산되면서 생긴 오류임 | 176.2661? 이건 잘못된 결과임 | . torch.mean((y-yhat2.flatten())**2) . tensor(85.8769, grad_fn=&lt;MeanBackward0&gt;) . loss=torch.mean((y.reshape(100,1)-yhat2)**2) loss . tensor(85.8769, grad_fn=&lt;MeanBackward0&gt;) . &#48169;&#48277;2: torch.nn.MSELoss()&#47484; &#49324;&#50857;&#54616;&#50668; &#49552;&#49892;&#54632;&#49688;&#47484; &#51221;&#51032;&#54616;&#45716; &#48169;&#48277; . lossfn=torch.nn.MSELoss() . loss=lossfn(y,yhat1) loss . tensor(85.8769, grad_fn=&lt;MseLossBackward&gt;) . loss=lossfn(y.reshape(100,1),yhat2) loss . tensor(85.8769, grad_fn=&lt;MseLossBackward&gt;) . &#49689;&#51228; . - model: $y_i= w_0+w_1 x_{i1}+w_2 x_{i2} + epsilon_i = 2.5 + 4x_{1i} + -2x_{2i}+ epsilon_i, quad i=1,2, dots,n$ . torch.manual_seed(43052) n=100 ones= torch.ones(n) x1,_ = torch.randn(n).sort() x2,_ = torch.randn(n).sort() X = torch.vstack([ones,x1,x2]).T W = torch.tensor([2.5,4,-2]) ϵ = torch.randn(n)*0.5 y = X@W + ϵ ytrue = X@W . X . tensor([[ 1.0000, -2.4821, -2.3721], [ 1.0000, -2.3621, -2.3032], [ 1.0000, -1.9973, -2.2271], [ 1.0000, -1.6239, -2.0301], [ 1.0000, -1.4792, -1.9157], [ 1.0000, -1.4635, -1.8241], [ 1.0000, -1.4509, -1.6696], [ 1.0000, -1.4435, -1.6675], [ 1.0000, -1.3722, -1.4723], [ 1.0000, -1.3079, -1.4405], [ 1.0000, -1.1904, -1.4111], [ 1.0000, -1.1092, -1.3820], [ 1.0000, -1.1054, -1.3803], [ 1.0000, -1.0875, -1.3456], [ 1.0000, -0.9469, -1.3255], [ 1.0000, -0.9319, -1.2860], [ 1.0000, -0.8643, -1.2504], [ 1.0000, -0.7858, -1.2095], [ 1.0000, -0.7549, -1.1498], [ 1.0000, -0.7421, -1.1151], [ 1.0000, -0.6948, -1.0980], [ 1.0000, -0.6103, -1.0609], [ 1.0000, -0.5830, -0.9825], [ 1.0000, -0.5621, -0.9672], [ 1.0000, -0.5506, -0.9396], [ 1.0000, -0.5058, -0.9208], [ 1.0000, -0.4806, -0.8768], [ 1.0000, -0.4738, -0.7517], [ 1.0000, -0.4710, -0.7091], [ 1.0000, -0.4676, -0.7027], [ 1.0000, -0.3874, -0.6918], [ 1.0000, -0.3719, -0.6561], [ 1.0000, -0.3688, -0.6153], [ 1.0000, -0.3159, -0.5360], [ 1.0000, -0.2775, -0.4784], [ 1.0000, -0.2772, -0.3936], [ 1.0000, -0.2734, -0.3763], [ 1.0000, -0.2721, -0.3283], [ 1.0000, -0.2668, -0.3227], [ 1.0000, -0.2155, -0.2860], [ 1.0000, -0.2000, -0.2842], [ 1.0000, -0.1816, -0.2790], [ 1.0000, -0.1708, -0.2472], [ 1.0000, -0.1565, -0.2199], [ 1.0000, -0.1448, -0.2170], [ 1.0000, -0.1361, -0.1952], [ 1.0000, -0.1057, -0.1886], [ 1.0000, -0.0603, -0.1829], [ 1.0000, -0.0559, -0.1447], [ 1.0000, -0.0214, -0.0723], [ 1.0000, 0.0655, -0.0667], [ 1.0000, 0.0684, -0.0625], [ 1.0000, 0.1195, -0.0539], [ 1.0000, 0.1420, -0.0356], [ 1.0000, 0.1521, 0.0306], [ 1.0000, 0.1568, 0.0783], [ 1.0000, 0.2646, 0.1328], [ 1.0000, 0.2656, 0.1925], [ 1.0000, 0.3157, 0.2454], [ 1.0000, 0.3220, 0.2519], [ 1.0000, 0.3461, 0.3517], [ 1.0000, 0.3984, 0.3816], [ 1.0000, 0.4190, 0.3831], [ 1.0000, 0.5443, 0.3850], [ 1.0000, 0.5579, 0.4247], [ 1.0000, 0.5913, 0.4431], [ 1.0000, 0.6148, 0.4589], [ 1.0000, 0.6469, 0.4709], [ 1.0000, 0.6469, 0.4711], [ 1.0000, 0.6523, 0.4944], [ 1.0000, 0.6674, 0.4969], [ 1.0000, 0.7059, 0.5234], [ 1.0000, 0.7141, 0.5614], [ 1.0000, 0.7822, 0.5874], [ 1.0000, 0.8154, 0.5899], [ 1.0000, 0.8668, 0.6259], [ 1.0000, 0.9291, 0.6296], [ 1.0000, 0.9804, 0.7098], [ 1.0000, 0.9853, 0.7154], [ 1.0000, 0.9941, 0.7437], [ 1.0000, 1.0376, 0.7786], [ 1.0000, 1.0393, 0.8346], [ 1.0000, 1.0697, 0.8432], [ 1.0000, 1.1024, 0.8558], [ 1.0000, 1.1126, 0.8803], [ 1.0000, 1.1532, 0.9951], [ 1.0000, 1.2289, 1.0430], [ 1.0000, 1.3403, 1.0580], [ 1.0000, 1.3494, 1.0685], [ 1.0000, 1.4279, 1.1723], [ 1.0000, 1.4994, 1.2669], [ 1.0000, 1.5031, 1.3621], [ 1.0000, 1.5437, 1.3738], [ 1.0000, 1.6789, 1.4183], [ 1.0000, 2.0832, 1.4193], [ 1.0000, 2.2444, 1.5095], [ 1.0000, 2.3935, 1.6424], [ 1.0000, 2.6056, 1.8131], [ 1.0000, 2.6057, 2.0058], [ 1.0000, 2.6632, 2.2810]]) . - torch.nn.Linear() 를 이용하여 $ bf{ hat{W}}= begin{bmatrix}1 1 1 end{bmatrix}$ 에 대한 $ hat{y}$를 구하라. . net = torch.nn.Linear(in_features=3,out_features=1, bias=False) . net.weight.data . tensor([[ 0.0411, 0.3420, -0.5768]]) . net.weight.data=torch.tensor([[1.0,1.0,1.0]]) . net.weight.data . tensor([[1., 1., 1.]]) . net(X) . tensor([[-3.8542], [-3.6654], [-3.2244], [-2.6540], [-2.3949], [-2.2877], [-2.1205], [-2.1110], [-1.8446], [-1.7484], [-1.6015], [-1.4912], [-1.4857], [-1.4330], [-1.2724], [-1.2179], [-1.1147], [-0.9953], [-0.9047], [-0.8572], [-0.7928], [-0.6712], [-0.5655], [-0.5293], [-0.4903], [-0.4266], [-0.3574], [-0.2255], [-0.1800], [-0.1702], [-0.0791], [-0.0280], [ 0.0160], [ 0.1480], [ 0.2441], [ 0.3293], [ 0.3503], [ 0.3997], [ 0.4105], [ 0.4984], [ 0.5157], [ 0.5393], [ 0.5820], [ 0.6235], [ 0.6382], [ 0.6687], [ 0.7057], [ 0.7568], [ 0.7995], [ 0.9063], [ 0.9989], [ 1.0058], [ 1.0656], [ 1.1064], [ 1.1827], [ 1.2350], [ 1.3973], [ 1.4581], [ 1.5611], [ 1.5739], [ 1.6979], [ 1.7800], [ 1.8021], [ 1.9292], [ 1.9827], [ 2.0343], [ 2.0737], [ 2.1177], [ 2.1180], [ 2.1468], [ 2.1643], [ 2.2293], [ 2.2755], [ 2.3696], [ 2.4052], [ 2.4927], [ 2.5587], [ 2.6901], [ 2.7007], [ 2.7379], [ 2.8162], [ 2.8738], [ 2.9129], [ 2.9582], [ 2.9929], [ 3.1483], [ 3.2719], [ 3.3983], [ 3.4179], [ 3.6003], [ 3.7663], [ 3.8652], [ 3.9175], [ 4.0971], [ 4.5026], [ 4.7539], [ 5.0359], [ 5.4187], [ 5.6114], [ 5.9442]], grad_fn=&lt;MmBackward&gt;) .",
            "url": "https://kimha02.github.io/ham/python/2021/09/28/(3%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "relUrl": "/python/2021/09/28/(3%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "date": " • Sep 28, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "(2주차) 9월14일, 9월16일",
            "content": ". import . import torch import numpy as np import matplotlib.pyplot as plt . &#47196;&#46300;&#47605; . - 회귀분석 $ to$ 로지스틱 $ to$ 심층신경망(DNN) $ to$ 합성곱신경망(CNN) . Data . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . torch.manual_seed(43052) n=100 ones= torch.ones(n) x,_ = torch.randn(n).sort() X = torch.vstack([ones,x]).T W = torch.tensor([2.5,4]) ϵ = torch.randn(n)*0.5 # epsilon으로 문자 넣기 y = X@W + ϵ ytrue = X@W . plt.plot(x,y,&#39;o&#39;) plt.plot(x,ytrue,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7e6cb9b80&gt;] . &#54617;&#49845;&#51060;&#46976;? . - 파란점만 주어졌을때, 주황색 점선을 추론하는것. 좀 더 정확하게 말하면 given data로 $ begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$를 최대한 $ begin{bmatrix} 2.5 4 end{bmatrix}$와 비슷하게 찾는것. . given data : $ big {(x_i,y_i) big }_{i=1}^{n}$ . | parameter: ${ bf W}= begin{bmatrix} w_0 w_1 end{bmatrix}$ . | estimated parameter: ${ bf hat{W}}= begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$ . | . - 더 쉽게 말하면 아래의 그림을 보고 적당한 추세선을 찾는것이다. . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7e6bb91c0&gt;] . - 시도: $( hat{w}_0, hat{w}_1)=(-5,10)$을 선택하여 선을 그려보고 적당한지 판단. . $ hat{y}_i=-5 +10 x_i$ 와 같이 $y_i$의 값을 적합시키겠다는 의미 | . plt.plot(x,y,&#39;o&#39;) plt.plot(x,-5+10*x,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7e6ba1040&gt;] . - 벡터표현으로 주황색점선을 계산 . What=torch.tensor([-5.0,10.0]) #5,10으로 하면 에러남 plt.plot(x,y,&#39;o&#39;) plt.plot(x,X@What,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7e6ae4df0&gt;] . &#54028;&#46972;&#47700;&#53552;&#47484; &#54617;&#49845;&#54616;&#45716; &#48169;&#48277; (&#51201;&#45817;&#54620; &#49440;&#51004;&#47196; &#50629;&#45936;&#51060;&#53944; &#54616;&#45716; &#48169;&#48277;) . - 이론적으로 추론 &lt;- 회귀분석시간에 배운것 . - 컴퓨터의 반복계산을 이용하여 추론 (경사하강법) &lt;- 우리가 오늘 파이토치로 실습해볼 내용. . (1) initial value: 임의의 선을 일단 그어본다. . What= torch.tensor([-5.0,10.0],requires_grad=True) What . tensor([-5., 10.], requires_grad=True) . 처음에는 ${ bf hat{W}}= begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}= begin{bmatrix} -5 10 end{bmatrix} $ 를 대입해서 주황색 점선을 적당히 그려보자는 의미 . | 끝에 requires_grad=True는 나중에 미분을 위한 것 . | . yhat=X@What yhat #What이 미분 꼬리표를 갖고 있어서 yhat도 미분 꼬리표를 갖고 있음 . tensor([-29.8211, -28.6215, -24.9730, -21.2394, -19.7919, -19.6354, -19.5093, -19.4352, -18.7223, -18.0793, -16.9040, -16.0918, -16.0536, -15.8746, -14.4690, -14.3193, -13.6426, -12.8578, -12.5486, -12.4213, -11.9484, -11.1034, -10.8296, -10.6210, -10.5064, -10.0578, -9.8063, -9.7380, -9.7097, -9.6756, -8.8736, -8.7195, -8.6880, -8.1592, -7.7752, -7.7716, -7.7339, -7.7208, -7.6677, -7.1551, -7.0004, -6.8163, -6.7081, -6.5655, -6.4480, -6.3612, -6.0566, -5.6031, -5.5589, -5.2137, -4.3446, -4.3165, -3.8047, -3.5801, -3.4793, -3.4325, -2.3545, -2.3440, -1.8434, -1.7799, -1.5386, -1.0161, -0.8103, 0.4426, 0.5794, 0.9125, 1.1483, 1.4687, 1.4690, 1.5234, 1.6738, 2.0592, 2.1414, 2.8221, 3.1536, 3.6682, 4.2907, 4.8037, 4.8531, 4.9414, 5.3757, 5.3926, 5.6973, 6.0239, 6.1261, 6.5317, 7.2891, 8.4032, 8.4936, 9.2794, 9.9943, 10.0310, 10.4369, 11.7886, 15.8323, 17.4440, 18.9350, 21.0560, 21.0566, 21.6324], grad_fn=&lt;MvBackward&gt;) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7e6a4ae50&gt;] . (2) 첫번째 수정: 적당한 선의 &#39;적당한 정도&#39;를 판단하고 더 적당한 선으로 업데이트 한다. . - &#39;적당한 정도&#39;를 판단하기 위한 장치: loss function 도입! . $loss= sum_{i=1}^{n}(y_i- hat{y}_i)^2= sum_{i=1}^{n}(y_i-( hat{w}_0+ hat{w}_1x_i))^2$ . $=({ bf y}-{ bf hat{y}})^ top({ bf y}-{ bf hat{y}})=({ bf y}-{ bf X}{ bf hat{W}})^ top({ bf y}-{ bf X}{ bf hat{W}})$ . - loss 함수의 특징 . $y_i approx hat{y}_i$ 일수록 loss값이 작다. | $y_i approx hat{y}_i$ 이 되도록 $( hat{w}_0, hat{w}_1)$을 잘 찍으면 loss값이 작다. | (★중요★) 주황색 점선이 &#39;적당할 수록&#39; loss값이 작다. | . loss=torch.sum((y-yhat)**2) loss . tensor(8587.6875, grad_fn=&lt;SumBackward0&gt;) . - 우리의 목표: 이 loss(=8587.6875)을 더 줄이자. $ to$ 아예 모든 조합 $( hat{w}_0, hat{w}_1)$에 대하여 가장 작은 loss를 찾으면 좋겠다. . - 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다. . 적당해보이는 주황색 선을 찾자 $ to$ $loss(w_0,w_1)$를 최소로하는 $(w_0,w_1)$의 값을 찾자. | . - 수정된 목표: $loss(w_0,w_1)$를 최소로 하는 $(w_0,w_1)$을 구하라. . 단순한 수학문제가 되었다. 마치 $loss(w)=w^2-2w+3$ 을 최소화하는 $w$를 찾으라는 것과 같음. | . - 우리의 무기: 경사하강법, 벡터미분 . . ($ ast$) &#51104;&#49884; &#44221;&#49324;&#54616;&#44053;&#48277;&#51012; &#47532;&#48624;&#54616;&#51088;. . 경사하강법 아이디어 (1차원) . (step 1) 임의의 점을 찍는다. . (step 2) 그 점에서 순간기울기를 구한다. (접선) &lt;-- 미분 . (step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다. (순간기울기와 같은 방향으로 움직이면 점점 커질테니까) . (팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. . 경사하강법 아이디어 (2차원) . - 경사하강법 아이디어 (1차원) . (step 1) 임의의 점을 찍는다. . (step 2) 그 점에서 순간기울기를 구한다. (접평면) &lt;-- 편미분 . (step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다. (순간기울기와 같은 방향으로 움직이면 점점 커질테니까) . (팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. . loss를 줄이도록 ${ bf W}$를 개선하는 방법 . - $수정값 leftarrow 원래값 - 기울어진크기(=미분계수) times alpha $ . 여기에서 $ alpha$는 전체적인 보폭의 크기를 결정한다. 즉 $ alpha$값이 클수록 한번의 update에 움직이는 양이 크다. | . - ${ bf W} leftarrow { bf W} - alpha times frac{ partial}{ partial { bf W}}loss(w_0,w_1)$ . 마이너스의 의미: 기울기의 부호를 보고 반대방향으로 움직여라. . | $ frac{ partial}{ partial { bf W}}loss(w_0,w_1):$ 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라. . | $ alpha$의 의미: 전체적인 보폭의 속도를 조절, $ alpha$가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다. . | . . - 우리의 목표: loss=8587.6875 인데, 이걸 줄이는 것이 목표라고 했었음. 이것을 줄이는 방법이 경사하강법이다. . - 경사하강법으로 loss를 줄이기 위해서는 $ frac{ partial}{ partial { bf W}}loss(w_0,w_1)$의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. . loss.backward() . RuntimeError Traceback (most recent call last) /tmp/ipykernel_2023438/3941280626.py in &lt;module&gt; -&gt; 1 loss.backward() ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs) 253 create_graph=create_graph, 254 inputs=inputs) --&gt; 255 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs) 256 257 def register_hook(self, hook): ~/anaconda3/envs/bda2021/lib/python3.8/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs) 145 retain_graph = create_graph 146 --&gt; 147 Variable._execution_engine.run_backward( 148 tensors, grad_tensors_, retain_graph, create_graph, inputs, 149 allow_unreachable=True, accumulate_grad=True) # allow_unreachable flag RuntimeError: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward. . 미분해라! 뭘로? requires_grad=True를 가진 텐서로!!loss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2) # 이었고 What=torch.tensor([-5.0,10.0],requires_grad=True) # 이므로 결국 What으로 미분하라는 의미. # 미분한 식이 나오는 것이 아니고, # 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. . | . 정확하게 말하면 미분을 활용하여 $(-5,10)$에서의 순간기울기를 구했다는 의미임. | . What.grad.data . tensor([-1342.2522, 1188.9305]) . 이것이 의미하는건 $(-5,10)$에서의 순간기울기가 $(-1342.2523, 1188.9307)$ 이라는 의미 | . - 잘계산한것이 맞는가? 손계산으로 검증하여 보자. . $loss(w_0,w_1)=(y- hat{y})^ top (y- hat{y})=(y-XW)^ top (y-XW)$ . | $ frac{ partial}{ partial W}loss(w_0,w_1)=-2X^ top y+2X^ top X W$ . | . - 2 * X.T @ y + 2 * X.T @ X @ What . tensor([-1342.2522, 1188.9308], grad_fn=&lt;AddBackward0&gt;) . alpha=0.001 print(&#39;수정전: &#39; + str(What.data)) print(&#39;수정하는폭: &#39; +str(-alpha * What.grad.data)) print(&#39;수정후: &#39; +str(What.data-alpha * What.grad.data)) print(&#39;*참값: (2.5,4)&#39; ) . 수정전: tensor([-5., 10.]) 수정하는폭: tensor([ 1.3423, -1.1889]) 수정후: tensor([-3.6577, 8.8111]) *참값: (2.5,4) . Wbefore = What.data Wafter = What.data-alpha * What.grad.data Wbefore, Wafter . (tensor([-5., 10.]), tensor([-3.6577, 8.8111])) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,X@Wbefore,&#39;--&#39;,color=&#39;b&#39;) #수정전: 파란점선 plt.plot(x,X@Wafter,&#39;--&#39;,color=&#39;r&#39;) #수정후: 빨간점선 plt.title(&quot;before: blue // after: red&quot;) . Text(0.5, 1.0, &#39;before: blue // after: red&#39;) . (3) Learn (=estimate $ bf hat{W})$: . What= torch.tensor([-5.0,10.0],requires_grad=True) . alpha=0.001 #보폭 for epoc in range(30): What.grad=None yhat=X@What loss=torch.sum((y-yhat)**2) loss.backward() What.data = What.data-alpha * What.grad.data . What.data ## true: (2.5,4) . tensor([2.4290, 4.0144]) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,(X@What.data),&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7dc1dbca0&gt;] . &#54028;&#46972;&#47700;&#53552;&#51032; &#49688;&#51221;&#44284;&#51221;&#51012; &#44288;&#52272;&#54624; &#49688; &#50630;&#51012;&#44620;? (&#54617;&#49845;&#44284;&#51221; &#47784;&#45768;&#53552;&#47553;) . - 기록을 해보자. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . What= torch.tensor([-5.0,10.0],requires_grad=True) alpha=0.001 for epoc in range(30): Whats=Whats+[What.data.tolist()] #업데이트되는 값을 저장하는 코드 What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . - $ hat{y}$ 관찰 . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhats[3],&#39;--&#39;) #[]에 숫자는 업데이트된 숫자. 커질수록 개선되는 모습을 보자 . [&lt;matplotlib.lines.Line2D at 0x7fc7be7f2a00&gt;] . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhats[10],&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7be760760&gt;] . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhats[15],&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7be6bb880&gt;] . - $ hat{ bf W}$ . Whats . [[-5.0, 10.0], [-3.657747745513916, 8.81106948852539], [-2.554811716079712, 7.861191749572754], [-1.649186372756958, 7.101552963256836], [-0.9060714244842529, 6.49347448348999], [-0.29667872190475464, 6.006272315979004], [0.2027742564678192, 5.615575313568115], [0.6119104623794556, 5.302003860473633], [0.9469034075737, 5.0501298904418945], [1.2210698127746582, 4.847658157348633], [1.4453644752502441, 4.684779644012451], [1.6287914514541626, 4.553659915924072], [1.7787461280822754, 4.448036193847656], [1.9012980461120605, 4.3628973960876465], [2.0014259815216064, 4.294229507446289], [2.0832109451293945, 4.238814353942871], [2.149996757507324, 4.194070339202881], [2.204521894454956, 4.157923698425293], [2.249027729034424, 4.128708839416504], [2.285348415374756, 4.105085849761963], [2.31498384475708, 4.0859761238098145], [2.339160442352295, 4.070511341094971], [2.3588807582855225, 4.057991027832031], [2.3749637603759766, 4.0478515625], [2.3880786895751953, 4.039637088775635], [2.3987717628479004, 4.032979965209961], [2.40748929977417, 4.027583599090576], [2.414595603942871, 4.023208141326904], [2.4203879833221436, 4.019659042358398], [2.4251089096069336, 4.016779899597168], [-5.0, 10.0], [-3.657747745513916, 8.81106948852539], [-2.554811716079712, 7.861191749572754], [-1.649186372756958, 7.101552963256836], [-0.9060714244842529, 6.49347448348999], [-0.29667872190475464, 6.006272315979004], [0.2027742564678192, 5.615575313568115], [0.6119104623794556, 5.302003860473633], [0.9469034075737, 5.0501298904418945], [1.2210698127746582, 4.847658157348633], [1.4453644752502441, 4.684779644012451], [1.6287914514541626, 4.553659915924072], [1.7787461280822754, 4.448036193847656], [1.9012980461120605, 4.3628973960876465], [2.0014259815216064, 4.294229507446289], [2.0832109451293945, 4.238814353942871], [2.149996757507324, 4.194070339202881], [2.204521894454956, 4.157923698425293], [2.249027729034424, 4.128708839416504], [2.285348415374756, 4.105085849761963], [2.31498384475708, 4.0859761238098145], [2.339160442352295, 4.070511341094971], [2.3588807582855225, 4.057991027832031], [2.3749637603759766, 4.0478515625], [2.3880786895751953, 4.039637088775635], [2.3987717628479004, 4.032979965209961], [2.40748929977417, 4.027583599090576], [2.414595603942871, 4.023208141326904], [2.4203879833221436, 4.019659042358398], [2.4251089096069336, 4.016779899597168]] . plt.plot(losses) . [&lt;matplotlib.lines.Line2D at 0x7fc7be670d30&gt;] . Animation . plt.rcParams[&#39;figure.figsize&#39;] = (10,4) plt.rcParams[&quot;animation.html&quot;] = &quot;jshtml&quot; . from matplotlib import animation fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . &lt;/input&gt; Once Loop Reflect $ alpha$&#50640; &#45824;&#54616;&#50668; ($ alpha$&#45716; &#54617;&#49845;&#47456;) . (1) $ alpha$가 너무 작다면? $ to$ 비효율적이다. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . alpha=0.0001 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . &lt;/input&gt; Once Loop Reflect (2) $ alpha$가 크다면? $ to$ 다른의미에서 비효율적이다 + 위험하다.. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . alpha=0.0083 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . &lt;/input&gt; Once Loop Reflect (3) $ alpha=0.0085$ . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . alpha=0.0085 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . &lt;/input&gt; Once Loop Reflect (4) $ alpha=0.01$ . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . alpha=0.01 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . &lt;/input&gt; Once Loop Reflect . &#45796;&#47336;&#44592; &#49899;&#51648;&#47564; &#54644;&#50556;&#54616;&#45716; &#49324;&#49548;&#54620; &#47928;&#51228;&#46308; . 9/28 강의영상 | . (A1) &#49552;&#49892;&#54632;&#49688; . - $ sum_{i=1}^{n}(y_i- hat{y}_i)^2$ 대신에 . $ frac{1}{n} sum_{i=1}^{n}(y_i- hat{y}_i)^2$ | $ frac{1}{2n} sum_{i=1}^{n}(y_i- hat{y}_i)^2$ | . 중 하나를 사용하여도 상관없다. 그런데 2번째 형태를 가장 많이 쓴다 $ to$ alpha를 잡기가 수월함 . (A2) &#48324;&#54364;&#47196; &#54364;&#49884;&#46108; &#51216;&#51060; &#51221;&#47568; $(2.5,4.0)$&#51068;&#44620;? $ Longleftrightarrow$ $l$&#51060; &#51221;&#47568; $w_0=2.5$, $w_1=4.0$&#50640;&#49436; &#52572;&#49548;&#54868; &#46104;&#45716;&#44032;? . - np.argmin 소개 . - 최소값 인덱스 출력 - arg = argument, min = minimum . _a=np.array([2,0,5,2,3,4]) np.argmin(_a) . 1 . np.argmin(l) . 598 . - 이건 무슨 값이지?? $ to$ l은 34*34개로 이루어져있는데 이 중 598번째(0포함) 숫자가 제일 작다! . - 왜 이런일이 생기는가? . _X=np.array([[1,6,3],[1,-5,5]]) . _X . array([[ 1, 6, 3], [ 1, -5, 5]]) . np.argmin(_X) . 4 . - array의 구조가 너무 컴퓨터 위주의 숫자임 $ to$ np.unravel_index() 함수사용 : 좀 더 사람이 이해하기 쉬운 형태로! 얽혀있는 것을 풀어준다는 의미의 함수 . np.unravel_index(4,_X.shape) . (1, 1) . _X.shape . (2, 3) . - 위에서 4번째 값은 2행 2열 값이니까 0부터 시작하는 파이썬에서는 (1,1) 로 나오는 것임! . - 이것을 응용하면 . np.unravel_index(np.argmin(l),l.shape) . (17, 20) . _w0[17],_w1[20] #위의 값을 넣어준다 . (2.5, 4.0) . - (2.5,4.0)에서 l이 최소값을 가지는 것이 맞긴함 . - 그런데 이론적으로 그래야 하는 것은 아님. . torch.sum((y-2.5-4.0*x)**2) . tensor(26.6494) . XX=np.matrix(X) yy=np.matrix(y).T . (XX.T*XX).I * XX.T * yy #I=inverse, T=transpose . matrix([[2.445869], [4.004342]], dtype=float32) . torch.sum((y-2.4458692-4.004343*x)**2) . tensor(26.3600) . 진짜로 (2.4458692,4.004343) 에서의 로스가 더 작음 | . - $n$이 커질수록 (2.4458692, 4.004343) 의 값은 점점 (2.5,4.0)의 값에 가까워 진다. . (A3) &#54665;&#48289;&#53552;&#50752; &#50676;&#48289;&#53552; . - 아래의 매트릭스를 관찰하자. . XX . matrix([[ 1. , -2.482113 ], [ 1. , -2.3621461 ], [ 1. , -1.9972954 ], [ 1. , -1.6239362 ], [ 1. , -1.4791915 ], [ 1. , -1.4635365 ], [ 1. , -1.450925 ], [ 1. , -1.4435216 ], [ 1. , -1.3722302 ], [ 1. , -1.3079282 ], [ 1. , -1.1903973 ], [ 1. , -1.109179 ], [ 1. , -1.1053556 ], [ 1. , -1.0874591 ], [ 1. , -0.94689655], [ 1. , -0.9319339 ], [ 1. , -0.8642649 ], [ 1. , -0.78577816], [ 1. , -0.7548619 ], [ 1. , -0.74213064], [ 1. , -0.6948388 ], [ 1. , -0.610345 ], [ 1. , -0.5829591 ], [ 1. , -0.56210476], [ 1. , -0.55064297], [ 1. , -0.50577736], [ 1. , -0.48062643], [ 1. , -0.4737953 ], [ 1. , -0.47096547], [ 1. , -0.46755713], [ 1. , -0.3873588 ], [ 1. , -0.37194738], [ 1. , -0.3687963 ], [ 1. , -0.31592152], [ 1. , -0.27751535], [ 1. , -0.27715707], [ 1. , -0.27338728], [ 1. , -0.27207515], [ 1. , -0.2667671 ], [ 1. , -0.21550845], [ 1. , -0.20004053], [ 1. , -0.18163072], [ 1. , -0.17081414], [ 1. , -0.1565458 ], [ 1. , -0.14479806], [ 1. , -0.13611706], [ 1. , -0.10566129], [ 1. , -0.06031348], [ 1. , -0.05588722], [ 1. , -0.02136729], [ 1. , 0.06554431], [ 1. , 0.06835173], [ 1. , 0.11953046], [ 1. , 0.14198998], [ 1. , 0.15207446], [ 1. , 0.15675156], [ 1. , 0.26455274], [ 1. , 0.26559785], [ 1. , 0.3156574 ], [ 1. , 0.32201108], [ 1. , 0.346143 ], [ 1. , 0.39839193], [ 1. , 0.4189721 ], [ 1. , 0.5442578 ], [ 1. , 0.557936 ], [ 1. , 0.591254 ], [ 1. , 0.61482644], [ 1. , 0.64686656], [ 1. , 0.64689904], [ 1. , 0.6523392 ], [ 1. , 0.6673753 ], [ 1. , 0.7059195 ], [ 1. , 0.7141374 ], [ 1. , 0.78221494], [ 1. , 0.8153611 ], [ 1. , 0.8668233 ], [ 1. , 0.9290748 ], [ 1. , 0.98036987], [ 1. , 0.9853081 ], [ 1. , 0.99413556], [ 1. , 1.0375688 ], [ 1. , 1.039256 ], [ 1. , 1.0697267 ], [ 1. , 1.1023871 ], [ 1. , 1.112612 ], [ 1. , 1.1531745 ], [ 1. , 1.2289088 ], [ 1. , 1.3403202 ], [ 1. , 1.3493598 ], [ 1. , 1.4279404 ], [ 1. , 1.4994265 ], [ 1. , 1.503098 ], [ 1. , 1.5436871 ], [ 1. , 1.6788615 ], [ 1. , 2.083233 ], [ 1. , 2.2444 ], [ 1. , 2.393501 ], [ 1. , 2.6056044 ], [ 1. , 2.605658 ], [ 1. , 2.66324 ]], dtype=float32) . - 두번째 col을 선택하고 싶다. . XX[:,1] . matrix([[-2.482113 ], [-2.3621461 ], [-1.9972954 ], [-1.6239362 ], [-1.4791915 ], [-1.4635365 ], [-1.450925 ], [-1.4435216 ], [-1.3722302 ], [-1.3079282 ], [-1.1903973 ], [-1.109179 ], [-1.1053556 ], [-1.0874591 ], [-0.94689655], [-0.9319339 ], [-0.8642649 ], [-0.78577816], [-0.7548619 ], [-0.74213064], [-0.6948388 ], [-0.610345 ], [-0.5829591 ], [-0.56210476], [-0.55064297], [-0.50577736], [-0.48062643], [-0.4737953 ], [-0.47096547], [-0.46755713], [-0.3873588 ], [-0.37194738], [-0.3687963 ], [-0.31592152], [-0.27751535], [-0.27715707], [-0.27338728], [-0.27207515], [-0.2667671 ], [-0.21550845], [-0.20004053], [-0.18163072], [-0.17081414], [-0.1565458 ], [-0.14479806], [-0.13611706], [-0.10566129], [-0.06031348], [-0.05588722], [-0.02136729], [ 0.06554431], [ 0.06835173], [ 0.11953046], [ 0.14198998], [ 0.15207446], [ 0.15675156], [ 0.26455274], [ 0.26559785], [ 0.3156574 ], [ 0.32201108], [ 0.346143 ], [ 0.39839193], [ 0.4189721 ], [ 0.5442578 ], [ 0.557936 ], [ 0.591254 ], [ 0.61482644], [ 0.64686656], [ 0.64689904], [ 0.6523392 ], [ 0.6673753 ], [ 0.7059195 ], [ 0.7141374 ], [ 0.78221494], [ 0.8153611 ], [ 0.8668233 ], [ 0.9290748 ], [ 0.98036987], [ 0.9853081 ], [ 0.99413556], [ 1.0375688 ], [ 1.039256 ], [ 1.0697267 ], [ 1.1023871 ], [ 1.112612 ], [ 1.1531745 ], [ 1.2289088 ], [ 1.3403202 ], [ 1.3493598 ], [ 1.4279404 ], [ 1.4994265 ], [ 1.503098 ], [ 1.5436871 ], [ 1.6788615 ], [ 2.083233 ], [ 2.2444 ], [ 2.393501 ], [ 2.6056044 ], [ 2.605658 ], [ 2.66324 ]], dtype=float32) . 정상적을 잘 선택되었다. | . - 이제 XX에서 첫번째 row를 선택하고 싶다면? . XX[0,:] . matrix([[ 1. , -2.482113]], dtype=float32) . - X에 관심을 가져보자. . - 첫번째 row를 뽑고싶다면? . X[0,:] . tensor([ 1.0000, -2.4821]) . - 두번째 col을 뽑고 싶다면? . X[:,1] . tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435, -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319, -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621, -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719, -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155, -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603, -0.0559, -0.0214, 0.0655, 0.0684, 0.1195, 0.1420, 0.1521, 0.1568, 0.2646, 0.2656, 0.3157, 0.3220, 0.3461, 0.3984, 0.4190, 0.5443, 0.5579, 0.5913, 0.6148, 0.6469, 0.6469, 0.6523, 0.6674, 0.7059, 0.7141, 0.7822, 0.8154, 0.8668, 0.9291, 0.9804, 0.9853, 0.9941, 1.0376, 1.0393, 1.0697, 1.1024, 1.1126, 1.1532, 1.2289, 1.3403, 1.3494, 1.4279, 1.4994, 1.5031, 1.5437, 1.6789, 2.0832, 2.2444, 2.3935, 2.6056, 2.6057, 2.6632]) . - shape을 비교하여 보자. . XX.shape, (XX[0,:]).shape, (XX[:,1]).shape . ((100, 2), (1, 2), (100, 1)) . 이게 상식적임 | . X.shape, (X[0,:]).shape, (X[:,1]).shape . (torch.Size([100, 2]), torch.Size([2]), torch.Size([100])) . row-vec, col-vec의 구분없이 그냥 길이2인 벡터, 길이가 100인 벡터로 고려됨 | row-vec, col-vec의 구분을 하려면 2차원이 필요한데 1차원으로 축소가 되면서 생기는 현상 | 대부분의 경우 별로 문제가 되지 않음. | 수학적으로는 col-vec, row-vec를 엄밀하게 구분하는 것이 좋지만, 프로그래밍 효율을 생각하면 떄로는 구분이 모호한게 유리할 수도 있다. | .",
            "url": "https://kimha02.github.io/ham/python/2021/09/14/(3%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "relUrl": "/python/2021/09/14/(3%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "date": " • Sep 14, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "(2주차) 9월 9일",
            "content": "import . from fastai.data.all import * from fastai.vision.all import * . path ? . path=Path() # Path클래스에서 인스턴스생성 . - 기능 : 현재 폴더 혹은 그 하위폴더들에 속한 파일의 목록을 볼 수 있음 . path? . Type: PosixPath String form: . File: ~/anaconda3/envs/bda2021/lib/python3.8/pathlib.py Docstring: Path subclass for non-Windows systems. On a POSIX system, instantiating a Path should return this object. . path . Path(&#39;.&#39;) . - . 은 현재 폴더, .. 은 상위 폴더로 이동 . - Path(...)에서 무엇을 넣느냐에 따라 원하는 경로를 설정할 수 있다. . path=Path(&#39;/&#39;) #최상위폴더 . path.ls() . (#25) [Path(&#39;/lib&#39;),Path(&#39;/run&#39;),Path(&#39;/libx32&#39;),Path(&#39;/usr&#39;),Path(&#39;/dev&#39;),Path(&#39;/cdrom&#39;),Path(&#39;/opt&#39;),Path(&#39;/proc&#39;),Path(&#39;/snap&#39;),Path(&#39;/boot&#39;)...] . path=Path(&#39;/home&#39;) . path.ls() . (#1) [Path(&#39;/home/khy&#39;)] . - 폴더를 만들 수 있다! : mkdir()=make directory . path=Path() . (path/&#39;temp&#39;).mkdir() . (path/&#39;temp&#39;).ls() . (#0) [] . - 이미 폴더가 존재하는 경우에는 다시 폴더를 만들 수 없다. . (path/&#39;temp&#39;).mkdir() #이미 존재한다는 에러 . FileExistsError Traceback (most recent call last) /tmp/ipykernel_2002088/4140436892.py in &lt;module&gt; -&gt; 1 (path/&#39;temp&#39;).mkdir() #이미 존재한다는 에러 ~/anaconda3/envs/bda2021/lib/python3.8/pathlib.py in mkdir(self, mode, parents, exist_ok) 1286 self._raise_closed() 1287 try: -&gt; 1288 self._accessor.mkdir(self, mode) 1289 except FileNotFoundError: 1290 if not parents or self.parent == self: FileExistsError: [Errno 17] File exists: &#39;temp&#39; . (path/&#39;temp&#39;).mkdir(exist_ok=True) #있으면 에러띄우기 보다 그냥 만들지마 명령어 . - 생성한 폴더를 지우는 방법 . (path/&#39;temp&#39;).rmdir() . . &#51060;&#48120;&#51648; &#53356;&#47204;&#47553; . - 이미지 크롤링은 (1) 검색 (2) 이미지 주소를 찾음 (3) 해당주소로 이동하여 저장하는 과정을 반복하면 된다. - 교재: 빙(검색엔진)을 이용하여 이미지 크롤링 - 단점: 애져(마이크로소프트 클라우드 서비스)에 가입, 완전무료가 아님 (학생에게 1년간 무료) - 다른방법: 덕덕고를 이용한 이미지 크롤링 ref: https://github.com/fastai/fastbook/blob/master/utils.py . def search_images_ddg(key,max_n=200): &quot;&quot;&quot;Search for &#39;key&#39; with DuckDuckGo and return a unique urls of &#39;max_n&#39; images (Adopted from https://github.com/deepanprabhu/duckduckgo-images-api) &quot;&quot;&quot; url = &#39;https://duckduckgo.com/&#39; params = {&#39;q&#39;:key} res = requests.post(url,data=params) searchObj = re.search(r&#39;vqd=([ d-]+) &amp;&#39;,res.text) if not searchObj: print(&#39;Token Parsing Failed !&#39;); return requestUrl = url + &#39;i.js&#39; headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:71.0) Gecko/20100101 Firefox/71.0&#39;} params = ((&#39;l&#39;,&#39;us-en&#39;),(&#39;o&#39;,&#39;json&#39;),(&#39;q&#39;,key),(&#39;vqd&#39;,searchObj.group(1)),(&#39;f&#39;,&#39;,,,&#39;),(&#39;p&#39;,&#39;1&#39;),(&#39;v7exp&#39;,&#39;a&#39;)) urls = [] while True: try: res = requests.get(requestUrl,headers=headers,params=params) data = json.loads(res.text) for obj in data[&#39;results&#39;]: urls.append(obj[&#39;image&#39;]) max_n = max_n - 1 if max_n &lt; 1: return L(set(urls)) # dedupe if &#39;next&#39; not in data: return L(set(urls)) requestUrl = url + data[&#39;next&#39;] except: pass . - (2) 이미지 주소 찾기 test : searach_images_ddg(검색어)를 통해 검색어에 해당하는 url을 얻는다. . search_images_ddg(&#39;hynn&#39;, max_n=5) . (#5) [&#39;https://koreajoongangdaily.joins.com/jmnet/koreajoongangdaily/_data/photo/2020/04/06194306.jpg&#39;,&#39;https://yt3.ggpht.com/a/AGF-l7_1jF579BUaWHBEpY95iZAb0WI2SC4vykeo3A=s900-c-k-c0xffffffff-no-rj-mo&#39;,&#39;http://talkimg.imbc.com/TVianUpload/tvian/TViews/image/2020/03/21/GRMTjLNM9a88637203974033409433.jpg&#39;,&#39;https://images.genius.com/a37e8f087886e8a9f1f1d4d4d02aba44.960x960x1.jpg&#39;,&#39;https://www.nautiljon.com/images/people/01/59/hynn_99095.jpg?0&#39;] . - (3) 이미지 저장 : download_images(저장하고 싶은 폴더 위치, url의 리스트)를 이용하여 url에 해당하는 이미지를 저장하고 싶은 폴더에 저장한다. . path=Path() . path.ls() . (#19) [Path(&#39;singer&#39;),Path(&#39;test&#39;),Path(&#39;program&#39;),Path(&#39;2021-09-06-hani03.png&#39;),Path(&#39;2021-09-07(1주차) 빅데이터.ipynb&#39;),Path(&#39;2021-09-06-cat1.png&#39;),Path(&#39;00000004.jpg&#39;),Path(&#39;2021-11-01-ggul.jpg&#39;),Path(&#39;2021-09-06-hani02.png&#39;),Path(&#39;ggul2.jpg&#39;)...] . download_images(path, urls=search_images_ddg(&#39;hynn&#39;, max_n=5)) . - 현재 work directory에 사진이 저장됨 . keywords = &#39;hynn&#39;, &#39;iu&#39; path=Path(&#39;singer&#39;) . if not path.exists(): #현재폴더에 singer라는 폴더가 있는 체크 path.mkdir() #현재폴더에 singer라는 폴더가 만들어짐 for keyword in keywords: #keyword=hynn, keyword=iu일 떄 아래 내용을 반복 lastpath=path/keyword #새로운keyword경로생성 ./singer/hynn or ./singer/iu lastpath.mkdir(exist_ok=True) #위에서 언급한 경로를 만든다 urls=search_images_ddg(keyword) #검색어로 url들의 리스트를 얻음 download_images(lastpath, urls=urls) #그 url에 해당하는 이미지들을 위에서 언급한 두 경로에 저장 . Cleaning Data . - 탐색기로 파일들을 살펴보니 조금 이상한 확장자도 있음. - 조금 이상해 보이는 확장자도 열리기는 함. . PILImage.create(&#39;./singer/iu/00000108.jpg:large&#39;) . - 그런데 이것을 우리가 계속 하기란 쉽지 않음... - 대신 해주는 함수를 이용하자! $ to$ verify_images . verify_images(get_image_files(path)) . (#0) [] . - 위에서 언급된 파일들은 열리지 않는 파일들임. 지워주자! - 자동으로 지워주는 함수도 있지만 여기는 숫자가 적으니 직접 지워줬음. - csv을 받았으면 df를 만들어야 하듯이, 이미지 파일들을 받았으면 dls 를 만들어야 fastai가 지원하는 함수로 분석하기 좋음. . - 지난 강아지/고양이 분석 예제는 파일이름으로 강아지/고양이를 구분할 수 있었음. - 이번 예제는 폴더 2개에 이미지가 있으며, 이미지 파일 이름으로 폴더를 구분할 수 없음. - 그래서 사용하는 함수가 다르다! . dls = ImageDataLoaders.from_folder( path, train=&#39;singer&#39;, valid_pct=0.2, item_tfms=Resize(224)) . dls.show_batch(max_n=16) . - 모형을 만들고 학습을 시키자. . learn=cnn_learner(dls,resnet34,metrics=error_rate) learn.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 1.152002 | 0.508378 | 0.203125 | 00:03 | . epoch train_loss valid_loss error_rate time . 0 | 0.606856 | 0.736607 | 0.281250 | 00:02 | . - error_rate가 높다.. 학습을 더 시켜보자! . learn=cnn_learner(dls,resnet34,metrics=error_rate) learn.fine_tune(7) . epoch train_loss valid_loss error_rate time . 0 | 1.234616 | 1.661402 | 0.343750 | 00:02 | . epoch train_loss valid_loss error_rate time . 0 | 0.693173 | 1.295955 | 0.359375 | 00:02 | . 1 | 0.547231 | 1.049156 | 0.281250 | 00:02 | . 2 | 0.412173 | 0.766495 | 0.187500 | 00:02 | . 3 | 0.311454 | 0.619963 | 0.156250 | 00:02 | . 4 | 0.245190 | 0.524244 | 0.125000 | 00:02 | . 5 | 0.201767 | 0.443742 | 0.140625 | 00:02 | . 6 | 0.170655 | 0.402706 | 0.140625 | 00:02 | . learn.show_results(max_n=16) . interp = Interpretation.from_learner(learn) interp.plot_top_losses(4) . - 수동으로 특정 observation에 대한 예측결과를 확인하여 보자. . dls.train_ds . (#260) [(PILImage mode=RGB size=1920x1200, TensorCategory(1)),(PILImage mode=RGB size=1000x774, TensorCategory(1)),(PILImage mode=RGB size=846x790, TensorCategory(0)),(PILImage mode=RGB size=1000x1300, TensorCategory(0)),(PILImage mode=RGB size=900x600, TensorCategory(1)),(PILImage mode=RGB size=1280x720, TensorCategory(0)),(PILImage mode=RGB size=658x987, TensorCategory(0)),(PILImage mode=RGB size=1280x1622, TensorCategory(1)),(PILImage mode=RGB size=500x559, TensorCategory(0)),(PILImage mode=RGB size=660x400, TensorCategory(0))...] . training set | . dls.train_ds[0] . (PILImage mode=RGB size=1920x1200, TensorCategory(1)) . dls.train_ds[0] 가 의미하는 것은 첫번쨰 observation을 의미함. 즉 $(x_1,y_1)$ | $x_1$ = PILImage mode = RGB size = 960*960 | $y_1$ = TensorCategory(1) | . dls.train_ds[210][0] . $x_{211}$ = 위의 이미지 | . dls.train_ds[210][1] . TensorCategory(0) . dls.train_ds[210] . (PILImage mode=RGB size=1080x1080, TensorCategory(0)) . - 1이면 iu, 0이면 hynn 인 것을 유추할 수 있음. . $y_{211}$ = TensorCategory(0) | . x210=dls.train_ds[210][0] . learn.predict(x210) . (&#39;hynn&#39;, tensor(0), tensor([0.9952, 0.0048])) . Test . path = Path() . if not (path/&#39;test&#39;).exists(): (path/&#39;test&#39;).mkdir() . urls=search_images_ddg(&#39;hynn 박혜원&#39;,max_n=20) download_images(path/&#39;test&#39;,urls=urls) testset=get_image_files(path/&#39;test&#39;) testset . (#26) [Path(&#39;test/00000007.jpeg&#39;),Path(&#39;test/00000019.jpg&#39;),Path(&#39;test/00000009.png&#39;),Path(&#39;test/00000018.jpg&#39;),Path(&#39;test/00000019.png&#39;),Path(&#39;test/00000015.jpg&#39;),Path(&#39;test/00000016.jpg&#39;),Path(&#39;test/00000004.jpg&#39;),Path(&#39;test/00000013.jpg&#39;),Path(&#39;test/00000006.jpg&#39;)...] . for i in range(len(testset)): print(learn.predict(PILImage.create(testset[i]))) . (&#39;hynn&#39;, tensor(0), tensor([0.9755, 0.0245])) . (&#39;hynn&#39;, tensor(0), tensor([0.9971, 0.0029])) . (&#39;hynn&#39;, tensor(0), tensor([9.9986e-01, 1.3556e-04])) . (&#39;hynn&#39;, tensor(0), tensor([9.9957e-01, 4.3153e-04])) . (&#39;iu&#39;, tensor(1), tensor([1.1942e-04, 9.9988e-01])) . (&#39;hynn&#39;, tensor(0), tensor([9.9997e-01, 3.0605e-05])) . (&#39;hynn&#39;, tensor(0), tensor([9.9901e-01, 9.9428e-04])) . (&#39;hynn&#39;, tensor(0), tensor([9.9988e-01, 1.2449e-04])) . (&#39;iu&#39;, tensor(1), tensor([0.0530, 0.9470])) . (&#39;iu&#39;, tensor(1), tensor([0.2828, 0.7172])) . (&#39;hynn&#39;, tensor(0), tensor([1.0000e+00, 6.0792e-08])) . (&#39;iu&#39;, tensor(1), tensor([0.2056, 0.7944])) . (&#39;hynn&#39;, tensor(0), tensor([9.9994e-01, 5.7602e-05])) . (&#39;hynn&#39;, tensor(0), tensor([9.9988e-01, 1.2449e-04])) . (&#39;hynn&#39;, tensor(0), tensor([0.9382, 0.0618])) . (&#39;hynn&#39;, tensor(0), tensor([9.9998e-01, 2.0421e-05])) . (&#39;iu&#39;, tensor(1), tensor([0.2828, 0.7172])) . (&#39;hynn&#39;, tensor(0), tensor([9.9989e-01, 1.1234e-04])) . (&#39;hynn&#39;, tensor(0), tensor([0.9959, 0.0041])) . (&#39;hynn&#39;, tensor(0), tensor([0.9986, 0.0014])) . (&#39;hynn&#39;, tensor(0), tensor([9.9998e-01, 1.8711e-05])) . (&#39;hynn&#39;, tensor(0), tensor([9.9997e-01, 3.0605e-05])) . (&#39;hynn&#39;, tensor(0), tensor([0.9980, 0.0020])) . (&#39;hynn&#39;, tensor(0), tensor([0.9895, 0.0105])) . (&#39;hynn&#39;, tensor(0), tensor([0.8985, 0.1015])) . (&#39;hynn&#39;, tensor(0), tensor([0.9977, 0.0023])) . 결과를 보니까 hynn이 많음 $ to$ 어느정도 맞추는것 같긴하다. | . PILImage.create(testset[4]) . 실제로는 hynn인데 iu로 예측한 사진 | . path = Path() . if not (path/&#39;test2&#39;).exists(): (path/&#39;test2&#39;).mkdir() . urls=search_images_ddg(&#39;iu 아이유&#39;,max_n=20) download_images(path/&#39;test2&#39;,urls=urls) testset=get_image_files(path/&#39;test2&#39;) testset . (#22) [Path(&#39;test2/00000019.jpg&#39;),Path(&#39;test2/00000018.jpg&#39;),Path(&#39;test2/00000015.jpg&#39;),Path(&#39;test2/00000016.jpg&#39;),Path(&#39;test2/00000004.jpg&#39;),Path(&#39;test2/00000013.jpg&#39;),Path(&#39;test2/00000006.jpg&#39;),Path(&#39;test2/00000005.jpg&#39;),Path(&#39;test2/00000008.jpg&#39;),Path(&#39;test2/00000011.jpg&#39;)...] . for i in range(len(testset)): print(learn.predict(PILImage.create(testset[i]))) . (&#39;iu&#39;, tensor(1), tensor([1.0493e-05, 9.9999e-01])) . (&#39;iu&#39;, tensor(1), tensor([5.3872e-06, 9.9999e-01])) . (&#39;iu&#39;, tensor(1), tensor([8.6674e-07, 1.0000e+00])) . (&#39;iu&#39;, tensor(1), tensor([6.6005e-04, 9.9934e-01])) . (&#39;iu&#39;, tensor(1), tensor([0.0021, 0.9979])) . (&#39;iu&#39;, tensor(1), tensor([0.0021, 0.9979])) . (&#39;iu&#39;, tensor(1), tensor([1.3685e-04, 9.9986e-01])) . (&#39;iu&#39;, tensor(1), tensor([3.8723e-06, 1.0000e+00])) . (&#39;iu&#39;, tensor(1), tensor([1.5014e-05, 9.9998e-01])) . (&#39;iu&#39;, tensor(1), tensor([1.5859e-05, 9.9998e-01])) . (&#39;iu&#39;, tensor(1), tensor([0.0551, 0.9449])) . (&#39;iu&#39;, tensor(1), tensor([0.0352, 0.9648])) . (&#39;iu&#39;, tensor(1), tensor([1.9844e-05, 9.9998e-01])) . (&#39;iu&#39;, tensor(1), tensor([1.0545e-05, 9.9999e-01])) . (&#39;iu&#39;, tensor(1), tensor([1.9844e-05, 9.9998e-01])) . (&#39;iu&#39;, tensor(1), tensor([9.3245e-06, 9.9999e-01])) . (&#39;iu&#39;, tensor(1), tensor([8.8714e-08, 1.0000e+00])) . (&#39;iu&#39;, tensor(1), tensor([7.0835e-05, 9.9993e-01])) . (&#39;iu&#39;, tensor(1), tensor([0.0094, 0.9906])) . (&#39;iu&#39;, tensor(1), tensor([0.0352, 0.9648])) . (&#39;iu&#39;, tensor(1), tensor([0.1664, 0.8336])) . (&#39;iu&#39;, tensor(1), tensor([7.0835e-05, 9.9993e-01])) . PILImage.create(testset[8]) . 결과를 보니 아이유 역시 잘 맞추는 듯 보인다. | . - 정확률이 아쉽긴 하지만 어느정도 유의미한 결과를 얻었다. . . &#45236;&#44032; &#50896;&#54616;&#45716; &#51060;&#48120;&#51648;&#47484; &#47784;&#50500;&#49436; &#54644;&#48372;&#44592;! . keywords = &#39;simpsons&#39;, &#39;spongebob&#39; path=Path(&#39;program&#39;) . if not path.exists(): path.mkdir() for keyword in keywords: lastpath=path/keyword lastpath.mkdir(exist_ok=True) urls=search_images_ddg(keyword) download_images(lastpath, urls=urls) . verify_images(get_image_files(path)) . (#0) [] . verify_images(get_image_files(path)) . (#0) [] . dls = ImageDataLoaders.from_folder( path, train=&#39;program&#39;, valid_pct=0.2, item_tfms=Resize(224)) . dls.show_batch(max_n=16) . learn=cnn_learner(dls,resnet34,metrics=error_rate) learn.fine_tune(3) . epoch train_loss valid_loss error_rate time . 0 | 1.225802 | 0.419170 | 0.220588 | 00:04 | . epoch train_loss valid_loss error_rate time . 0 | 0.338974 | 0.184293 | 0.058824 | 00:04 | . 1 | 0.231918 | 0.061374 | 0.029412 | 00:04 | . 2 | 0.180025 | 0.056058 | 0.014706 | 00:04 | . learn.show_results(max_n=16) . interp = Interpretation.from_learner(learn) interp.plot_top_losses(16) .",
            "url": "https://kimha02.github.io/ham/python/2021/09/09/(2%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "relUrl": "/python/2021/09/09/(2%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "date": " • Sep 9, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "(1주차) 9월 7일",
            "content": "Import . from fastai.vision.all import * . &#45936;&#51060;&#53552; &#51200;&#51109;, &#45936;&#51060;&#53552; &#47196;&#45908;&#49828; &#49373;&#49457; &#54980; dls&#47196; &#51200;&#51109; . path=untar_data(URLs.PETS)/&#39;images&#39; . URLs.PETS? . Type: str String form: https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz Length: 62 Docstring: str(object=&#39;&#39;) -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to &#39;strict&#39;. . URLs.PETS는 스트링인데 주소가 저장되어 있는 것임 | . path #주소 확인 . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images&#39;) . path.ls() #path안에 있는 데이터 확인 . (#7393) [Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/boxer_128.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Sphynx_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/British_Shorthair_203.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Ragdoll_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Persian_272.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Bombay_200.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/shiba_inu_103.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/chihuahua_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/scottish_terrier_156.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/basset_hound_163.jpg&#39;)...] . files=get_image_files(path) #이미지파일들의 이름을 모두 복붙하여 리스트를 만든 뒤에 files.txt로 저장하는 과정으로 비유할 수 있음 . files . (#7390) [Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/boxer_128.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Sphynx_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/British_Shorthair_203.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Ragdoll_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Persian_272.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/Bombay_200.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/shiba_inu_103.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/chihuahua_142.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/scottish_terrier_156.jpg&#39;),Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/basset_hound_163.jpg&#39;)...] . files[2] #txt파일의 3번째 목록 . Path(&#39;/home/khy/.fastai/data/oxford-iiit-pet/images/British_Shorthair_203.jpg&#39;) . def label_func(f): if f[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . label_func(&#39;Dog&#39;) . &#39;cat&#39; . 위에서 만든 함수 label_func로 y를 판별해내 저장해보도록 하겠음! $ to$ 이게 dls로 저장하는 것! | . from_name_func에 경로, 우리가 이미지 파일을 따로 저장해준 files, 판별해낼 함수를 넣고, 이미지 크기가 다 달라서 동일하게 맞춰주는 옵션을 넣어줌. | . dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(224)) . dls.show_batch(max_n=16) . learn=cnn_learner(dls,resnet18,metrics=error_rate) #cnn_learner(cell, 모형, 평가지표) . #!conda install -c conda-forge ipywidgets -y #!conda install -c conda-forge nodejs -y . learn.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.153901 | 0.031889 | 0.012855 | 00:06 | . epoch train_loss valid_loss error_rate time . 0 | 0.068081 | 0.016483 | 0.007442 | 00:07 | . learn.predict(files[0]) . (&#39;dog&#39;, tensor(1), tensor([3.3425e-04, 9.9967e-01])) . learn.show_results() #전체 결과 . &#50724;&#45813; &#48516;&#49437; . interp = Interpretation.from_learner(learn) . interp.plot_top_losses(4) . &#51652;&#51676; &#51096;&#46104;&#45716;&#44172; &#47582;&#45716;&#44148;&#44032;???? . PILImage.create(&#39;2021-09-06-cat1.png&#39;) . learn.predict(PILImage.create(&#39;2021-09-06-cat1.png&#39;)) . (&#39;cat&#39;, tensor(0), tensor([9.9991e-01, 9.0146e-05])) . PILImage.create(&#39;2021-09-06-cat2.png&#39;) . learn.predict(PILImage.create(&#39;2021-09-06-cat2.png&#39;)) . (&#39;cat&#39;, tensor(0), tensor([1.0000e+00, 3.2217e-06])) . PILImage.create(&#39;2021-09-06-hani01.png&#39;) . learn.predict(PILImage.create(&#39;2021-09-06-hani01.png&#39;)) . (&#39;dog&#39;, tensor(1), tensor([5.9770e-07, 1.0000e+00])) . PILImage.create(&#39;2021-09-06-hani02.png&#39;) . learn.predict(PILImage.create(&#39;2021-09-06-hani02.png&#39;)) . (&#39;dog&#39;, tensor(1), tensor([0.0091, 0.9909])) . PILImage.create(&#39;2021-09-06-hani03.png&#39;) . learn.predict(PILImage.create(&#39;2021-09-06-hani03.png&#39;)) . (&#39;dog&#39;, tensor(1), tensor([0.2357, 0.7643])) . . &#45796;&#47480; &#51060;&#48120;&#51648;&#47196; &#54644;&#48372;&#44592;! . PILImage.create(&#39;2021-11-01-ggul.jpg&#39;) . learn.predict(PILImage.create(&#39;2021-11-01-ggul.jpg&#39;)) . (&#39;dog&#39;, tensor(1), tensor([0.0659, 0.9341])) . 강아지로 잘 맞췄고, 강아지가 아닌 확률이 0.9341로 잘 예측함! | . PILImage.create(&#39;ggul2.jpg&#39;) . learn.predict(PILImage.create(&#39;ggul2.jpg&#39;)) . (&#39;dog&#39;, tensor(1), tensor([0.0191, 0.9809])) .",
            "url": "https://kimha02.github.io/ham/python/2021/09/07/(1%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "relUrl": "/python/2021/09/07/(1%EC%A3%BC%EC%B0%A8)-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0.html",
            "date": " • Sep 7, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "(공부) R_ggplot2",
            "content": "참고 :「R을 활용한 데이터 과학」 1장 내용을 실습한 내용임 &gt; ggplot2는 구글링해도 좋은 자료들이 많아서 더 예쁘게 시각화하고 싶을 때는 추가 정보를 꼭 찾아볼 것! . ggplot2 . ggplot2 ⊂ tidyverse -&gt; library(tidyverse)가 더 편하겠다 | + 표시는 항상 마지막에 넣어준다 | . (&#9733;) ggplot &#53076;&#46300; &#53596;&#54540;&#47551; . ggplot(data=NAME)+ geom_함수(mapping=aes(x=NAME, y=NAME, color=NAME), stat=STAT, position=POSITION)+ 좌표계함수 + 면분할함수 . ggplot(data=dia)+ geom_bar(mapping=aes(x=cut, fill=color), stat=&quot;count&quot;, position=&quot;stack&quot;)+ coord_flip() . . 1. geom_point . 0) 기본 형태 . ggplot(data = NAME)+ geom_point(mapping = aes(x = NAME, y = NAME)) . library(tidyverse) . library(patchwork) . dia&lt;-diamonds; str(dia) . tibble [53,940 × 10] (S3: tbl_df/tbl/data.frame) $ carat : num [1:53940] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... $ cut : Ord.factor w/ 5 levels &#34;Fair&#34;&lt;&#34;Good&#34;&lt;..: 5 4 2 4 2 3 3 3 1 3 ... $ color : Ord.factor w/ 7 levels &#34;D&#34;&lt;&#34;E&#34;&lt;&#34;F&#34;&lt;&#34;G&#34;&lt;..: 2 2 2 6 7 7 6 5 2 5 ... $ clarity: Ord.factor w/ 8 levels &#34;I1&#34;&lt;&#34;SI2&#34;&lt;&#34;SI1&#34;&lt;..: 2 3 5 4 2 6 7 3 4 5 ... $ depth : num [1:53940] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... $ table : num [1:53940] 55 61 65 58 58 57 57 55 61 61 ... $ price : int [1:53940] 326 326 327 334 335 336 336 337 337 338 ... $ x : num [1:53940] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... $ y : num [1:53940] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... $ z : num [1:53940] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... . ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price)) . 1) 그룹별로 차이를 주고 싶을 때 - aes 안에 심미성 요소 를 넣어준다 - color, size, alpha, shape . a&lt;-ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price, color=cut))+ggtitle(&#39;color&#39;) #color_1가지 색으로만 b&lt;-ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price), color=&quot;blue&quot;)+ggtitle(&#39;one_color&#39;) #size_크기 c&lt;-ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price, size=cut))+ggtitle(&#39;size&#39;) #alpha_투명도 d&lt;-ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price, alpha=cut))+ggtitle(&#39;alpha&#39;) #shape_점모양 e&lt;-ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price, shape=cut))+ggtitle(&#39;shape&#39;) #shape은 6개까지만 . options(repr.plot.width=10, repr.plot.height=7,repr.plot.res=100) (a+b+c)/(d+e) #patchwork . Warning message: “Using shapes for an ordinal variable is not advised” . 2) 오버 플로팅을 방지하고 싶을 때 - position = &quot;jitter&quot;로 조금씩 움직일 수 있다 - geom_jitter 도 가능 . ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price), position=&quot;jitter&quot;) . 3) 면분할 - facet_wrap : 한 개의 변수로 면분할, 이산형 변수만 사용 가능하다 - fece_grid : 두 개의 변수 조합으로 면분할 . ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price))+ facet_wrap(~cut, nrow=1) . ggplot(data=dia)+ geom_point(mapping=aes(x=carat, y=price))+ facet_grid(color~cut) . . 2. geom_smooth . 0) 기본 형태 . 평활 geom 이다.ggplot(data = NAME)+ geom_smooth(mapping = aes(x = NAME, y = NAME)) . | . 그룹별로 차이를 주고 싶을 때 | aes 안에 심미성 요소 를 넣어준다 | linetype, color | . a&lt;-ggplot(data=dia)+geom_smooth(mapping=aes(x=carat, y=price, linetype=cut)) #color b&lt;-ggplot(data=dia)+geom_smooth(mapping=aes(x=carat, y=price, color=cut)) . a+b . `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &#34;cs&#34;)&#39; `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &#34;cs&#34;)&#39; . ggplot(data=dia)+geom_smooth(mapping=aes(x=carat, y=price, linetype=cut), se=F) . `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &#34;cs&#34;)&#39; . 특정 데이터만 보고 싶을 때 | filter 사용 아래는 price가 10,000 보다 큰 data만 사용한 그림이다 | . | . ggplot(data=filter(dia, price&gt;10000))+geom_smooth(mapping=aes(x=carat, y=price, linetype=cut), se=F) . `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &#34;cs&#34;)&#39; . . (*) geom_point + geom_smooth . 같이 쓰면 ggplot 안에 데이터명, x, y 지정을 한 번에 해주면 편하다. | . ggplot(data=dia, mapping=aes(x=carat, y=price))+ geom_point(mapping=aes(color=cut))+ geom_smooth(mapping=aes(linetype=cut), se=F) . `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &#34;cs&#34;)&#39; . . 3. geom_bar . 0) 기본 형태 . 막대그래프로, y에는 count()가 들어간다. 각 막대들을 bin이라고 생각하면 편하다!ggplot(data = NAME)+ geom_bar(mapping = aes(x = NAME)) . | . 그룹별로 차이를 주고 싶을 때 | fill으로 채우기 색 변화 | color로 테두리 색 변화 | dodge로 그룹핑해 한 번에 확인하기 | . ggplot(data = dia)+ geom_bar(mapping = aes(x = cut, fill=cut)) . ggplot(data = dia)+ geom_bar(mapping = aes(x = cut, fill=color)) . ggplot(data = dia)+ geom_bar(mapping = aes(x = cut, color=cut), fill=&#39;white&#39;) . ggplot(dia) + geom_bar(aes(x = cut, fill = color), position = &quot;dodge&quot;) . 비율(%) 로 표시하고 싶을 때 | ..prop.. 추가 | . ggplot(data = dia)+ geom_bar(mapping = aes(x = cut, y=..prop..,group=3)) #책에는 group=1이라고 되어있는데 아무거나 넣어도 상관없나보다 . 각 항목의 color의 분포 정도를 보고 싶을 때 $ to$ 내가 생각한 비율로 보는 그래프에 가까운 것 같아 | . ggplot(dia) + geom_bar(aes(x = cut, fill =color), position = &quot;fill&quot;) . . 4. stat_summary . 0) 기본 형태 . y값 요약해줘!ggplot(data = NAME)+ stat_summary(mapping = aes(x = NAME, y = NAME), fun.y=FUNCTION NAME) . | . 여러 가지 요약값을 보여주는 것도 가능하다 | 최소값, 중앙값, 최대값 보여주기 | . ggplot(dia) + stat_summary(aes(x=cut, y=price) ,fun.ymin=min, fun.ymax=max, fun.y=median) . Warning message: “`fun.y` is deprecated. Use `fun` instead.” Warning message: “`fun.ymin` is deprecated. Use `fun.min` instead.” Warning message: “`fun.ymax` is deprecated. Use `fun.max` instead.” .",
            "url": "https://kimha02.github.io/ham/r/2021/08/30/R-1.html",
            "relUrl": "/r/2021/08/30/R-1.html",
            "date": " • Aug 30, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "(공부) Higher-order function",
            "content": "Intro . def myadd(a,b): return a+b . myadd(1,2) . 3 . ?myadd . Signature: myadd(a, b) Docstring: &lt;no docstring&gt; File: /tmp/ipykernel_3127126/4154224718.py Type: function . Type이 function이다? . | myadd 는 function class의 instance이다. . | 결국 myadd 역시 하나의 오브젝트에 불과하다. . | . . higher-order function . myadd(1,2) . 3 . myadd의 입력 1,2는 int class의 인스턴스 오브젝트였음. . | 즉 문법의 논리로 보면 함수의 입력에 들어갈 수 있는 것은 오브젝트면 된다. . 그런데 함수 자체도 오브젝트이다 $ to$ 함수도 함수의 입력으로 쓸 수 있다? | . | . . &#50696;&#51228;1 . def calc(fun,a,b): return fun(a,b) . calc(myadd,-3,3) . 0 . 이처럼 함수 자체를 입력으로 받거나 출력으로 보내는 함수를 higher-order function이라고 한다. | . . &#50696;&#51228;2 . 미분: 아래의 함수 | . $$f(x)=3x^2-2x+5$$ . 에서 x=2에서의 접선의 기울기는 아래와 같이 대략적으로 구할 수 있다. . $$ frac{f(2+h)-f(2)}{h}, quad h=0.0000001$$ . $h$의 값을 더 0에 가깝게 만든다면 접선의 기울기의 정확도는 올라간다. | . 미분에 익숙하다면 이론적으로 아래와 같이 $x=2$일때 접선의 기울기를 구할 수 있다. . $f&#39;(x)=6x-2$ | $f&#39;(2)=12-2=10$ | . | 즉 $x=2$일때 이론적으로 구한 접선의 기울기값은 10이다. . | . 미분을 계산해주는 코드를 구현하자. | . def f(x): return 3*x**2-2*x+5 . def derivative(fun,x): #fun은 함수 h=0.00000001 return (fun(x+h)-fun(x))/h . derivative(f,2) . 9.99999993922529 . $g(x)=x^2$와 같은 함수를 미분하고 싶다면? | . def g(x): return x**2 . derivative(g,0) . 1e-08 .",
            "url": "https://kimha02.github.io/ham/python/2021/08/29/python-14.html",
            "relUrl": "/python/2021/08/29/python-14.html",
            "date": " • Aug 29, 2021"
        }
        
    
  
    
        ,"post28": {
            "title": "(공부) aliasing(에일리어싱)",
            "content": ". &#50696;&#51228;1 . 아래의 코드를 관찰하자. | . a=[1,2,3] b=a a.append(4) . 현재 b의 출력결과는? → a와 b 모두 바뀌어버렸다! → a와 b는 무조건 같이 움직이는 건가? | . a, b . ([1, 2, 3, 4], [1, 2, 3, 4]) . . &#50696;&#51228;2 . 하지만 아래 예제에서 b는 영향을 받지 않았다..? | . a=[1,2,3] b=a a=[1,2,3]+[4] . a, b . ([1, 2, 3, 4], [1, 2, 3]) . . &#47700;&#47784;&#47532;&#44396;&#51312; &#49345;&#49345; . 아래의 코드를 다시 살펴보자. a=[1,2,3] b=a a.append(4) . a,b라는 변수들은 메모리에 어떻게 저장되어 있을까? | . 상상력을 발휘하면 아래와 같이 생각할 수 있다. | . (1) 메모리는 방이 100개 있는 호텔이라고 생각하자. . (2) 아래를 실행했을 때 . a=[1,2,3] . 메모리주소1에 존재하는 방을 앞으로 a라고 부르자. 그리고 그 방에 [1,2,3]을 넣는다. | . (3) 아래를 실행했을 때 . b=a . 메모리주소7에 존재하는 방을 앞으로 b라고 부르고 그 방에 a를 넣는다. | 그런데 a=[1,2,3]이므로 b역시 [1,2,3]이 들어가 있다. | . (4) 아래를 실행했을 때 . a.append(4) . 방 a로 가서 [1,2,3]을 [1,2,3,4]로 바꾼다. | 방 b는 아무일도 일어나지 않는다. | 다른 언어에서는 이러한 상상이 맞는 이야기 일 수 있는데, 파이썬에서는 다르다. ` | . a=[1,2,3] b=a a.append(4) . id(a) . 140603071933120 . id(b) . 140603071933120 . b . [1, 2, 3, 4] . a,b 변수 모두 동일한 메모리주소에 저장되어 있음. | . ★ 아래와 같이 상상하는것이 더 올바르게 이해할 수 있다. . (1) 메모리는 방이 100개 있는 호텔이라고 생각하자. . (2) 아래를 실행했을 때 . a=[1,2,3] . [1,2,3] 이라는 오브젝트가 먼저 만들어지고, | [1,2,3] 이 저장된 메모리주소(140187934839488번 방)에 a라는 포스트잇을 붙이자. | [1,2,3] 을 찾기위해서는 a라는 포스트잇이 붙은 방을 찾아가서 내용을 열어보면 된다. | . (3) 아래를 실행했을 때 . b=a . a라는 포스트잇이 붙은 메모리주소(140187934839488번 방)에 b라는 포스트잇을 추가로 붙인다. | 같은 방에 a,b라는 포스트잇이 모두 붙어있는 상태이므로, [1,2,3]을 찾기 위해서는 b라는 포스트잇을 찾아가서 내용을 읽어보거나, a라는 포스트잇을 찾아가서 내용을 읽어본다. | . (4) 아래를 실행했을 때 . a.append(4) . a라는 포스트잇이 붙은 방으로 찾아가서, [1,2,3]을 찾고 거기에서 append함수를 써서 [1,2,3,4]로 바꾼다. | 같은 방에 a,b라는 포스트잇이 모두 붙어있으므로 b라는 포스트잇을 찾아가서 내용을 열어보면 [1,2,3,4]가 나온다. | . . &#54624;&#45817;&#47928;&#51032; &#51060;&#54644; . 파이썬에서 할당문을 이해하려면 언제나 오른쪽을 먼저 읽어야 한다. . 할당문의 오른쪽에서 객체를 생성하거나 가져온다. | 그 후에 포스트잇을 붙이듯이 할당문 왼쪽의 변수가 객체에 바인딩 된다. | . → [1,2,3]이라는 공간이 생긴 후 그 메모리 주소를 a라고 부른다. . . &#50640;&#51068;&#47532;&#50612;&#49905;(aliasing) . b=a는 . 나는 이미 a가 의미하는걸 알고 있어, 그런데 a가 의미하는걸 b라고도 부르고 싶다. . 라는 것과 같다. 즉 이미 a라고 부르고 있던것을 가져와서 b라고도 부르고 싶다는 의미인데, 이러한 관점에서 ★b는 a의 별칭(alias)★이라고 볼 수 있다. . 반대로 생각해보면 a 역시 b의 별명이라고 볼 수 있다. . ★하나의 메모리 주소에 여러 개의 변수이름을 바인드하는 것을 aliasing이라고 부른다.★ . . ID vs value . - 모든 객체(object)는 ID, value, type을 가진다. . https://docs.python.org/3/reference/datamodel.html#objects-values-and-types . - 아래의 예제를 고려하자. . a=[1,2,3] b=a a.append(4) c=[1,2,3,4] . 여기에서 a,b,c는 모두 같은 값을 가진다. . a,b,c . ([1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]) . a==c, b==c, c==a . (True, True, True) . - 하지만 그 ID가 같은 것은 아니다. . id(a),id(b),id(c) . (140603072685248, 140603072685248, 140603072642688) . a is b, b is c, c is a . (True, False, False) . . Note: 연산자 == 는 두 객체간의 값(value)를 비교하고 연산자 is는 두 객체간의 메모리주소값을 비교한다. . . &#47560;&#47924;&#47532; . 아래의 코드를 다시 비교해보자. | . ## code1 a=[1,2,3] b=a a.append(4) . ## code2 a=[1,2,3] b=a a=[1,2,3]+[4] . code2는 [1,2,3]+[4]라는 새로운 오브젝트가 만들어진 후, a 포스트잇이 이 공간에 붙여지는 것이다. → 그래서 b와 개별로 움직이는 것! | .",
            "url": "https://kimha02.github.io/ham/python/2021/08/28/python-13.html",
            "relUrl": "/python/2021/08/28/python-13.html",
            "date": " • Aug 28, 2021"
        }
        
    
  
    
        ,"post29": {
            "title": "(공부) WITH문",
            "content": "&#54028;&#51068;&#51069;&#44592; . &#50696;&#51228;1 . f=open(&#39;test[1].txt&#39;) . a=f.read() . a . &#39;hello nhello2 nhello3&#39; . print(a) # n은 enter . hello hello2 hello3 . f.closed #닫혀있는 상태인지 확인 . False . - 현재 f가 열려있는 상태이다. 따라서 닫아줘야 한다. . f.close() #닫아주는 명령어 . f.closed . True . (?) 왜 닫아야 할까 . 열려있으면 원하지 않는 수정 등이 일어날 수 있고, 메모리를 차지할 수도 있기 때문임 -&gt; 그냥 인터넷 창 닫는 느낌? 파일을 닫지 않는다고 해서 큰 문제는 없어보이지만 그냥 닫는것이 좋다. f가 닫힌 상태에서는 더 이상 읽을 수가 없다. . b=f.read() . ValueError Traceback (most recent call last) /tmp/ipykernel_661245/672958580.py in &lt;module&gt; -&gt; 1 b=f.read() ValueError: I/O operation on closed file. . &#9733; motivation . 생각해 보니까 파일을 열면 항상 닫아야 한다. 이처럼 쌍(시작-끝)으로 수행되는 처리가 반복적으로 발생하는 경우가 있는데 그때마다 .close() 메소드 따위를 쓰는 것이 번거롭게 느껴진다. 예를 들면 파일을 열었으면 적당한 동작 뒤에 알아서 닫아졌으면 좋겠다는 것이다. . 이러한 모티브에서 구현된 것이 with문 이다. . with open(&#39;test[1].txt&#39;) as g: print(g.read()) . hello hello2 hello3 . - 파일이 닫아졌는지 확인해보자. . g.closed . True . . &#44592;&#48376;&#49324;&#50857;&#48277; . with의 사용법은 직관적으로 이해가 가능하지만 그래도 다시 한 번 살펴보자. . with blabla as variable: yadiyadi yadiyadi2 . (1) with blabla as variable에서 blabla가 실행된다. . (2) blabla의 실행결과로 어떠한 특별한 오브젝트가 만들어지는데 그 오브젝트를 우리가 variable로 부르기로 한다. . (3) 탭으로 들여쓰기된 부분, 즉 yadiyadi, yadiyadi2 가 순서대로 실행된다. . (4) 탭으로 들여쓰기된 부분이 실행되고 난 뒤에 g.closed() 따위의 미리 약속된 어떠한 코드가 실행되는 것 같다. . . &#46041;&#51089;&#50896;&#47532; . - g 라는 오브젝트를 특별한 오브젝트라고 했는데, 무엇이 특별한지 알아보자. . dir(g) . [&#39;_CHUNK_SIZE&#39;, &#39;__class__&#39;, &#39;__del__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__enter__&#39;, &#39;__eq__&#39;, &#39;__exit__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__next__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;_checkClosed&#39;, &#39;_checkReadable&#39;, &#39;_checkSeekable&#39;, &#39;_checkWritable&#39;, &#39;_finalizing&#39;, &#39;buffer&#39;, &#39;close&#39;, &#39;closed&#39;, &#39;detach&#39;, &#39;encoding&#39;, &#39;errors&#39;, &#39;fileno&#39;, &#39;flush&#39;, &#39;isatty&#39;, &#39;line_buffering&#39;, &#39;mode&#39;, &#39;name&#39;, &#39;newlines&#39;, &#39;read&#39;, &#39;readable&#39;, &#39;readline&#39;, &#39;readlines&#39;, &#39;reconfigure&#39;, &#39;seek&#39;, &#39;seekable&#39;, &#39;tell&#39;, &#39;truncate&#39;, &#39;writable&#39;, &#39;write&#39;, &#39;write_through&#39;, &#39;writelines&#39;] . ★ 비밀은 __enter__ 와 __exit__ 메소드에 있다. . __enter__ 와 __exit__ 의 역할을 알아보기 위해서 아래의 코드를 다시 관찰하자. . with open(&#39;test.txt&#39;) as g: print(g.read()) . (for문 복습) for i in ...: 에서 ...에 올 수 있는 오브젝트는 __iter__ 메소드가 정의되어 있어야 한다. 이러한 오브젝트를 iterable한 오브젝트라고 한다. . (with문) with ... as variable: 에서 ...의 실행결과로 생성되는 오브젝트는 __enter__ 와 __exit__ 메소드가 정의되어 있어야 한다. . 이 중 __enter__는 with문이 시작되면 자동으로 실행된다. | 이 중 __exit__는 with문이 끝나면 자동으로 실행된다. | . . &#50696;&#51228;2 . class MooYaHo: def __init__(self): #enter와 init 중 뭐가 먼저 실행될까? mooyaho가 실행되면서 init 실행 -&gt; with 실행되면서 enter 실행 print(&#39;init&#39;) def __enter__(self): print(&#39;무야호&#39;) def __exit__(self,exc_type,exc_value,traceback): # self 이외의 3가지 변수는 예외처리에 관련된 변수인데 여기서는 다루지 않음. print(&#39;그만큼 신나시는거지&#39;) . with MooYaHo() as a: print(&#39;.&#39;) . init 무야호 . 그만큼 신나시는거지 . - 경우에 따라서 as 이하를 생략할 수 있다. . with MooYaHo(): print(&#39;xx&#39;) . init 무야호 xx 그만큼 신나시는거지 .",
            "url": "https://kimha02.github.io/ham/python/2021/08/27/python-12.html",
            "relUrl": "/python/2021/08/27/python-12.html",
            "date": " • Aug 27, 2021"
        }
        
    
  
    
        ,"post30": {
            "title": "(공부) 데이터시각화",
            "content": "matplotlib: &#48289;&#53552;&#52828;&#54868;&#51201;&#51064; &#49884;&#44033;&#54868; . &#50696;&#51228;1 . ! pip install matplotlib #패키지 설치 . Requirement already satisfied: matplotlib in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (3.4.2) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from matplotlib) (1.3.1) Requirement already satisfied: cycler&gt;=0.10 in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from matplotlib) (0.10.0) Requirement already satisfied: python-dateutil&gt;=2.7 in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from matplotlib) (2.8.2) Requirement already satisfied: pillow&gt;=6.2.0 in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from matplotlib) (8.3.1) Requirement already satisfied: numpy&gt;=1.16 in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from matplotlib) (1.21.1) Requirement already satisfied: pyparsing&gt;=2.2.1 in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from matplotlib) (2.4.7) Requirement already satisfied: six in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from cycler&gt;=0.10-&gt;matplotlib) (1.16.0) . import matplotlib.pyplot as plt . x=[1,2,3,4] y=[1,2,3,2] . plt.plot(x,y,&#39;x&#39;) ### &#39;x&#39;는 모양 . [&lt;matplotlib.lines.Line2D at 0x7efc4a957c40&gt;] . y2=[1.1,2.1,3.2,1] . plt.plot(x,y,&#39;:o&#39;) plt.plot(x,y2,&#39;:o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efc4a86aa90&gt;] . &#50696;&#51228;2 . import pandas as pd . dfdata=pd.read_csv(&quot;dfdata[1].csv&quot;) . dfdata.head() . toeic gpa employed company salary . 0 400 | 4.2 | N | - | 0 | . 1 445 | 2.2 | N | - | 0 | . 2 440 | 3.4 | N | - | 0 | . 3 490 | 3.8 | N | - | 0 | . 4 520 | 4.1 | Y | K | 5000 | . plt.plot(dfdata.toeic,dfdata.gpa,&#39;o&#39;) #x=toeic, y=gpa, shape=&#39;o&#39; . [&lt;matplotlib.lines.Line2D at 0x7efc44d3c400&gt;] . - 색깔로 그룹 구분하기 . toeic_y=dfdata.query(&#39;employed==&quot;Y&quot;&#39;).toeic #채용된 사람들의 토익점수 toeic_n=dfdata.query(&#39;employed==&quot;N&quot;&#39;).toeic #채용 안 된 사람들의 토익점수 gpa_y=dfdata.query(&#39;employed==&quot;Y&quot;&#39;).gpa #채용된 사람들의 성적 gpa_n=dfdata.query(&#39;employed==&quot;N&quot;&#39;).gpa #채용 안 된 사람들의 성적 plt.plot(toeic_y,gpa_y,&#39;o&#39;) #Blue Point plt.plot(toeic_n,gpa_n,&#39;o&#39;) #Orange Point . [&lt;matplotlib.lines.Line2D at 0x7efc436ac940&gt;] . - 그런데 과정이 좀 복잡해보인다. . 과정 :데이터프레임 -&gt; 쿼리문 -&gt; 필터링된 데이터 프레임 -&gt; 벡터화 -&gt; 저장 -&gt; 플랏 데이터 프레임을 벡터화하여 플랏하는 과정은 필수적인데 좀 귀찮다. ★ 바로 플랏하는 방법을 알아보자! . . seaborn: &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; &#52828;&#54868;&#51201;&#51064; &#49884;&#44033;&#54868; . &#50696;&#51228;2 (&#51060;&#50612;&#49436;) . import seaborn as sns . - 아까 그린 Blue, Orange 그림을 그려보자. . sns.relplot(data=dfdata, x=&#39;toeic&#39;,y=&#39;gpa&#39;,hue=&#39;employed&#39;) #범례도 생긴다. hue에 그룹핑하고 싶은 변수 입력 . &lt;seaborn.axisgrid.FacetGrid at 0x7efc44e948b0&gt; . – 취업된 사람들이 각각 어떠한 회사에 갔는지 궁금하다. . sns.relplot(data=dfdata.query(&#39;employed==&quot;Y&quot;&#39;), x=&#39;toeic&#39;,y=&#39;gpa&#39;,hue=&#39;company&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7efc44d53820&gt; . - 연봉정보도 한눈에 알아보기 쉽게 그리고 싶다면? . sns.relplot(data=dfdata.query(&#39;employed==&quot;Y&quot;&#39;), x=&#39;toeic&#39;,y=&#39;gpa&#39;,hue=&#39;company&#39;,size=&#39;salary&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7efc439dbac0&gt; . . &#44061;&#52404;&#51648;&#54693;&#51201; &#51064;&#53552;&#54168;&#51060;&#49828; . - 위에서 까지 진행한 것은 함수에 값을 입력하면 함수가 알아서 실행되어 플랏을 그리는 방식임 -&gt; 데이터 전처리 계획 등이 필요함 - 객체지향적 인터페이스는 그림을 보며 하나씩 만들어가는 느낌 -&gt; 자유도가 높다! . p1=plt.figure() . &lt;Figure size 432x288 with 0 Axes&gt; . p1 . &lt;Figure size 432x288 with 0 Axes&gt; . p1.axes . [] . p1.add_axes([0,0,1,1]) #(0,0)위치에 가로세로 길이가 1인 축을 만들어라 . &lt;Axes:&gt; . p1 #축 1개 생성 . p1.add_axes([0,1,1,1]) . &lt;Axes:&gt; . p1.axes . [&lt;Axes:&gt;, &lt;Axes:&gt;] . p1 . p1.add_axes([0.5,0.5,1,1]) #(0.5,0.5)위치에 가로세로 길이가 1인 축을 만들어라 . &lt;Axes:&gt; . p1.axes . [&lt;Axes:&gt;, &lt;Axes:&gt;, &lt;Axes:&gt;] . p1 . p1.axes[0].plot(x,y) #가장 처음 만든 면에 plot . [&lt;matplotlib.lines.Line2D at 0x7efc43343340&gt;] . p1 . p1.axes[2].plot(x,y,&#39;o&#39;) #3번째 면에 plot . [&lt;matplotlib.lines.Line2D at 0x7efc433b4640&gt;] . p1 . p1.axes[2].plot(x,y2,&#39;:o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7efc43360880&gt;] . p1 .",
            "url": "https://kimha02.github.io/ham/python/2021/08/26/python-11.html",
            "relUrl": "/python/2021/08/26/python-11.html",
            "date": " • Aug 26, 2021"
        }
        
    
  
    
        ,"post31": {
            "title": "(공부) if문 & for문",
            "content": ". if&#47928; . - 예제1 . - a=11 처음에 선언 - a&lt;5, a&gt;10, 5&lt;=a=&lt;10 으로 나눠서 if문 작성 - **if, elif, else** 로 구분했다는 것을 기억해두자! . a=11 if a&lt;5: print(&#39;a=....1,2,3,4&#39;) elif a&gt;10: print(&#39;a=11,12,13,....&#39;) else: print(&#39;a=5,6,7,...,10&#39;) . a=11,12,13,.... . - 예제2 . - a,b=2,3이면 a=2, b=3으로 입력됨 - 크게 **if, else**로 나누고, **else 안에서 다시 if, else로 나눌 수 있다!** . a,b=5,2 if a==b: print(&#39;a=b&#39;) else: if a&lt;b: print(&#39;a&lt;b&#39;) else: print(&#39;a&gt;b&#39;) . a&gt;b . - 예제3 . - a==1이면 a=1을 출력 . a=1.0005 if a==1: print(&#39;a=1&#39;) . . for &#47928; . - 예제1 . - 리스트여도 잘 된다. . for i in [1,2,3,4]: print(i) . 1 2 3 4 . - 예제2 . - tuple이어도 잘 된다. . for i in (1,2,3,4): print(i) . 1 2 3 4 . - 예제3 . - string도 잘 된다. . for i in &#39;1234&#39;: print(i) . 1 2 3 4 . (?) 의문 . for i in ???: print(i) . 에서 물음표 자리에 올 수 있는 것이 무엇일까? . - 예제4 . a=5 for i in a: print(i) . TypeError Traceback (most recent call last) &lt;ipython-input-25-0141710f97f4&gt; in &lt;module&gt; 1 a=5 -&gt; 2 for i in a: 3 print(i) TypeError: &#39;int&#39; object is not iterable . 5라고 출력될 줄 알았는데 아니었다. 무슨 차이인가? A : 길이가 정의되는 1차원 자료형 이상이어야 for문은 정의된다. | . 아래를 살펴보자. | . - 예제5 . L=[[1,2,3],[3,4,5]] . for i in L: print(i) . [1, 2, 3] [3, 4, 5] . import pandas as pd df=pd.DataFrame(L) . for i in df: print(i) . 0 1 2 . import numpy as np ndr=np.array(L) . for i in ndr: print(i) . [1 2 3] [3 4 5] . 1차원 자료형을 넣었지만 결과를 예측할 수 없었다. 결과를 어떻게 예상할 수 있을까? | . &#9733; for&#47928;&#51032; &#46041;&#51089;&#50896;&#47532; . 사실 ??? 자리에 올 수 있는 것은 dir()하여 __iter__()라는 메서드가 있는 object이다. | 이러한 오브젝트를 iterable한 오브젝트라고 한다. | . a=1 . dir(a) . [&#39;__abs__&#39;, &#39;__add__&#39;, &#39;__and__&#39;, &#39;__bool__&#39;, &#39;__ceil__&#39;, &#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__divmod__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__float__&#39;, &#39;__floor__&#39;, &#39;__floordiv__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__getnewargs__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__index__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__int__&#39;, &#39;__invert__&#39;, &#39;__le__&#39;, &#39;__lshift__&#39;, &#39;__lt__&#39;, &#39;__mod__&#39;, &#39;__mul__&#39;, &#39;__ne__&#39;, &#39;__neg__&#39;, &#39;__new__&#39;, &#39;__or__&#39;, &#39;__pos__&#39;, &#39;__pow__&#39;, &#39;__radd__&#39;, &#39;__rand__&#39;, &#39;__rdivmod__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__rfloordiv__&#39;, &#39;__rlshift__&#39;, &#39;__rmod__&#39;, &#39;__rmul__&#39;, &#39;__ror__&#39;, &#39;__round__&#39;, &#39;__rpow__&#39;, &#39;__rrshift__&#39;, &#39;__rshift__&#39;, &#39;__rsub__&#39;, &#39;__rtruediv__&#39;, &#39;__rxor__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__sub__&#39;, &#39;__subclasshook__&#39;, &#39;__truediv__&#39;, &#39;__trunc__&#39;, &#39;__xor__&#39;, &#39;as_integer_ratio&#39;, &#39;bit_length&#39;, &#39;conjugate&#39;, &#39;denominator&#39;, &#39;from_bytes&#39;, &#39;imag&#39;, &#39;numerator&#39;, &#39;real&#39;, &#39;to_bytes&#39;] . 예상대로 int클래스의 인스턴스는 __iter__()가 없다. . - 위에서 정의한 L, df, ndr 는 모두 __iter__() 함수가 있다. 따라서 iterable한 오브젝트이다. . -&gt; iterable한 오브젝트는 iterator로 만들 수 있는 특징이 있다. . iterable한 오브젝트를 어떻게 iterator로 만드는가? | . dfiter1=df.__iter__() . dfiter1? . Type: generator String form: &lt;generator object RangeIndex.__iter__ at 0x7fa6071b6cf0&gt; Docstring: &lt;no docstring&gt; . - dfiter1은 generator라는 클래스에서 만들어진 인스턴스 오브젝트이다. . dir(dfiter1) . [&#39;__class__&#39;, &#39;__del__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__name__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__next__&#39;, &#39;__qualname__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;close&#39;, &#39;gi_code&#39;, &#39;gi_frame&#39;, &#39;gi_running&#39;, &#39;gi_yieldfrom&#39;, &#39;send&#39;, &#39;throw&#39;] . dfiter1.__next__() #next의 역할은 순서대로 계속 작업하는.. . StopIteration Traceback (most recent call last) /tmp/ipykernel_23225/135013321.py in &lt;module&gt; -&gt; 1 dfiter1.__next__() #next의 역할은 순서대로 계속 작업하는.. StopIteration: . dfiter2=iter(df) . ?dfiter2 . Type: generator String form: &lt;generator object RangeIndex.__iter__ at 0x7fa6404a54a0&gt; Docstring: &lt;no docstring&gt; . dfiter2.__next__() . StopIteration Traceback (most recent call last) /tmp/ipykernel_23225/2401884540.py in &lt;module&gt; -&gt; 1 dfiter2.__next__() StopIteration: . &#8211; for &#47928;&#51032; &#51089;&#46041;&#50896;&#47532; . for i in L: print(i) . (1) iter함수를 사용해서 L을 iterator로 만든다. . (2) iterator에서 .__next__()함수를 호출하고 결과를 i에 저장한 뒤에 for문 블 안에 있는 내용(들여쓰기 된 내용)을 실행한다. . (3) StopIteration 에러가 발생하면 for 문을 멈춘다. . Liter=iter(L) . ?Liter . Type: list_iterator String form: &lt;list_iterator object at 0x7fa6071bb880&gt; Docstring: &lt;no docstring&gt; . Liter.__next__() . StopIteration Traceback (most recent call last) /tmp/ipykernel_23225/3305166288.py in &lt;module&gt; -&gt; 1 Liter.__next__() StopIteration: . ndriter=iter(ndr) . print(ndriter.__next__()) . StopIteration Traceback (most recent call last) /tmp/ipykernel_23225/3774912080.py in &lt;module&gt; -&gt; 1 print(ndriter.__next__()) StopIteration: . range() . - for문의 정석은 아래와 같이 range() 를 사용하는 것이다. . for i in range(5): print(i) . 0 1 2 3 4 . - range(5)의 정체는 그냥 iterable object이다. . a=range(5) . - 그래서 언제든지 iterator로 바꿀 수 있다. . aiter=iter(a) . aiter . &lt;range_iterator at 0x7fa6071bbf90&gt; . aiter.__next__() . StopIteration Traceback (most recent call last) /tmp/ipykernel_23225/3185881957.py in &lt;module&gt; -&gt; 1 aiter.__next__() StopIteration: . &#51060;&#53552;&#47112;&#51060;&#53552;&#51032; &#44060;&#45392;&#51008; &#46356;&#48260;&#44613;&#50640; &#51025;&#50857;&#51060; &#44032;&#45733;&#54616;&#45796;. . for i in zip([1,2,3],&#39;abc&#39;): print(i) . (1, &#39;a&#39;) (2, &#39;b&#39;) (3, &#39;c&#39;) . zip([1,2,3],&#39;abc&#39;) . &lt;zip at 0x7fa6404bb580&gt; . 어차피 for i in ????: ????의 자리는 iterable object 자리이다. . z=zip([1,2,3],&#39;abc&#39;) . dir(z) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__next__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;] . - __next__()함수가 있음 $ to$ z자체가 iterable object 이면서 iterator였다. . z.__next__() . StopIteration Traceback (most recent call last) /tmp/ipykernel_23225/4267025455.py in &lt;module&gt; -&gt; 1 z.__next__() StopIteration: . - ???? 자리에 iterator 자체가와도 무방할것 같다. . - 확인 $ to$ 가능하다! . L=iter([1,2,3,4]) for i in L: print(i) . 1 2 3 4 .",
            "url": "https://kimha02.github.io/ham/python/2021/08/25/python-10.html",
            "relUrl": "/python/2021/08/25/python-10.html",
            "date": " • Aug 25, 2021"
        }
        
    
  
    
        ,"post32": {
            "title": "(공부) 문자열",
            "content": ". &#47928;&#51088;&#50676; &#50741;&#49496; . - 예제1: 한줄 띄우기 ( n) . &#39;오늘의점심 n카레라이스&#39; # n을 그냥 넣으면 안된다. . &#39;오늘의점심 n카레라이스&#39; . print(&#39;오늘의점심 n카레라이스&#39;) #print에 넣어주면 한 줄 넘어간다. . 오늘의점심 카레라이스 . – 예제2: 탭 ( t) . print(&#39;오늘의점심 t카레라이스&#39;) . 오늘의점심 카레라이스 . - 예제3: 이스케이프( 옵션을 나타내주고 싶을 때) . print(&#39;오늘의점심 n카레라이스&#39;) #역슬래쉬가 2개인데 출력은 한 개만 된다-&gt;역슬래쉬를 하나 더 넣어주면 옵션 확인 가능하다! . 오늘의점심 n카레라이스 . print(&#39; &#39;) . . print(&#39;오늘의점심&#39;카레라이스&#39;&#39;) #따옴표 안에 있는 내용을 출력하고 싶은데 오류가 난다, . File &#34;/tmp/ipykernel_662842/33763534.py&#34;, line 1 print(&#39;오늘의점심&#39;카레라이스&#39;&#39;) #따옴표 안에 있는 내용을 출력하고 싶은데 오류가 난다, ^ SyntaxError: invalid syntax . print(&#39;오늘의점심 &#39;카레라이스 &#39;&#39;) #해결1) 이스케이프 활용 . 오늘의점심&#39;카레라이스&#39; . print(&quot;오늘의점심&#39;카레라이스&#39;&quot;) #해결2) 큰 따옴표 안에 작은 따옴표 . 오늘의점심&#39;카레라이스&#39; . . &#47928;&#51088;&#50676; &#47700;&#49548;&#46300; . 1) .replace() . - 특정 문자열 대체 . - 예제1 . S = &#39;spammy&#39; S.replace(&#39;mm&#39;,&#39;xx&#39;) . &#39;spaxxy&#39; . – 예제2 . S = &#39;xxxxSPAMxxxxSPAMxxxx&#39; . S.replace(&#39;SPAM&#39;,&#39;EGGS&#39;) . &#39;xxxxEGGSxxxxEGGSxxxx&#39; . S.replace(&#39;SPAM&#39;,&#39;EGGS&#39;,1) #1개만 바꾼다. . &#39;xxxxEGGSxxxxSPAMxxxx&#39; . ?S.replace . Signature: S.replace(old, new, count=-1, /) Docstring: Return a copy with all occurrences of substring old replaced by new. count Maximum number of occurrences to replace. -1 (the default value) means replace all occurrences. If the optional argument count is given, only the first count occurrences are replaced. Type: builtin_function_or_method . 2) .find() . – 예제1 . S = &#39;xxxxSPAMxxxxSPAMxxxx&#39; . where=S.find(&#39;SPAM&#39;) #SPAM이 어디있는지 찾아줘! -&gt; 결과 : 4번째부터 시작되네 -&gt; 4를 where에저장 . S[where] #input : 4 -&gt; output : S(S의 4번째 문자가 &#39;S&#39;라서) . &#39;S&#39; . S[:where]+&#39;EGGS&#39;+S[(where+4):] #0~4까지 문자 출력 + EGGS 삽입 + 4+4번 문자부터 마지막까지 출력 . &#39;xxxxEGGSxxxxSPAMxxxx&#39; . 3) .join() . – 예제1 . &#39;-&#39;.join([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]) # - 로 언급한 문자들을 결합시킨다 . &#39;a-b-c&#39; . s=&#39;-&#39; s.join([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]) . &#39;a-b-c&#39; . – 예제2 . S=&#39;spammy&#39; . S . &#39;spammy&#39; . S[3:5] . &#39;mm&#39; . S[3:5]=&#39;xx&#39; . TypeError Traceback (most recent call last) &lt;ipython-input-34-84bfa6854842&gt; in &lt;module&gt; -&gt; 1 S[3:5]=&#39;xx&#39; TypeError: &#39;str&#39; object does not support item assignment . mm을 xx로 바꾸고 싶은데 문자열은 불변리스트라서 바꿀 수 없다. | . ★ 전략: 문자열을 잠시 가변객체인 리스트로 바꾼 뒤 리스트에서 자유롭게 편집하고 그 다음에 다시 문자열로 만들자. | . L=list(S) . L . [&#39;s&#39;, &#39;p&#39;, &#39;a&#39;, &#39;m&#39;, &#39;m&#39;, &#39;y&#39;] . L[3:5] . [&#39;m&#39;, &#39;m&#39;] . L[3:5]=[&#39;x&#39;,&#39;x&#39;] . L . [&#39;s&#39;, &#39;p&#39;, &#39;a&#39;, &#39;x&#39;, &#39;x&#39;, &#39;y&#39;] . S=&#39;&#39;.join(L) . S . &#39;spaxxy&#39; . 4) .split(&#39;,&#39;) . – 예제1 . s=&#39;bob,hacker,40&#39; . s.split(&#39;,&#39;) # , 로 분리된 s 텍스트 나누기 . [&#39;bob&#39;, &#39;hacker&#39;, &#39;40&#39;] . – 예제2 . s= &#39;aaa bbb ccc&#39; . s.split(&#39; &#39;) # &#39;공백&#39; 으로 분리된 s 텍스트 나누기 . [&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;] . s.split() # &#39;공백&#39; 으로 분리된 s 텍스트 나누기 . [&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;] . s.split? . Signature: s.split(sep=None, maxsplit=-1) Docstring: Return a list of the words in the string, using sep as the delimiter string. sep The delimiter according which to split the string. None (the default value) means split according to any whitespace, and discard empty strings from the result. maxsplit Maximum number of splits to do. -1 (the default value) means no limit. Type: builtin_function_or_method . . &#47928;&#51088;&#50676; &#54252;&#47588;&#54021; . 1) &#54364;&#54788;&#49885; (&#47928;&#51088;&#50676;&#50640;&#49436; %&#50672;&#49328;&#51088; &#49324;&#50857;) . - 예제1 . &#39;age: %s&#39; % 39 # s : string의 약자로 문자열도 가능함, (굉장히 특별한 경우가 아니면) 얘만 알아도 된다! . &#39;age: 39&#39; . &#39;age: %d&#39; % 39.1359 #정수형 . &#39;age: 39&#39; . &#39;age: %f&#39; % 39.1359 #float형 . &#39;age: 39.135900&#39; . - 예제2 . &#39;addr: %s to %s&#39; % (&#39;seoul&#39;,&#39;jeonju&#39;) . &#39;addr: seoul to jeonju&#39; . 잘못된 사용예시1 . &#39;addr: %s to %s&#39; % [&#39;seoul&#39;,&#39;jeonju&#39;] . TypeError Traceback (most recent call last) /tmp/ipykernel_662842/655998447.py in &lt;module&gt; -&gt; 1 &#39;addr: %s to %s&#39; % [&#39;seoul&#39;,&#39;jeonju&#39;] TypeError: not enough arguments for format string . 잘못된 사용예시2 . &#39;addr: %s to %s&#39; % &#39;seoul&#39;,&#39;jeonju&#39; . TypeError Traceback (most recent call last) &lt;ipython-input-60-0c8ecede52e2&gt; in &lt;module&gt; -&gt; 1 &#39;addr: %s to %s&#39; % &#39;seoul&#39;,&#39;jeonju&#39; TypeError: not enough arguments for format string . &#39;addr: %s to %s&#39; . str . % 연산자는 왼쪽에 문자열 오브젝트, 그리고 오른쪽에는 명시적인 튜플이 있어야 연산이 진행된다. | . 연산자라는 포인트를 이해하면 아래와 같은 문법도 가능함을 알 수 있다. | . s = &#39;addr: %s to %s&#39; s % (&#39;seoul&#39;,&#39;jeonju&#39;) . &#39;addr: seoul to jeonju&#39; . 2) &#46357;&#49492;&#45320;&#47532; &#44592;&#48152; &#54252;&#47588;&#54021; . - 사실 명시적인 튜플이 오른쪽에 오지 않아도 연산이 가능하다..! - 반복작업에 적합 . - 예제1 . &#39;여기 %(food1)s 1개, %(food2)s 1개 주문이요&#39; % {&#39;food1&#39;:&#39;짜장면&#39;,&#39;food2&#39;:&#39;짬뽕&#39;} . &#39;여기 짜장면 1개, 짬뽕 1개 주문이요&#39; . &#39;여기 %(food1)s 1개, %(food2)s 1개 주문이요, 아.. 아니다. %(food1)s은 취소하고 그냥 %(food2)s 두개 주세요&#39; % {&#39;food1&#39;:&#39;짜장면&#39;,&#39;food2&#39;:&#39;짬뽕&#39;} . &#39;여기 짜장면 1개, 짬뽕 1개 주문이요, 아.. 아니다. 짜장면은 취소하고 그냥 짬뽕 두개 주세요&#39; . - 예제2 . mail=&#39;%(studentname)s 학생 안녕하세요 n저는 통계학과 최규빈 교수 입니다. n전공설계과목 지침에 따라 %(studentname)s학생과 2회 상담을 실시해야 합니다. n저는 %(day)s에 시간이 괜찮은데 %(studentname)s 학생도 그날 시간이 괜찮을까요? n&#39; . print(mail % {&#39;studentname&#39;:&#39;박혜원&#39;, &#39;day&#39;:&#39;5월31일&#39;}) . 박혜원 학생 안녕하세요 저는 통계학과 최규빈 교수 입니다. 전공설계과목 지침에 따라 박혜원학생과 2회 상담을 실시해야 합니다. 저는 5월31일에 시간이 괜찮은데 박혜원 학생도 그날 시간이 괜찮을까요? . print(mail % {&#39;studentname&#39;:&#39;강호동&#39;, &#39;day&#39;:&#39;6월3일&#39;}) . 강호동 학생 안녕하세요 저는 통계학과 최규빈 교수 입니다. 전공설계과목 지침에 따라 강호동학생과 2회 상담을 실시해야 합니다. 저는 6월3일에 시간이 괜찮은데 강호동 학생도 그날 시간이 괜찮을까요? . - 예제3 . import pandas as pd df=pd.DataFrame({&#39;studentname&#39;:[&#39;박혜원&#39;,&#39;강호동&#39;],&#39;day&#39;:[&#39;5월31일&#39;,&#39;6월3일&#39;]}) df . studentname day . 0 박혜원 | 5월31일 | . 1 강호동 | 6월3일 | . for i in [0,1]: print(mail % dict(df.iloc[i])) . 박혜원 학생 안녕하세요 저는 통계학과 최규빈 교수 입니다. 전공설계과목 지침에 따라 박혜원학생과 2회 상담을 실시해야 합니다. 저는 5월31일에 시간이 괜찮은데 박혜원 학생도 그날 시간이 괜찮을까요? 강호동 학생 안녕하세요 저는 통계학과 최규빈 교수 입니다. 전공설계과목 지침에 따라 강호동학생과 2회 상담을 실시해야 합니다. 저는 6월3일에 시간이 괜찮은데 강호동 학생도 그날 시간이 괜찮을까요? . 3) &#47700;&#49436;&#46300; . - 예제1 . mail=&#39;{studentname} 학생 안녕하세요 n저는 통계학과 최규빈 교수 입니다. n전공설계과목 지침에 따라 {studentname}학생과 2회 상담을 실시해야 합니다. n저는 {day}에 시간이 괜찮은데 {studentname} 학생도 그날 시간이 괜찮을까요? n&#39; . mail.format(studentname=&#39;박혜원&#39;,day=&#39;6월2일&#39;) #.format으로 정의 (% 연산자 사용안함) . &#39;박혜원 학생 안녕하세요 n저는 통계학과 최규빈 교수 입니다. n전공설계과목 지침에 따라 박혜원학생과 2회 상담을 실시해야 합니다. n저는 6월2일에 시간이 괜찮은데 박혜원 학생도 그날 시간이 괜찮을까요? n&#39; . mm=mail.format(studentname=&#39;박혜원&#39;,day=&#39;6월2일&#39;) . print(mm) . 박혜원 학생 안녕하세요 저는 통계학과 최규빈 교수 입니다. 전공설계과목 지침에 따라 박혜원학생과 2회 상담을 실시해야 합니다. 저는 6월2일에 시간이 괜찮은데 박혜원 학생도 그날 시간이 괜찮을까요? . – 예제2 . &#39;name:{},age:{},city:{}&#39;.format(&#39;Sponge bob&#39;,&#39;2&#39;,&#39;male&#39;) . &#39;name:Sponge bob,age:2,city:male&#39; .",
            "url": "https://kimha02.github.io/ham/python/2021/08/24/python-9.html",
            "relUrl": "/python/2021/08/24/python-9.html",
            "date": " • Aug 24, 2021"
        }
        
    
  
    
        ,"post33": {
            "title": "(공부) 네임스페이스 & 연산자오버로딩 & 도움말 추가하기",
            "content": ". &#50696;&#51228;1 . - 아래의 코드를 관찰하라. . class Testclass1: x=0 . Testclass1.x . 0 . a=Testclass1() . a.x . 0 . – Testclass1.x를 수정하면 a.x가 강제로 수정된다. . Testclass1.x=100 . a.x . 100 . - a.x를 수정한다고 하여 Testclass1.x가 강제로 수정되는 것은 아님 . a.x=200 . Testclass1.x . 100 . a.x . 200 . - 이건 왜이러지? . Testclass1.x=300 . a.x . 200 . - 아래의 상황과 비슷하다. . x=39 def nextyear(): y=x+1 print(x,y) nextyear() . 39 40 . x=39 def nextyear(): y=x+1 print(x,y) x=0 nextyear() . UnboundLocalError Traceback (most recent call last) &lt;ipython-input-13-9c5d2bc270db&gt; in &lt;module&gt; 5 print(x,y) 6 x=0 -&gt; 7 nextyear() &lt;ipython-input-13-9c5d2bc270db&gt; in nextyear() 2 x=39 3 def nextyear(): -&gt; 4 y=x+1 5 print(x,y) 6 x=0 UnboundLocalError: local variable &#39;x&#39; referenced before assignment . – [code1]은 잘 실행되는 코드다. . - [code2]는 실행되지 않는 코드다. . - [code2]와 [code1]의 차이점은 x=0이라는 코드가 추가로 포함되었는지 유무다. . – (헛소리) x=0 이 잘못된 코드다!! 이걸 실행하는 과정에서 문제가 생겼다!! . - (올바른소리) code1에서는 x는 global variable, code2에서는 x가 local variable 이라서 생기는 문제점이다. . x=39 def nextyear(): x=0 y=x+1 print(x,y) nextyear() . 0 1 . x . 39 . – 다시 우리의 예제로 돌아오자. . ### 시점1 class Testclass1: x=0 ### 시점2 a=Testclass1() ### 시점3 Testclass1.x=100 ### 시점4 a.x=200 ### 시점5 Testclass1.x=300 . 시점1 시점2 시점3 시점4 시점5 . Testclass1.x | 0 | 0 | 100 | 100 | 300 | . a.x | 값없음 | 0 | 100 | 200 | 200 | . a.x의 속성 | - | class | class | instance | instance | . – a.x가 클래스로부터 물려받은 속성인지 (그래서 클래스와 연결되어있는지) 아니면 instance가 독자적으로 가지고 있는 속성인지 어떻게 알 수 있을까? . class Testclass1: x=0 print(&#39;시점1&#39;,Testclass1.x) ### 시점2 a=Testclass1() print(&#39;시점2&#39;,Testclass1.x,a.x,a.__dict__) ### 시점3 Testclass1.x=100 print(&#39;시점3&#39;,Testclass1.x,a.x,a.__dict__) ### 시점4 a.x=200 print(&#39;시점4&#39;,Testclass1.x,a.x,a.__dict__) ### 시점5 Testclass1.x=300 print(&#39;시점5&#39;,Testclass1.x,a.x,a.__dict__) . 시점1 0 시점2 0 0 {} 시점3 100 100 {} 시점4 100 200 {&#39;x&#39;: 200} 시점5 300 200 {&#39;x&#39;: 200} . . &#50696;&#51228;2 . x=11 ## 전역변수 ... A def f(): x=22 ## 함수 f안에 설정된 지역변수 print(x) ## 전역에 x=11 있지만 함수안에 x=22가 있으므로 x=22를 사용. --&gt; 22출력됨 def g(): print(x) ## 함수 g안에 x를 찾아봤는데 없음 --&gt; 전역에서 x를 찾음 --&gt; x=11 --&gt; 11출력함. class Testclass2: x=33 ## 클래스 변수 ... B def m1(self): x=44 ## 메소드 변수 ... C def m2(self): self.x=44 ## 인스턴스 변수 ... D . - 결과를 관찰하고 해석해보자. . print(x) . 11 . . Note: 전역변수 출력 . f() . 22 . . Note: f에서 설정된 지역변수 22가 출력됨 . x . 11 . . Note: f내의 지역변수를 사용하여도 전역변수는 변하지 않음. (함수내부에서 선언된 x=22는 함수외부에 영향을 주지못함) . g() . 11 . . Note: g에서 설정된 지역변수가 따로 없으므로 전역변수 출력 . x,Testclass2.x . (11, 33) . . Note: 전역변수 x와 클래스오브젝트에 설정된 변수 x . a=Testclass2() (x,Testclass2.x,a.x),a.__dict__ . ((11, 33, 33), {}) . . Note: 전역변수, 클래스 오브젝트내의 변수, 인스턴스내의 변수. a.__dict__의 결과로 보아 인스턴스내의 변수는 클래스 오브젝트내의 변수를 빌려쓰고 있다. . Testclass2.x=200 (x,Testclass2.x,a.x),a.__dict__ . ((11, 200, 200), {}) . . Note: 클래스오브젝트에서 변수를 고치면 인스턴스에 영향을 미침 . a.m1() (x,Testclass2.x,a.x),a.__dict__ . ((11, 200, 200), {}) . . Note: 메소드 m1내에서 선언된 x=44라는 선언은 아무것도 변화시킬수 없음. . a.m2() (x,Testclass2.x,a.x),a.__dict__ . ((11, 200, 44), {&#39;x&#39;: 44}) . . Note: 메소드 m2에 있는 self.x는 결국 a.x라는 의미이고, 이 선언은 클래스오브젝트 내의 변수와 독립적으로 인스턴스오브젝트 내에서 통용되는 변수를 선언하는 것임. 이 선언의 결과는 a.__dict__의 출력결과에서도 확인가능. . Testclass2.x=300 (x,Testclass2.x,a.x),a.__dict__ . ((11, 300, 44), {&#39;x&#39;: 44}) . . Note: 이제는 a.x와 Testclass2.x 는 분리된 상태이므로, Testclass2.x의 값을 바꾸어도 a.x에는 값의 변화가 없음. . - 전역변수 &gt; 클래스변수 &gt; 인스턴스변수 &gt; 메소드변수 내용을 모르고 사용한다면 예상하지 못한 오류가 발생할 수 있으므로 조심해서 사용하자. . . &#50672;&#49328;&#51088; &#50724;&#48260;&#47196;&#46377; . - 아래의 코드를 관찰하자. . 1+1 . 2 . - 생각해보니까 1은 int class 에서 생성된 인스턴스이다. . - 코드를 관찰하니 instance와 instance를 +라는 연산이 연결하는 형태임. . class Student: def __init__(self,age=20.0,semester=1): self.age=age self.semester=semester def __add__(self,val): # val==0: 휴학 # val==1: 등록 if val==0: self.age=self.age +0.5 elif val==1: self.age=self.age+0.5 self.semester=self.semester+1 return self ### return을 통해 guebin+1도 Student Type이 된다 def __repr__(self): return &#39;나이: %s n학기: %s&#39; % (self.age,self.semester) . guebin=Student() . guebin.age . 20.0 . guebin.semester . 1 . guebin . 나이: 20.0 학기: 1 . type(guebin) . __main__.Student . guebin+1 . 나이: 20.5 학기: 2 . type(guebin+1) . __main__.Student . guebin+0 . 나이: 21.5 학기: 3 . guebin+0+0+0+0+1+0+1 . 나이: 25.0 학기: 5 . - 연산자 오버로드 핵심아이디어 . 클래스가 일반 파이썬 연산을 재정의하는 것 | 여기에서 연산은 단순히 더하기 빼기를 의미하는게 아니라, print(), +, [0] 와 같은 파이썬 내장문법을 모두 포괄하는 개념이라 이해하는 것이 옳다. | . guebin[0] . TypeError Traceback (most recent call last) &lt;ipython-input-44-961de20e3474&gt; in &lt;module&gt; -&gt; 1 guebin[0] TypeError: &#39;Student&#39; object is not subscriptable . class Student2(Student): def __getitem__(self,index): return [self.age,self.semester][index] . hynn=Student2() . hynn+1+1+0+0 . 나이: 22.0 학기: 3 . hynn[0] . 22.0 . hynn[1] . 3 . hynn[:] . [22.0, 3] . - 연산자 오버로딩을 이해하면 파이썬 전반에 대한 이해폭이 넓어진다. . import pandas as pd . df=pd.DataFrame({&#39;age&#39;:[20,21.5],&#39;semester&#39;:[1,2]}) . df.iloc[:,0] . 0 20.0 1 21.5 Name: age, dtype: float64 . . &#46020;&#50880;&#47568; &#51089;&#49457;&#48169;&#48277; . - 넘파이의 경우 아래와 같이 도움말이 잘 작성되어 있다. . import numpy as np a=np.array([1,2,3]) a? . Type: ndarray String form: [1 2 3] Length: 3 File: ~/anaconda3/envs/py38r40/lib/python3.8/site-packages/numpy/__init__.py Docstring: &lt;no docstring&gt; Class docstring: ndarray(shape, dtype=float, buffer=None, offset=0, strides=None, order=None) An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.) Arrays should be constructed using `array`, `zeros` or `empty` (refer to the See Also section below). The parameters given here refer to a low-level method (`ndarray(...)`) for instantiating an array. For more information, refer to the `numpy` module and examine the methods and attributes of an array. Parameters - (for the __new__ method; see Notes below) shape : tuple of ints Shape of created array. dtype : data-type, optional Any object that can be interpreted as a numpy data type. buffer : object exposing buffer interface, optional Used to fill the array with data. offset : int, optional Offset of array data in buffer. strides : tuple of ints, optional Strides of data in memory. order : {&#39;C&#39;, &#39;F&#39;}, optional Row-major (C-style) or column-major (Fortran-style) order. Attributes - T : ndarray Transpose of the array. data : buffer The array&#39;s elements, in memory. dtype : dtype object Describes the format of the elements in the array. flags : dict Dictionary containing information related to memory use, e.g., &#39;C_CONTIGUOUS&#39;, &#39;OWNDATA&#39;, &#39;WRITEABLE&#39;, etc. flat : numpy.flatiter object Flattened version of the array as an iterator. The iterator allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for assignment examples; TODO). imag : ndarray Imaginary part of the array. real : ndarray Real part of the array. size : int Number of elements in the array. itemsize : int The memory use of each array element in bytes. nbytes : int The total number of bytes required to store the array data, i.e., ``itemsize * size``. ndim : int The array&#39;s number of dimensions. shape : tuple of ints Shape of the array. strides : tuple of ints The step-size required to move from one element to the next in memory. For example, a contiguous ``(3, 4)`` array of type ``int16`` in C-order has strides ``(8, 2)``. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (``2 * 4``). ctypes : ctypes object Class containing properties of the array needed for interaction with ctypes. base : ndarray If the array is a view into another array, that array is its `base` (unless that array is also a view). The `base` array is where the array data is actually stored. See Also -- array : Construct an array. zeros : Create an array, each element of which is zero. empty : Create an array, but leave its allocated memory unchanged (i.e., it contains &#34;garbage&#34;). dtype : Create a data-type. Notes -- There are two modes of creating an array using ``__new__``: 1. If `buffer` is None, then only `shape`, `dtype`, and `order` are used. 2. If `buffer` is an object exposing the buffer interface, then all keywords are interpreted. No ``__init__`` method is needed because the array is fully initialized after the ``__new__`` method. Examples -- These examples illustrate the low-level `ndarray` constructor. Refer to the `See Also` section above for easier ways of constructing an ndarray. First mode, `buffer` is None: &gt;&gt;&gt; np.ndarray(shape=(2,2), dtype=float, order=&#39;F&#39;) array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]]) Second mode: &gt;&gt;&gt; np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3]) . - 하지만 우리는? . hynn? . Type: Student2 String form: 나이: 22.0 학기: 3 Docstring: &lt;no docstring&gt; . - 우리도 도움말을 작성하고 싶다. . class Student2(Student): &#39;&#39;&#39; Student2는 Student의 개선 # Student 클래스의 기능 1. 출력기능 (__repr__) 2. 연산기능 (__add__): 학기와 나이를 카운트 Examples -- &gt;&gt;&gt; hynn=Student2() &gt;&gt;&gt; hynn+1 나이: 20.5 학기: 2 # Student2에서 추가된 기능 1. 인덱싱 &#39;&#39;&#39; def __getitem__(self,index): return [self.age,self.semester][index] . hynn=Student2() . hynn? . Type: Student2 String form: 나이: 20.0 학기: 1 Docstring: Student2는 Student의 개선 # Student 클래스의 기능 1. 출력기능 (__repr__) 2. 연산기능 (__add__): 학기와 나이를 카운트 Examples -- &gt;&gt;&gt; hynn=Student2() &gt;&gt;&gt; hynn+1 나이: 20.5 학기: 2 # Student2에서 추가된 기능 1. 인덱싱 . hynn=Student2(21,1) . hynn . 나이: 21 학기: 1 . hynn? . Type: Student2 String form: 나이: 21 학기: 1 Docstring: Student2는 Student의 개선 # Student 클래스의 기능 1. 출력기능 (__repr__) 2. 연산기능 (__add__): 학기와 나이를 카운트 Examples -- &gt;&gt;&gt; hynn=Student2() &gt;&gt;&gt; hynn+1 나이: 20.5 학기: 2 # Student2에서 추가된 기능 1. 인덱싱 . . self&#50640; &#45824;&#54620; &#51652;&#49892; . – 사실 이름이 self가 아니어도 된다. . class MooYaHo: def __init__(a): a.text=&#39;mooyaho&#39; . moo1=MooYaHo() . moo1.text . – 일반적으로 사람들이 self를 많이 쓴다. a는 간단하게 정의할 때 많이 쓰이기 때문에 향후에 헛갈릴 수도 있다. .",
            "url": "https://kimha02.github.io/ham/python/2021/07/23/python-8.html",
            "relUrl": "/python/2021/07/23/python-8.html",
            "date": " • Jul 23, 2021"
        }
        
    
  
    
        ,"post34": {
            "title": "(공부) Class(클래스)_심화",
            "content": "&#53364;&#47000;&#49828;, &#51064;&#49828;&#53556;&#49828;, &#50724;&#48652;&#51229;&#53944; . - 오브젝트 . 클래스 오브젝트 | 인스턴스 오브젝트 | . - 클래스 (=클래스 오브젝트) . - 인스턴스 (=인스턴스 오브젝트) . &#53364;&#47000;&#49828; &#49549;&#49457; vs &#51064;&#49828;&#53556;&#49828; &#49549;&#49457; . 노트(5)에서 아래와 같은 노트가 있었다. | . 규칙2:클래스 내에서 정의한 변수 (예를들면 title, img, don)를 사용하려면 - self.title, self.img, self.don . - `MooYaHo.title`, `MooYaHo.img`, `MooYaHo.don` . $ to$ self.는 인스턴스 속성, MooYaHo.는 클래스 속성을 의미한다. . [&#50696;&#51228;1] . class Testclass1: x=0 y=0 def my_print(self): self.x += 1 Testclass1.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . f=Testclass1 . a=Testclass1() . b=f() ### f라는 클래스 오브젝트에서 b라는 인스턴트 오브젝트 생성 . a.my_print() . b.my_print() . b.my_print() . a.my_print() . a.my_print() . - 신기한 점: 각 인스턴스에서 instance.my_print()를 실행한 횟수를 서로 공유하는 듯 하다. . &#48516;&#49437; . - 코드를 시점별로 분석해보자. . - 분석을 위해서 커널을 재시작한다. . [시점1]: Testclass1를 선언하는 시점 . class Testclass1: x=0 y=0 def my_print(self): self.x += 1 Testclass1.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . dir(Testclass1) ###Testclass 탐색 . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;, &#39;x&#39;, &#39;y&#39;] . dir(a) . NameError Traceback (most recent call last) &lt;ipython-input-3-3af1c875b71a&gt; in &lt;module&gt; -&gt; 1 dir(a) NameError: name &#39;a&#39; is not defined . dir(b) . NameError Traceback (most recent call last) &lt;ipython-input-4-35660f044d44&gt; in &lt;module&gt; -&gt; 1 dir(b) NameError: name &#39;b&#39; is not defined . – 이 시점에는 Testclass1만이 존재한다. Testclass1를 바로 클래스 오브젝트 라고 부름. . Testclass1.x . 0 . Testclass1.y . 0 . – 현재시점에서는 클래스 오브젝트의 수 1개, 인스턴스 오브젝트의 수 0개, 따라서 총 오브젝트 수는 1개임. . [시점2] 클래스에 별칭을 지정하는 시점 . f=Testclass1 ###f라는 별칭을 지정 . f.x . 0 . f.y . 0 . Testclass1.x . 0 . Testclass1.y . 0 . – 이 시점에서 클래스 오브젝트는 2개가 있는 것 처럼 보인다. . - 그렇다면 이 2개의 클래스 오브젝트는 컴퓨터의 어딘가에 저장이 되어 있을 것이다. . - 구체적으로는 메모리에 저장되어 있을 것. . - 2개의 클래스오브젝트는 서로 다른 메모리 공간에 저장되어 있을 것이다. . - 진짜인가? 확인해보자. id()는 오브젝트(클래스 오브젝트, 인스턴스 오브젝트)가 저장된 메모리 주소를 확인하는 명령어이다. . id(f) . 93883369152752 . – f라는 오브젝트는 93883369152752 메모리에 저장되어 있다. . id(Testclass1) . 93883369152752 . - Testclass1의 오브젝트 역시 93883369152752 메모리에 저장되어 있다. . - 추론: 사실 93883369152752 라는 메모리공간에 저장된 어떠한 것은 동일한데, 그것을 어떤사람은 Testclass1 이라고 부르고 어떤사람은 f라고 부른다. . - 이는 마치 별명이랑 비슷하다. 부르는 이름이 2개라고 해서 나라는 오브젝트가 2개가 있는것은 아니다. . - 결국 이 시점에서 클래스 오브젝트의 수는 여전히 1개라고 볼 수 있다. (인스턴스 오브젝트의 수는 0개) . [시점3]: 클래스 오브젝트로부터 인스턴스 오브젝트를 만드는 시점 . a=Testclass1() b=f() . id(Testclass1),id(f),id(a),id(b) . (93883369152752, 93883369152752, 140489211063024, 140489211062064) . – 이 순간에는 클래스 오브젝트 1개, 인스턴스 오브젝트 2개 존재한다. 즉 총 3개의 오브젝트가 존재한다. . - 메모리주소 93883369152752 에 존재하는 오브젝트는 클래스 오브젝트이며 Testclass1 또는 f 라고 불린다. . - 메모리주소 140489211063024 에 존재하는 오브젝트는 인스턴스 오브젝트이며 a라고 불린다. . - 메모리주소 140489211062064 에 존재하는 오브젝트는 인스턴스 오브젝트이며 b라고 불린다. . Testclass1.x, Testclass1.y . (0, 0) . f.x,f.y . (0, 0) . a.x,a.y . (0, 0) . b.x,b.y . (0, 0) . [시점4] . a.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 1), (1, 1), (0, 1)) . - 특징 . a.my_print()를 실행하면 a.x 의 값이 1이 증가한다. | a.my_print()를 실행하면 f.y, a.y, b.y 의 값이 동시에 1이 증가한다. (공유가 되는 느낌) | . [시점5] . b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 2 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 2), (1, 2), (1, 2)) . [시점6] . b.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 3 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 3), (1, 3), (2, 3)) . [시점7] . a.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 4 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 4), (2, 4), (2, 4)) . [시점8] . a.my_print() . 현재 인스턴스에서 3 회 출력 전체 인스턴스에서 총 5 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 5), (3, 5), (2, 5)) . . [&#50696;&#51228;2] . - 아래처럼 코드를 바꿔도 잘 동작할것 같다. . class Testclass2: def __init__(self): self.x=0 self.y=0 def my_print(self): self.x += 1 Testclass2.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . c=Testclass2() . c.my_print() . AttributeError Traceback (most recent call last) &lt;ipython-input-35-5500abb1215d&gt; in &lt;module&gt; -&gt; 1 c.my_print() &lt;ipython-input-33-72dbe3bd77f6&gt; in my_print(self) 5 def my_print(self): 6 self.x += 1 -&gt; 7 Testclass2.y +=1 8 print(&#34;현재 인스턴스에서 %s 회 출력&#34; % self.x) 9 print(&#34;전체 인스턴스에서 총 %s 회 출력&#34; % self.y) AttributeError: type object &#39;Testclass2&#39; has no attribute &#39;y&#39; . – 왜 에러가 나는가? . dir(Testclass2) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;] . dir(Testclass1) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;, &#39;x&#39;, &#39;y&#39;] . - 관찰1: Testclass2에서는 Testclass1과는 다르게 x,y가 없다. . dir(c) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;, &#39;x&#39;, &#39;y&#39;] . – 관찰2: 그런데 c라는 인스턴스 오브젝트에서는 x,y가 있다. . - 추론: __init__함수는 클래스 오브젝트가 만들어지는 시점에서는 실행되지 않고, 인스텐스 오브젝트가 만들어지는 시점에 실행된다. . - 결국 __init__함수의 역할은 클래스 오브젝트에서 인스턴스 오브젝트를 만든후에 초기화를 위해서 실행하는 어떠한 일련의 명령들을 묶어놓은 것에 불과하다. . – 즉 위의 코드는 굳이 따지면 아래를 실행한 것과 동일하다. . class Testclass2: # def __init__(self): # self.x=0 # self.y=0 def my_print(self): self.x += 1 Testclass2.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . c=Testclass2() . c.x=0 c.y=0 . - 이 상황에서 . c.my_print() . 를 실행하면 . c.x += 1 Testclass2.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % c.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % c.y) . 이 실행되는데, 이때 Testclass2.y 이 정의되어 있지 않으므로 . Testclass2.y +=1 . 에서 에러가 난다. . . [&#50696;&#51228; 3] . - 그렇다면 아래와 같이 수정하면 어떨까? . class Testclass3: def __init__(self): self.x=0 Testclass3.y=0 def my_print(self): self.x += 1 Testclass3.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . a=Testclass3() b=Testclass3() . a.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 2 회 출력 . a.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 3 회 출력 . a.my_print() . 현재 인스턴스에서 3 회 출력 전체 인스턴스에서 총 4 회 출력 . b.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 5 회 출력 . b.my_print() . 현재 인스턴스에서 3 회 출력 전체 인스턴스에서 총 6 회 출력 . – Testclass1과 동일한 기능이 수행되는것 같다. . - 그런데 조금만 생각해보면 엉터리라는 것을 알 수 있다. 아래의 코드를 관찰하여보자. . class Testclass3: def __init__(self): self.x=0 Testclass3.y=0 def my_print(self): self.x += 1 Testclass3.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) a=Testclass3() a.my_print() a.my_print() b=Testclass3() b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 2 회 출력 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . - Testclass3는 인스턴스를 생성할때마다 y=0이 설정된다. 그래서 . b=Testclass3() . 이 시점에서 의도하지 않게 &#39;전체 인스턴스에서 출력된 횟수&#39;를 의미하는 y가 초기화되었다. . - 코드는 엉터리이지만, Testclass3은 의외로 분석할만한 가치가 있다. 특히 위의 실행결과를 시점별로 Testclass1과 비교해보면 재미있다. . Testclass1 &amp; Testclass3 &#48708;&#44368; . - Testclass1 . ### Testclass1 ## 시점1: 클래스 오브젝트 생성 class Testclass1: x=0 y=0 def my_print(self): self.x += 1 Testclass1.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) ## 시점2: 인스턴스 오브젝트 a를 생성 a=Testclass1() ## 시점3: a에서 메소드 실행 a.my_print() ## 시점4: a에서 메소드를 한번 더 실행 a.my_print() ## 시점5: 인스턴스 오브젝트 b를 생성 b=Testclass1() ## 시점6: b에서 메소드를 실행 b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 2 회 출력 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 3 회 출력 . 시점1 시점2 시점3 시점4 시점5 시점6 . Testclass1.x | 0 | 0 | 0 | 0 | 0 | 0 | . Testclass1.y | 0 | 0 | 1 | 2 | 2 | 3 | . a.x | 값없음 | 0 | 1 | 2 | 2 | 2 | . a.y | 값없음 | 0 | 1 | 2 | 2 | 3 | . b.x | 값없음 | 값없음 | 값없음 | 값없음 | 0 | 1 | . b.y | 값없음 | 값없음 | 값없음 | 값없음 | 2 | 3 | . – Testclass3 . #### Testclass3 ## 시점1: 클래스 오브젝트 생성 class Testclass3: def __init__(self): self.x=0 Testclass3.y=0 def my_print(self): self.x += 1 Testclass3.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) ## 시점2: 인스턴스 오브젝트 a를 생성 a=Testclass3() ## 시점3: a에서 메소드 실행 a.my_print() ## 시점4: a에서 메소드를 한번 더 실행 a.my_print() ## 시점5: 인스턴스 오브젝트 b를 생성 b=Testclass3() ## 시점6: b에서 메소드를 실행 b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 2 회 출력 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . 시점1 시점2 시점3 시점4 시점5 시점6 . Testclass3.x | 값없음 | 값없음 | 값없음 | 값없음 | 값없음 | 값없음 | . Testclass3.y | 값없음 | 0 | 1 | 2 | 0 | 1 | . a.x | 값없음 | 0 | 1 | 2 | 2 | 2 | . a.y | 값없음 | 0 | 1 | 2 | 0 | 1 | . b.x | 값없음 | 값없음 | 값없음 | 값없음 | 0 | 1 | . b.y | 값없음 | 값없음 | 값없음 | 값없음 | 0 | 1 | . – Testclass3.y가 업데이트 되면 a.y, b.y도 자동으로 업데이트 된다. .",
            "url": "https://kimha02.github.io/ham/python/2021/07/21/python-7.html",
            "relUrl": "/python/2021/07/21/python-7.html",
            "date": " • Jul 21, 2021"
        }
        
    
  
    
        ,"post35": {
            "title": "(공부) Class(클래스)_예제",
            "content": "[&#50696;&#51228;4] &#51064;&#49324;&#44288;&#47532; &#50696;&#51228; . 원시적인 형태의 클래스 $ to$ 복잡하고 다양한 속성과 기능을 가지는 클래스로 발전 | 클래스는 무에서 점차 발전해나가는 프로토타입과 같이 코드를 설계할 때 유리 | . Step1: &#51064;&#51201;&#49324;&#54637; &#51077;&#47141; . class Person: def __init__(self,name,job=None,pay=0): self.name=name self.job=job self.pay=pay . hd=Person(&#39;Hodong Kang&#39;) iu=Person(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person(&#39;Hyewon Park&#39;,pay=3000) . print(hd.name,hd.job,hd.pay) print(iu.name,iu.job,iu.pay) print(hynn.name,hynn.job,hynn.pay) . Hodong Kang None 0 Jieun Lee dev 5000 Hyewon Park None 3000 . Step2: &#47700;&#49548;&#46300; &#52628;&#44032; . 아이유의 연봉을 10퍼센트 올리고 싶다면? . iu.pay *= 1.1 . iu.pay . 5500.0 . --&gt; 클래스의 외부에서 클래스의 속성 (iu.pay)을 바꾸는 동작(=함수)을 하드코딩하는 것은 좋은 방법이 아니다. . 좀 더 좋은 방법은 클래스 내부에 함수를 선언하는 방법이다. . class Person: def __init__(self,name,job=None,pay=0): self.name=name self.job=job self.pay=pay def giveRaise(self,percent): self.pay *= (1+percent) . hd=Person(&#39;Hodong Kang&#39;) iu=Person(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person(&#39;Hyewon Park&#39;,pay=3000) . print(hd.name,hd.job,hd.pay) print(iu.name,iu.job,iu.pay) print(hynn.name,hynn.job,hynn.pay) . Hodong Kang None 0 Jieun Lee dev 5000 Hyewon Park None 3000 . iu.giveRaise(0.1) . print(iu.name,iu.job,iu.pay) . Jieun Lee dev 5500.0 . hynn.giveRaise(0.2) print(hynn.name,hynn.job,hynn.pay) . Hyewon Park None 3600.0 . giveRaise라는 함수를 클래스 내부에 정의하면 . (1) 자명한 입력은 넣지 않아도 된다. (self) . (2) 원래 아이유의 연봉을 올리기 위해 작성한 코드였는데, Hynn의 연봉도 올릴 수 있게 되었다. . note: 만약에 하드코딩을 했다면? . class Person: def __init__(self,name,job=None,pay=0): self.name=name self.job=job self.pay=pay iu=Person(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person(&#39;Hyewon Park&#39;,pay=3000) iu.pay *= 1.1 hynn.pay *= 1.2 . note2: 함수를 클래스 외부에 선언했다면? (암묵적 전달대상 / 암묵적 업데이트 대상을 매순간 명시해야함) . class Person: def __init__(self,name,job=None,pay=0): self.name=name self.job=job self.pay=pay def giveRaise(pay,percent) pay *= (1+percent) return pay iu=Person(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person(&#39;Hyewon Park&#39;,pay=3000) iu.pay *= giveRaise(iu.pay,0.1) hynn.pay *= giveRaise(hynn.pay,0.2) . Step3: &#50672;&#49328;&#51088; &#50724;&#48260;&#47196;&#46377; . 클래스의 정보를 확인하기 위해서는? . print(hd.name,hd.job,hd.pay) print(iu.name,iu.job,iu.pay) print(hynn.name,hynn.job,hynn.pay) . 이것도 어떻게 보면 코드의 낭비 아닌가? 어차피 Person에서 보고 싶은 정보란 뻔하다. . 소망: 만약에 아래와 같이 타이핑만 하면 원하는 정보가 알아서 출력되면 좋겠다. . print(hd) print(iu) print(hynn) . 우리의 소망은 불가능해 보인다. print 함수이고 함수의 기능을 바꾸려면 함수를 다시 정의해야한다. . 그런데 print는 결국 내장함수이므로, 우리의 소망을 실현하기 위해서는 파이썬에 내장된 함수를 바꿔야한다. . 가능하다고 하더라도 문제이다. 그전까지 작성한 코드는 모두 어떻게 되는지? . ?hd . Type: Person String form: &lt;__main__.Person object at 0x7fbf621bb100&gt; Docstring: &lt;no docstring&gt; . Type이 Person인 경우에 한정하여 print의 기능을 바꾼다면? . print 내장함수는 Person타입(=내가 만든 클래스의 이름)에서만 바뀐 기능을 수행하고, 그외에서는 일반적으로 동작 . 조금 특별한 함수 __str__ 개발! . class Person: def __init__(self,name,job=None,pay=0): self.name=name self.job=job self.pay=pay def giveRaise(self,percent): self.pay *= (1+percent) def __str__(self): return str(self.name)+str(self.job)+str(self.pay) . __str__의 특징 . self를 입력으로 받는다. | 출력의 형태가 항상 문자열이어야 한다. | . hd=Person(&#39;Hodong Kang&#39;) iu=Person(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person(&#39;Hyewon Park&#39;,pay=3000) . print(hynn) . Hyewon ParkNone3000 . 욕심: 보통 주피터 노트북과 같은 대화형 프롬프트에서는 print를 굳이 사용하지 않아도 원하는 출력결과를 쉽게 얻는다. . 우리가 만든 클래스는? . print(hd) . Hodong KangNone0 . hd . &lt;__main__.Person at 0x7fbf621bbd00&gt; . 아쉬운데?.. $ to$ __repr__ 함수 개발 . class Person: def __init__(self,name,job=None,pay=0): self.name=name self.job=job self.pay=pay def giveRaise(self,percent): self.pay *= (1+percent) def __repr__(self): return str(self.name)+str(self.job)+str(self.pay) . hd=Person(&#39;Hodong Kang&#39;) iu=Person(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person(&#39;Hyewon Park&#39;,pay=3000) . hd . Hodong KangNone0 . print(hd) . Hodong KangNone0 . 보통은 __repr__을 더 선호한다. . __repr__이 더 많은 디스플레이 케이스에서 적용 | 두 가지 서로 다른 형태로 디스플레이하는데 관심이 없음. | . Step 4: &#49345;&#49549; . print(hd)의 디스플레이 형태가 예쁘지 않음 --&gt; 수정해보자. . 잔기술1 . &#39;파이는 %s&#39; % 3.14 . &#39;파이는 3.14&#39; . 잔기술2 . print(&#39;나는 n최고다&#39;) . 나는 최고다 . class Person2(Person): def __repr__(self): return &#39;이름: %s n직업: %s n연봉: %s&#39; % (self.name,self.job,self.pay) . hd=Person2(&#39;Hodong Kang&#39;) iu=Person2(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person2(&#39;Hyewon Park&#39;,pay=3000) . hd . 이름: Hodong Kang 직업: None 연봉: 0 . iu . 이름: Jieun Lee 직업: dev 연봉: 5000 . hynn . 이름: Hyewon Park 직업: None 연봉: 3000 . hd,iu,hynn . (이름: Hodong Kang 직업: None 연봉: 0, 이름: Jieun Lee 직업: dev 연봉: 5000, 이름: Hyewon Park 직업: None 연봉: 3000) . Manager라는 클래스를 새로 만들자. . Person2와 동일한데, 연봉상승방법이 약간 다르다고 하자. . 나쁜코드 . class Manager(Person2): def giveRaise(self,percent,bonus=0.1): self.pay *= (1+percent+bonus) . hd=Manager(&#39;Hodong Kang&#39;, job=&#39;mgr&#39;, pay=8000) . hd . 이름: Hodong Kang 직업: mgr 연봉: 8000 . hd.giveRaise(0.1) . hd . 이름: Hodong Kang 직업: mgr 연봉: 9600.000000000002 . 연봉상승은 10%상승이지만 매니저는 기본적으로 10% 상승시키므로 총 상승분은 20% . 좀 더 좋은 코드 기존에 만들어놓은 함수를 이용하자! . class Manager(Person2): def giveRaise(self,percent,bonus=0.1): Person2.giveRaise(self,percent+bonus) . hd=Manager(&#39;Hodong Kang&#39;, job=&#39;mgr&#39;, pay=8000) . hd . 이름: Hodong Kang 직업: mgr 연봉: 8000 . hd.giveRaise(0.1) . hd . 이름: Hodong Kang 직업: mgr 연봉: 9600.0 . 만약에 우리회사의 모든 직원들의 연봉을 20%올리고 싶다면? . hd=Manager(&#39;Hodong Kang&#39;, job=&#39;mgr&#39;, pay=8000) iu=Person2(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person2(&#39;Hyewon Park&#39;,pay=3000) . hd,iu,hynn . (이름: Hodong Kang 직업: mgr 연봉: 8000, 이름: Jieun Lee 직업: dev 연봉: 5000, 이름: Hyewon Park 직업: None 연봉: 3000) . for ins in [hd,iu,hynn]: ins.giveRaise(0.2) . hd,iu,hynn . (이름: Hodong Kang 직업: mgr 연봉: 10400.0, 이름: Jieun Lee 직업: dev 연봉: 6000.0, 이름: Hyewon Park 직업: None 연봉: 3600.0) . 코드분석 . (1) ins는 Person2클래스의 인스턴스 혹은 Manager클래스의 인스턴스 . (2) 각 인스턴스는 각 클래스에 정의된 적당한 버전의 &#39;giveRaise&#39;를 활용하여 연봉이 인상된다. 즉 iu, hynn은 Person2버전의 giveRasie를 실행하고, hd는 Manager버전의 &#39;giveRaise&#39;를 실행 . (3) 출력은 모두 동일한 __repr__을 실행 . 클래스가 없다면? . (1) 함수의 암묵적인자를 전달하지 못하므로 코드가 길어진다. (self 인자) . (2) (hd, iu, hynn) 와 같이 같이 깔끔한 코드로 출력결과를 바로바로 확인하기가 불가능할 것이다. (연산자 오버로딩) . (3) 그 사람이 매니저인지 아닌지에 따라 연봉상승하는 방법이 다르므로, 어딘가에 if문을 넣어야 할 것이다. . (4) 코드의 재사용이 어렵다.. 디버깅이 어렵다.. 등등.. . . [$ ast$] __init__함수 재정의 . 생각해보니까 아래의 코드에서 호동의 직업을 매니저로 입력하는 것이 낭비같다. . hd=Manager(&#39;Hodong Kang&#39;, job=&#39;mgr&#39;, pay=8000) iu=Person2(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person2(&#39;Hyewon Park&#39;,pay=3000) . 호동은 매니저클래스의 인스턴스이므로 직업은 당연히 매니저일것. . 굳이 job=&#39;mgr&#39;와 같은 방식으로 입력하지 않아도 될것 같다. . 어떻게 하면 될까? . class Manager(Person2): def __init__(self,name,pay=0): self.name=name self.job=&#39;mgr&#39; self.pay=pay def giveRaise(self,percent,bonus=0.1): Person2.giveRaise(self,percent+bonus) . hd=Manager(&#39;Hodong Kang&#39;, pay=8000) iu=Person2(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person2(&#39;Hyewon Park&#39;,pay=3000) . hd . 이름: Hodong Kang 직업: mgr 연봉: 8000 . hd,iu,hynn . (이름: Hodong Kang 직업: mgr 연봉: 8000, 이름: Jieun Lee 직업: dev 연봉: 5000, 이름: Hyewon Park 직업: None 연봉: 3000) . 관찰: 아까 매니저 클래스에서 함수를 정의하는 과정을 잘 관찰하면 . class Manager(Person2): def giveRaise(self,percent,bonus=0.1): Person2.giveRaise(self,percent+bonus) . 상속받은 클래스(서브클래스)에서 슈퍼클래스이름.함수이름으로 슈퍼클래스의 함수를 호출함. . - __init__도 함수이므로 위와 같은 방식을 사용할 수 있겠다. . class Manager(Person2): def __init__(self,name,pay=0): Person2.__init__(self,name,&#39;mgr&#39;,pay) def giveRaise(self,percent,bonus=0.1): Person2.giveRaise(self,percent+bonus) . hd=Manager(&#39;Hodong Kang&#39;, pay=8000) iu=Person2(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person2(&#39;Hyewon Park&#39;,pay=3000) . hd,iu,hynn . (이름: Hodong Kang 직업: mgr 연봉: 8000, 이름: Jieun Lee 직업: dev 연봉: 5000, 이름: Hyewon Park 직업: None 연봉: 3000) . - giveRiase를 수정한 기법과 __init__을 수정한 기법은 동일함. . . [$ ast$] 객체임베딩(객체내장) . - 클래스 Person2를 상속받지 않고 사용할 수는 없을까? . - Person2를 인스턴스화 하고 그 인스턴스를 입력으로 받아 기능을 사용하는 방식을 취한다면? $ to$ 구현해보자. . - 원래코드 . class Manager(Person2): def __init__(self,name,pay=0): Person2.__init__(self,name,&#39;mgr&#39;,pay) def giveRaise(self,percent,bonus=0.1): Person2.giveRaise(self,percent+bonus) . - 아래와 같이 수정 . class Manager(): def __init__(self,name,pay=0): self.person2=Person2(name,&#39;mgr&#39;,pay) def giveRaise(self,percent,bonus=0.1): self.person2.giveRaise(self,percent+bonus) . hd=Manager(&#39;Hodong Kang&#39;, pay=8000) iu=Person2(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person2(&#39;Hyewon Park&#39;,pay=3000) . hd,iu,hynn . (&lt;__main__.Manager at 0x7fdea54ddbe0&gt;, 이름: Jieun Lee 직업: dev 연봉: 5000, 이름: Hyewon Park 직업: None 연봉: 3000) . hd.__repr__ . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;giveRaise&#39;, &#39;job&#39;, &#39;name&#39;, &#39;pay&#39;] . class Manager(): def __init__(self,name,pay=0): self.person2=Person2(name,&#39;mgr&#39;,pay) def giveRaise(self,percent,bonus=0.1): self.person2.giveRaise(self,percent+bonus) def __repr__(self): return str(self.person2) . hd=Manager(&#39;Hodong Kang&#39;, pay=8000) iu=Person2(&#39;Jieun Lee&#39;,job=&#39;dev&#39;,pay=5000) hynn=Person2(&#39;Hyewon Park&#39;,pay=3000) . hd,iu,hynn . (이름: Hodong Kang 직업: mgr 연봉: 8000, 이름: Jieun Lee 직업: dev 연봉: 5000, 이름: Hyewon Park 직업: None 연봉: 3000) . hd.person2.__repr__ . &lt;__main__.Manager at 0x7fdea54a1940&gt; . hd.__repr__ . &lt;__main__.Manager at 0x7fdea54a1940&gt; . - 이 예제에서는 임베딩기법이 그다지 유용하지 않다. . - 코드에 따라서 유용할수도있다. .",
            "url": "https://kimha02.github.io/ham/python/2021/07/21/python-6.html",
            "relUrl": "/python/2021/07/21/python-6.html",
            "date": " • Jul 21, 2021"
        }
        
    
  
    
        ,"post36": {
            "title": "(공부) Class(클래스)_이해",
            "content": "&#53364;&#47000;&#49828;&#46976; &#47924;&#50631;&#51064;&#44032;? . 많은 교재에서 정의를 회피함 | 비유적 설명 , 다른 대상을 가져와서 설명 클래스는 과자틀과 비슷하다. 클래스란 똑같은 무엇인가를 계속 만들어 낼 수도 있는 설계도면이고 객체란 클래스로 만든 피조물을 뜻한다. (점프투파이썬) | In object-oriented programming, a class is an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods).` | . | . 직접적 설명 복제를 위한 확장가능한 프로그램 코드의 유닛 | . | . . &#50857;&#50612;&#51221;&#47532; . 클래스 인스턴스 . 과자틀 | 과자 | . 공장 | 공장에서 나온 생산품 | . 설계도 | 설계도 바탕으로 소프트웨어 세계에 구현된 실체 | . 프로그램 | 프로세스 | . . &#50724;&#45720;&#51032; &#50696;&#51228;&#45716; &#47924;&#50556;&#54840;~! . 밈_무야호의 탄생 과정 . (1) 무야호 원본 시청 . (2) 복사하고 싶은 속성을 추림 . (3) 복제가능한 어떤 밈(틀)을 만듬 . 틀1: 무야호~~~ -&gt; 그만큼 ~하셨다는거지? | 틀2: 무야호 + 영상샘플링 + 음악샘플링 | . (4) 밈으로부터 짤을 만든다. . 다시 말해, . (1) 개념의 인지 . (2) 복사하고 싶은 속성을 추림 . (3) 복사가능한 어떤 틀을 만듬 (=클래스를 정의) . (4) 틀에서 인스턴스를 만든다 (=클래스에서 인스턴스를 만든다) . . [&#50696;&#51228;1] . 무파마에 무야호 밈을 적용해보자 . [예비학습] 그림 불러오는 함수 . ! pip3 install image # PIL : python image library -&gt; image library 설치 . Collecting image Downloading image-1.5.33.tar.gz (15 kB) Collecting pillow Downloading Pillow-8.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB) |████████████████████████████████| 3.0 MB 1.9 MB/s eta 0:00:01 Collecting django Downloading Django-3.2.5-py3-none-any.whl (7.9 MB) |████████████████████████████████| 7.9 MB 10.5 MB/s eta 0:00:01 |████████████████████████████▉ | 7.1 MB 10.5 MB/s eta 0:00:01 Requirement already satisfied: six in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from image) (1.16.0) Collecting sqlparse&gt;=0.2.2 Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB) |████████████████████████████████| 42 kB 1.6 MB/s eta 0:00:01 Requirement already satisfied: pytz in /home/khy/anaconda3/envs/py38r40/lib/python3.8/site-packages (from django-&gt;image) (2021.1) Collecting asgiref&lt;4,&gt;=3.3.2 Downloading asgiref-3.4.1-py3-none-any.whl (25 kB) Building wheels for collected packages: image Building wheel for image (setup.py) ... done Created wheel for image: filename=image-1.5.33-py2.py3-none-any.whl size=19482 sha256=731adb6c12993075241d6d32bee228d3652bc2c0f793c21fa4c941ace88f6f23 Stored in directory: /home/khy/.cache/pip/wheels/ac/30/5c/a8b33888bea3507eda7c924a143d34b2390d2ca5b145b327b5 Successfully built image Installing collected packages: sqlparse, asgiref, pillow, django, image Successfully installed asgiref-3.4.1 django-3.2.5 image-1.5.33 pillow-8.3.1 sqlparse-0.4.1 . from PIL import Image Image.open(&#39;mooyaho1.jpg&#39;) # 그냥 불러오면 이미지가 너무 커서 결과 삭제 . Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) # 이미지 크기 조절 . &#47785;&#54364;: (1) &quot;&#45453;&#49900; &#47924;&#54028;&#47560;&quot;&#47484; &#52636;&#47141;&#54616;&#44256; (2) &#47924;&#50556;&#54840; &#44536;&#47548;&#51012; &#48372;&#50668;&#51468; (3) &quot;&#44536;&#47564;&#53372; &#47579;&#51080;&#51004;&#49884;&#45800;&#44144;&#51648;&quot; &#47196; &#47560;&#47924;&#47532; . &#52395; &#49884;&#46020; . title=&quot;농심 무파마&quot; img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) don=&quot;그만큼 맛있으시단거지&quot; . print(title) display(img) print(don) . 농심 무파마 . 그만큼 맛있으시단거지 . 짤을 변경하고 싶다면, 아래와 같이 수행하자. | . title=&quot;속 시원한 농심 무야호&quot; print(title) display(img) print(don) . 속 시원한 농심 무야호 . 그만큼 맛있으시단거지 . 첫 시도의 아쉬움 . 드립을 바꾼 여러 개의 짤을 관리하기 힘들다. | 불필요한 반복도 많다. print, display, print &lt;-- 짤을 만들때마다 반복 | 코드가 지저분하다. (디버깅이 힘들다) | . &#46160;&#48264;&#51704; &#49884;&#46020;: &#47784;&#46280; . import mooyaho . mooyaho.memeshow(mooyaho.title, mooyaho.img,mooyaho.don) . 농심 무파마 . 그만큼 맛있으시단거지 . 타이틀을 바꾸고싶다면? . mooyaho.title=&#39;속시원한 농심 무야호&#39; mooyaho.memeshow(mooyaho.title, mooyaho.img, mooyaho.don) . 속시원한 농심 무야호 . 그만큼 맛있으시단거지 . 두 번째 시도의 아쉬운 점 . 코드는 상대적으로 깔끔하지만, 함수부분이 조금 아쉽다. | 코드를 수정할 때 마다 커널재시작을 해야한다. | . &#49464;&#48264;&#51704; &#49884;&#46020;: &#53364;&#47000;&#49828; . 다시 밈으로 짤을 만드는 개념을 복습하면 아래와 같다. . (1) 무야호 원본 시청 . (2) 복사하고싶은 속성 추출 . (3) 복제가능한 어떤 틀(밈)을 만듬 . (4) 밈으로 부터 짤을 만든다. . (1) &#48373;&#51228;&#44032;&#45733;&#54620; &#53952;&#51012; &#47564;&#46308;&#51088;. = &#53364;&#47000;&#49828;&#47484; &#49440;&#50616;&#54616;&#51088; . class MooYaHo(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(self): ### 클래스안에서 정의된 함수* print(self.title) display(self.img) print(self.don) . 모듈버전과 비교해보자. . from PIL import Image title=&quot;농심 무파마&quot; ### 모듈안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 모듈안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 모듈안에서 정의된 변수3 def memeshow(title,img,don): ### 모듈안에서 정의된 함수 print(title) display(img) print(don) . -&gt; 모듈버전이랑 비교하니까 함수부분이 조금 다르다. . 혹시 모듈처럼 아래와 같이 클래스를 선언해도 되지 않나? . class MooYaHo(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(title,img,don): ### 클래스안에서 정의된 함수 print(title) display(img) print(don) . $ to$ 안된다... (자세한 이유는 나중에) . 규칙1: 클래스내에서 함수를 선언하면 반드시 첫번째 인자는 self를 넣어야 한다. --&gt; self가 뭘까? . 규칙2: 클래스 내에서 정의한 변수 (예를들면 title, img, don)를 사용하려면 . self.title, self.img, self.don | MooYaHo.title, MooYaHo.img, MooYaHo.don | . (2) &#48136;&#51004;&#47196; &#48512;&#53552; &#51684;&#51012; &#47564;&#46304;&#45796;. (&#53364;&#47000;&#49828;&#47196;&#48512;&#53552; &#51064;&#49828;&#53556;&#49828;&#47484; &#49373;&#49457;&#54620;&#45796;.) . Step1: 클래스에서 인스턴스를 만듬 . Step2: 인스턴스에서 memeshow라는 함수를 사용 . 클래스에서 인스턴스를 찍어내는 방법 . 함수사용법과 비슷하다. | 클래스 이름을 쓰고 콘텐츠를 구체화시키는 과정에서 필요한 입력1, 입력2를 ()에 넣는다. | MooYaHo의 경우는 따로 입력이 없으므로, 그냥 MooYaHo하고 입력을 비워둔다. 즉 MooYaHo()로 생성 | . moo1=MooYaHo() ### 첫번째 인스턴스 생성 . moo1? . Type: MooYaHo String form: &lt;__main__.MooYaHo object at 0x7f9cc80c8580&gt; Docstring: &lt;no docstring&gt; . Type : Mooyaho ? 우리가 아는 Type은 int, float, list $ to$ int가 Class 이름이었나? $ to$ 나중에 설명 . 밈의 속성 확인 . moo1.하고 탭을 눌러보자. . moo1. . 주황색: don, img, title | 파란식: memeshow &lt;-- 함수 함수의 입력: self | 함수의 기능: print, display, print | . | . moo1.memeshow() . 농심 무파마 . 그만큼 맛있으시단거지 . . [$ star$] &#53364;&#47000;&#49828;&#51032; &#50948;&#47141; (&#51060;&#44152; &#45796;&#47480; &#48169;&#48277;&#51004;&#47196; &#50612;&#46523;&#44172; &#53076;&#46377;&#54644;&#50556; &#54624;&#51648; &#49345;&#49345;&#54644;&#48380;&#44163;) . 성능1: 인스턴스에서 .을 찍고 접근할 수 있는 여러 자료들을 정의할 수 있다. . moo1.title . &#39;농심 무파마&#39; . 성능2:인스턴스에서 .을 찍고 쓸 수 있는 자체적인 함수(=method라고 함)를 정의할 수 있다. . moo1.memeshow() . 농심 무파마 . 그만큼 맛있으시단거지 . 성능3: 짤의 내용을 쉽게 바꿀 수 있다. . moo1.title=&quot;속까지 시원해지는 농심 무야호&quot; . moo1.memeshow() . 속까지 시원해지는 농심 무야호 . 그만큼 맛있으시단거지 . moo1.don=&quot;그만큼 시원하시다는 거지&quot; moo1.memeshow() . 속까지 시원해지는 농심 무야호 . 그만큼 시원하시다는 거지 . 성능4: 여러짤을 동시에 쉽게 컨트롤 할 수 있다. . moo2=MooYaHo() moo3=MooYaHo() . moo2.title=&quot;오뚜기 진야호&quot; moo2.don=&quot;그만큼 진하시다는 거지~&quot; moo2.memeshow() . 오뚜기 진야호 . 그만큼 진하시다는 거지~ . moo3.title=&quot;팔도 비야호&quot; moo3.don=&quot;그만큼 비비고 싶으셨단 거지~&quot; moo3.memeshow() . 팔도 비야호 . 그만큼 비비고 싶으셨단 거지~ . moo2.memeshow() . 오뚜기 진야호 . 그만큼 진하시다는 거지~ . 성능 5: 틀의 재설계(밈의 재설계) $ star$$ star$$ star$ . 출력만 살짝 바꾸어서 MooYaHo2를 만들고 싶다. $ to$ MooYaHo의 모든 내용은 그대로 가져오고, 살짝만 다시 조정하면 된다. . #### 이런식으로 할 필요 없다. class MooYaHo2(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(self): ### 클래스안에서 정의된 함수* print(&#39;☆☆☆☆☆☆[&#39;+self.title+&#39;]☆☆☆☆☆☆&#39;) display(self.img) print(&#39;형돈:&#39;+self.don) . class MooYaHo2(MooYaHo): ### ()에mooyaho를 넣어서 내용을 가져온다. title, img, don 언급할 필요 없음 choi=&#39;무야~~~~~호~~~!!!&#39; ### 문장 추가 def memeshow(self): ### 클래스안에서 정의된 함수* print(&#39;☆☆☆☆☆☆[&#39;+self.title+&#39;]☆☆☆☆☆☆&#39;) display(self.img) print(self.choi) print(&#39;형돈:&#39;+self.don) . moo4=MooYaHo2() . moo4.memeshow() . ☆☆☆☆☆☆[농심 무파마]☆☆☆☆☆☆ . 무야~~~~~호~~~!!! 형돈:그만큼 맛있으시단거지 . moo5=MooYaHo2() . moo5.title=&#39;오뚜기 진야호&#39; moo5.don=&#39;그만큼 진하시다는 거지&#39; moo5.memeshow() # 내용도 쉽게 바꿀 수 있다 . ☆☆☆☆☆☆[오뚜기 진야호]☆☆☆☆☆☆ . 무야~~~~~호~~~!!! 형돈:그만큼 진하시다는 거지 . . [&#50696;&#51228;2] . import numpy class Meme: # class Meme(): n=0 title=&quot;농심&quot; def memeshow(self): self.n=self.n+1 print(self.title) print(&quot;*****&quot;) print(numpy.random.normal()) print(&quot;*****&quot;) print(str(self.n)+&#39;번째 짤&#39;) . ins1=Meme() . ins1.memeshow() . 농심 ***** -1.4375019518644987 ***** 4번째 짤 . ins2=Meme() . ins2.title=&#39;삼양&#39; . ins2.memeshow() . 삼양 ***** 1.277311593375453 ***** 1번째 짤 . ins2.n . 1 . ins1.n . 4 . self에 들어가야 했던 것은 사실 인스턴스 이름이었음. . 그런데 인스턴스 이름은 모른다. (내가 뭘로 만들지 알고? ) $ to$ self로 적는다. . . [&#50696;&#51228;3] . 아래코드가 아쉽다. . ins2=Meme() ins2.title=&#39;삼양&#39; . title의 디폴트가 &#39;농심&#39;이어야하는가? . 인스턴스를 만들때마다 타이틀을 새로 정하는 방식이 있으면 좋겠다. . __init__ 함수 개발!! . __init__ 함수란? . 몇 가지 사항을 빼고는 별다른 특별한 점이 없는 (어떠한 마법도 없는) 그냥 함수이다. | 인스턴스가 생성되는 시점에 자동으로 실행된다. | 특별한 첫번째 인자를 가진다. (self) | 클래스를 인스턴스화 할때 (...)의 값들을 함수의 입력으로 받는다. | . class Meme2: # class Meme2(): n=0 def __init__(self,title): self.title=title def memeshow(self): self.n=self.n+1 print(self.title) print(&quot;*****&quot;) print(numpy.random.normal()) print(&quot;*****&quot;) print(str(self.n)+&#39;번째 짤&#39;) . ins3=Meme2() . TypeError Traceback (most recent call last) &lt;ipython-input-51-06a02fb50ab1&gt; in &lt;module&gt; -&gt; 1 ins3=Meme2() TypeError: __init__() missing 1 required positional argument: &#39;title&#39; . ins3=Meme2(&#39;팔도&#39;) . ins3.title . &#39;팔도&#39; . ins3.memeshow() . 팔도 ***** 1.654463136086809 ***** 1번째 짤 . - 무슨일이 일어난 것일까? . (1) Meme2()를 인스턴스화 하는 순간에 __init__ 이 실행되어야 함. . (2) 그런데 __init__의 첫번째 인수인 self는 입력안해도 된다고 치고, 두번째 인수인 title은 입력으로 받았어야만 하는 것인데, 입력으로 받지 못하여 에러메시지 발생. . (3) 그럼 언제 __init__의 두번째 인수인 title을 넣어야할까? 곰곰히 생각해보니 Meme2를 인스턴스화 하는 순간에 입력으로 넣었어야 논리적으로 맞다. 즉 ins3=Meme2(&#39;팔도&#39;)와 같은 식으로 생성하는 순간 입력으로 넣어야 하는 것이었음. . (4) __init__의 두번째 인자가 &#39;팔도&#39;로 입력되었고, 이것이 self.title 즉 ins3.title에 바로 업데이트 된 상황임. . . &#53076;&#46300;&#51032; &#54952;&#50984;&#51201;&#51064; &#49688;&#51221; . class Meme2(Meme): # class Meme2(): def __init__(self,title): self.title=title . ins3=Meme2(&#39;팔도&#39;) . ins3.memeshow() . 팔도 ***** 0.13698357679308168 ***** 1번째 짤 . ins4=Meme2(&#39;오뚜기&#39;) . ins4.memeshow() . 오뚜기 ***** -0.7467284797015331 ***** 1번째 짤 . . 욕심: 타이틀이 없다고 에러메시지를 띄우는 것 보다 없으면 없는대로 만들어도 되지 않을까? . class Meme3(Meme): def __init__(self,title=None): self.title=title . ins5=Meme3() . ins5.title ### none이라 결과 안 뜬다 . ins5.memeshow() . None ***** 0.8480657490572441 ***** 1번째 짤 . ins5.title=&#39;야구르트&#39; . ins5.title . &#39;야구르트&#39; . ins5.memeshow() . 야구르트 ***** 0.11260958814531723 ***** 2번째 짤 .",
            "url": "https://kimha02.github.io/ham/python/2021/07/21/python-5.html",
            "relUrl": "/python/2021/07/21/python-5.html",
            "date": " • Jul 21, 2021"
        }
        
    
  
    
        ,"post37": {
            "title": "(공부) 파이썬 객체 소개_pandas",
            "content": "(1) dict&#51032; &#48373;&#49845; . dict를 선언하는 방법: . dict({&#39;a&#39;:[1,2,3], &#39;b&#39;:[2,3,4], &#39;c&#39;:[3,4,5]}) . {&#39;a&#39;: [1, 2, 3], &#39;b&#39;: [2, 3, 4], &#39;c&#39;: [3, 4, 5]} . Q : dict는 왜 key:value의 집합으로 선언해야 하는가? . A : dict는 검색에 최적화되어있다. key로 접근하면 일일이 위치를 기억하지 않아도 원하는 정보를 얻을 수 있다. . (예제) . d={&#39;새로이&#39;:[30,600,4.0], &quot;이서&quot;:[20,950,4.2], &quot;일권&quot;:[28,950,2.3], &quot;현이&quot;:[28,650,3.8]} . d[&#39;이서&#39;] . [20, 950, 4.2] . &quot;이서&quot;로 검색을 하면 나이, 토익, 학점이 나온다. . 편하다. . (2) &#45436;&#51137;1 . 까칠이: list로 해도 충분히 가능하지 않나? . l=[[&#39;새로이&#39;,30,600,4.0], [&quot;이서&quot;,20,950,4.2], [&quot;일권&quot;,28,950,2.3], [&quot;현이&quot;,28,650,3.8]] . l[1] . [&#39;이서&#39;, 20, 950, 4.2] . 교과서: list는 &quot;이서&quot;의 위치를 알고 있어야 한다. dict는 &quot;이서&quot;의 위치를 몰라도, &quot;이서&quot;라는 키워드만 알면 정보를 얻을 수 있다. . 까칠이(넘파이,불인덱싱마스터): 아래처럼 하면 되는것 아닌가? . import numpy as np . l1=np.array(l) . l1 . array([[&#39;새로이&#39;, &#39;30&#39;, &#39;600&#39;, &#39;4.0&#39;], [&#39;이서&#39;, &#39;20&#39;, &#39;950&#39;, &#39;4.2&#39;], [&#39;일권&#39;, &#39;28&#39;, &#39;950&#39;, &#39;2.3&#39;], [&#39;현이&#39;, &#39;28&#39;, &#39;650&#39;, &#39;3.8&#39;]], dtype=&#39;&lt;U3&#39;) . l1.T . array([[&#39;새로이&#39;, &#39;이서&#39;, &#39;일권&#39;, &#39;현이&#39;], [&#39;30&#39;, &#39;20&#39;, &#39;28&#39;, &#39;28&#39;], [&#39;600&#39;, &#39;950&#39;, &#39;950&#39;, &#39;650&#39;], [&#39;4.0&#39;, &#39;4.2&#39;, &#39;2.3&#39;, &#39;3.8&#39;]], dtype=&#39;&lt;U3&#39;) . l1.T[0] . array([&#39;새로이&#39;, &#39;이서&#39;, &#39;일권&#39;, &#39;현이&#39;], dtype=&#39;&lt;U3&#39;) . l1.T[0]==&#39;이서&#39; . array([False, True, False, False]) . l1[l1.T[0]==&#39;이서&#39;] . array([[&#39;이서&#39;, &#39;20&#39;, &#39;950&#39;, &#39;4.2&#39;]], dtype=&#39;&lt;U3&#39;) . 교과서: 복잡하다.. dict는 이름만 알면 쉽게 정보검색 가능. . 까칠이: 나이가 28인 사람이 누군지 모두 알고 싶을 경우는? dict로 어떻게 하는지? . 교과서: ... . 까칠이(넘파이,불인덱싱마스터): 나는 할수 있다. . l1.T . array([[&#39;새로이&#39;, &#39;이서&#39;, &#39;일권&#39;, &#39;현이&#39;], [&#39;30&#39;, &#39;20&#39;, &#39;28&#39;, &#39;28&#39;], [&#39;600&#39;, &#39;950&#39;, &#39;950&#39;, &#39;650&#39;], [&#39;4.0&#39;, &#39;4.2&#39;, &#39;2.3&#39;, &#39;3.8&#39;]], dtype=&#39;&lt;U3&#39;) . l1.T[1] . array([&#39;30&#39;, &#39;20&#39;, &#39;28&#39;, &#39;28&#39;], dtype=&#39;&lt;U3&#39;) . l1.T[1]==&#39;28&#39; . array([False, False, True, True]) . l1[l1.T[1]==&#39;28&#39;] . array([[&#39;일권&#39;, &#39;28&#39;, &#39;950&#39;, &#39;2.3&#39;], [&#39;현이&#39;, &#39;28&#39;, &#39;650&#39;, &#39;3.8&#39;]], dtype=&#39;&lt;U3&#39;) . 교과서: ... . 까칠이: key를 사용하는 것이 왜 정보검색에 유리한것인지? . (3) &#45436;&#51137;2 . 사실 논쟁1에서 까칠이가 언급한 내용은 list의 장점이라기 보다 list와 호환성이 좋은 numpy의 장점이다. . dict도 dict와 호환성이 좋은 새로운 자료형이 있는데, 그것이 바로 pandas이다. . 근본적인 차이: list는 번호로, dict는 keyword로 접근한다. . 인덱싱, 슬라이싱 vs 맵핑 | . note: 리스트는 키워드로 정보검색이 불가능하다. . note: 딕셔너리는 인덱스로 정보검색이 불가능하다. . (4) pandas . import pandas as pd . d . {&#39;새로이&#39;: [30, 600, 4.0], &#39;이서&#39;: [20, 950, 4.2], &#39;일권&#39;: [28, 950, 2.3], &#39;현이&#39;: [28, 650, 3.8]} . pd.DataFrame(d) ## 판다스자료형 = 데이터프레임을 선언하는 방법 . 새로이 이서 일권 현이 . 0 30.0 | 20.0 | 28.0 | 28.0 | . 1 600.0 | 950.0 | 950.0 | 650.0 | . 2 4.0 | 4.2 | 2.3 | 3.8 | . df=pd.DataFrame(d).T . df . 0 1 2 . 새로이 30.0 | 600.0 | 4.0 | . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . 현이 28.0 | 650.0 | 3.8 | . note: 이서의 정보를 알고 싶다면? (딕셔너리 느낌) . df.loc[&#39;이서&#39;] . 0 20.0 1 950.0 2 4.2 Name: 이서, dtype: float64 . note: 칼럼이름을 정하고 싶다면? . df.columns=[&#39;age&#39;,&#39;toeic&#39;,&#39;gpa&#39;] . df . age toeic gpa . 새로이 30.0 | 600.0 | 4.0 | . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . 현이 28.0 | 650.0 | 3.8 | . note: 2번째 칼럼을 불러오자! (넘파이느낌) . df.iloc[:,1] . 새로이 600.0 이서 950.0 일권 950.0 현이 650.0 Name: toeic, dtype: float64 . note: 2-3번째 칼럼을 불러오자! (넘파이느낌) . df.iloc[:,1:3] . toeic gpa . 새로이 600.0 | 4.0 | . 이서 950.0 | 4.2 | . 일권 950.0 | 2.3 | . 현이 650.0 | 3.8 | . note: 토익점수를 불러오고 싶다면? . df.loc[:,&#39;toeic&#39;] . 새로이 600.0 이서 950.0 일권 950.0 현이 650.0 Name: toeic, dtype: float64 . note: age~toeic까지의 정보를 얻고 싶다면? . df.loc[:,&#39;age&#39;:&#39;toeic&#39;] . age toeic . 새로이 30.0 | 600.0 | . 이서 20.0 | 950.0 | . 일권 28.0 | 950.0 | . 현이 28.0 | 650.0 | . note: 새로이~일권까지의 정보를 얻고 싶다면? . df.loc[&#39;새로이&#39;:&#39;일권&#39;,:] . age toeic gpa . 새로이 30.0 | 600.0 | 4.0 | . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . note: 토익점수가 800보다 높은사람을 부르고 싶다면? . df . age toeic gpa . 새로이 30.0 | 600.0 | 4.0 | . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . 현이 28.0 | 650.0 | 3.8 | . df.query(&#39;toeic&gt;800&#39;) . age toeic gpa . 이서 20.0 | 950.0 | 4.2 | . 일권 28.0 | 950.0 | 2.3 | . note: 나이가 23보다 큰 사람을 부르고 싶다면? . df.query(&#39;age&gt;23&#39;) . age toeic gpa . 새로이 30.0 | 600.0 | 4.0 | . 일권 28.0 | 950.0 | 2.3 | . 현이 28.0 | 650.0 | 3.8 | . note: 나이가 23보다 많고 토익점수가 800보다 높은 사람을 부르고 싶다면? . df.query(&#39;age&gt;23 &amp; toeic&gt;800&#39;) . age toeic gpa . 일권 28.0 | 950.0 | 2.3 | .",
            "url": "https://kimha02.github.io/ham/python/2021/07/17/python-4.html",
            "relUrl": "/python/2021/07/17/python-4.html",
            "date": " • Jul 17, 2021"
        }
        
    
  
    
        ,"post38": {
            "title": "(공부) 파이썬 객체 소개_numpy",
            "content": "np.array . 욕심: (1,2,3)+(2,3,4)=(3,5,7)를 계산하고 싶다. . (실패) . a=[1,2,3] b=[2,3,4] a+b . [1, 2, 3, 2, 3, 4] . (성공) . [a[0]+b[0],a[1]+b[1],a[2]+b[2]] . [3, 5, 7] . (성공2) . a[0]+b[0],a[1]+b[1],a[2]+b[2] . (3, 5, 7) . temp_ = a[0]+b[0],a[1]+b[1],a[2]+b[2] . temp_ . (3, 5, 7) . list(temp_) . [3, 5, 7] . . 원소가 많을 경우 | . (실패) . c=[] for i in [0,1,2]: c[i]=a[i]+b[i] . IndexError Traceback (most recent call last) &lt;ipython-input-4-4af7fca0a837&gt; in &lt;module&gt; 1 c=[] 2 for i in [0,1,2]: -&gt; 3 c[i]=a[i]+b[i] IndexError: list assignment index out of range . c=[] c[0]=1 . IndexError Traceback (most recent call last) &lt;ipython-input-5-7a51dc8f9a26&gt; in &lt;module&gt; 1 c=[] -&gt; 2 c[0]=1 IndexError: list assignment index out of range . c=[] c=c+[1] . c . [1] . (성공) . c=[] for i in [0,1,2]: c=c+[a[i]+b[i]] . c . [3, 5, 7] . (성공) . a=[1,2,3] b=[2,3,4] c=[a[i]+b[i] for i in [0,1,2]] . c . [3, 5, 7] . . - np array 사용 . import numpy as np # np는 별칭(맨날 치기 귀찮으니까) . a=np.array((1,2,3)) #우리가 생각하는 벡터 형태, 리스트와 약간 다름! b=np.array([2,3,4]) . a+b . array([3, 5, 7]) . list - tuple - np.array사이에는 호환성이 좋음 . a=[1,2,3] . list(np.array(tuple(a))) . [1, 2, 3] . . 넘파이를 사용하면 벡터연산과 행렬연산을 쉽게 할 수 있다. . 예를들어 아래와 같은 문제가 있다고 하자. . $ begin{cases} w+2x+3y+4z=1 2w+2x+y=9 x-y=4 3w+x-y+3y=7 end{cases}$ . 매트릭스 형태로 위의 식을 표현하면 아래와 같다. . $ begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix} begin{bmatrix} w x y z end{bmatrix}= begin{bmatrix} 1 9 4 7 end{bmatrix}$ . 양변에 $ begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix}$의 역행렬을 취하면 . $ begin{bmatrix} w x y z end{bmatrix}= begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix}^{-1} begin{bmatrix} 1 9 4 7 end{bmatrix}$ . A=[[1,2,3,4],[2,2,1,0],[0,1,-1,0],[3,1,-1,3]] . A . [[1, 2, 3, 4], [2, 2, 1, 0], [0, 1, -1, 0], [3, 1, -1, 3]] . list로 선언된 A를 np.matrix로 변환 . Amat=np.matrix(A) . Amat . matrix([[ 1, 2, 3, 4], [ 2, 2, 1, 0], [ 0, 1, -1, 0], [ 3, 1, -1, 3]]) . 변환된 매트릭스의 역행렬을 구함. . Amat.I . matrix([[-0.15789474, 0.26315789, -0.42105263, 0.21052632], [ 0.10526316, 0.15789474, 0.61403509, -0.14035088], [ 0.10526316, 0.15789474, -0.38596491, -0.14035088], [ 0.15789474, -0.26315789, 0.0877193 , 0.12280702]]) . b=[1,9,4,7] . bvec=np.matrix(b) . bvec . matrix([[1, 9, 4, 7]]) . bvec은 $1 times 4$ 매트릭스가 된 셈. . 그런데 우리가 원한것은 $4 times 1$ 매트릭스였음. . bvec=bvec.T bvec . matrix([[1], [9], [4], [7]]) . Amat.I*bvec . matrix([[ 2.], [ 3.], [-1.], [-1.]]) . $ begin{bmatrix} w x y z end{bmatrix}= begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix}^{-1} begin{bmatrix} 1 9 4 7 end{bmatrix}= begin{bmatrix} 2 3 -1 -1 end{bmatrix}$ . 따라서 $w=2, x=3, y=-1,z=-1$가 된다. . . [$ ast$] &#48176;&#50676; vs &#54665;&#47148; (np.array vs np.matrix) . 아래의 문제를 다시 살펴보자. . $ begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 2 &amp; 2 &amp; 1 &amp; 0 0 &amp; 1 &amp;-1 &amp; 0 3 &amp; 1 &amp;-1 &amp; 3 end{bmatrix} begin{bmatrix} w x y z end{bmatrix}= begin{bmatrix} 1 9 4 7 end{bmatrix}$ . $(w,x,y,z)$를 풀기위해서는 . A=[[1,2,3,4],[2,2,1,0],[0,1,-1,0],[3,1,-1,3]] b=[1,9,4,7] Amat=np.matrix(A) bvec=np.matrix(b).T Amat.I * bvec . matrix([[ 2.], [ 3.], [-1.], [-1.]]) . 그런데 아래처럼 구해도 괜찮다. . A=[[1,2,3,4],[2,2,1,0],[0,1,-1,0],[3,1,-1,3]] b=[1,9,4,7] Aarr=np.array(A) barr=np.array(b) np.linalg.inv(Aarr) @barr # @는 연산자 . array([ 2., 3., -1., -1.]) . np.linalg.inv()가 통째로 역행렬을 구하는 함수다. . from numpy.linalg import inv A=[[1,2,3,4],[2,2,1,0],[0,1,-1,0],[3,1,-1,3]] b=[1,9,4,7] Aarr=np.array(A) barr=np.array(b) inv(Aarr) @ barr # 함수이름이 너무 길어서 줄여봤음 . array([ 2., 3., -1., -1.]) . 왜 np.matrix를 썼는가? . 행렬곱 | 역행렬계산 | . np.matrix가 진짜 편할까? . [불만1] 1차원자료형에 np.matrix를 쓰는게 이상하다. . barr.shape . (4,) . bvec.shape . (4, 1) . 이럴꺼면 굳이 1차원 자료형인 np.array를 왜 만드는지? . np.matrix([1,2,3])+np.matrix([4,5,6]) . matrix([[5, 7, 9]]) . [불만2] 3차원 자료가 있다면 어떻게 표현할래? $ to$ 확장성이 부족함 . B=[[[1,2],[2,3],[3,4]],[[3,2],[2,2],[4,1]]] . np.array(B)+100 . array([[[101, 102], [102, 103], [103, 104]], [[103, 102], [102, 102], [104, 101]]]) . np.matrix(B)+100 . ValueError Traceback (most recent call last) &lt;ipython-input-18-96c758f88605&gt; in &lt;module&gt; -&gt; 1 np.matrix(B)+100 ~/anaconda3/envs/py38r40/lib/python3.8/site-packages/numpy/matrixlib/defmatrix.py in __new__(subtype, data, dtype, copy) 147 shape = arr.shape 148 if (ndim &gt; 2): --&gt; 149 raise ValueError(&#34;matrix must be 2-dimensional&#34;) 150 elif ndim == 0: 151 shape = (1, 1) ValueError: matrix must be 2-dimensional . [불만3] np.array, np.matrix가 같이 있으면 혼란이 생긴다. col-vector, row-vector를 굳이 구분하고 싶지 않다. . 내적: $b= begin{bmatrix} 1 2 3 end{bmatrix}$라는 벡터가 있다고 하자. . 벡터의 크기의 제곱: $1^2+2^2+3^2$ . 벡터의 크기: $ sqrt{1^2+2^2+3^2}$ . b=[1,2,3] . np.array(b)@np.array(b) . 14 . $b= begin{bmatrix} 1 2 3 end{bmatrix}$, $b^T=[1,2,3]$ . $b^T b=[1,2,3] begin{bmatrix} 1 2 3 end{bmatrix}=1^2+2^2+3^2=14$ . $b b^T= begin{bmatrix} 1 2 3 end{bmatrix}[1,2,3]= begin{bmatrix}1 &amp; 2 &amp; 3 2 &amp; 4 &amp; 6 3 &amp; 6 &amp; 9 end{bmatrix}$ . b1=np.array(b) b2=np.matrix(b).T b1 . array([1, 2, 3]) . b2 . matrix([[1], [2], [3]]) . print(b2.T*b2) #... (1) print(b2*b2.T) #... (2) #print(b2*b2) ... (3) #print(b2.T*b2.T) ... (4) . [[14]] [[1 2 3] [2 4 6] [3 6 9]] . (1)~(4) 중에 무엇이 맞는 수식인지 따지고 싶지 않다. . b1@b1 #...(1) b1@b1.T #...(2) b1.T@b1 #...(3) b1.T@b1.T #...(4) . 14 . A=np.array([[1,0],[0,1]]) . A . array([[1, 0], [0, 1]]) . b=np.matrix([200,300]).T . A*b . matrix([[200], [300]]) . b*A # 위치를 바꿀 때 마다 형태를 변형해줘야 하는 불편함이 있음 . ValueError Traceback (most recent call last) &lt;ipython-input-36-865294475ca9&gt; in &lt;module&gt; -&gt; 1 b*A # 위치를 바꿀 때 마다 형태를 변형해줘야 하는 불편함이 있음 ~/anaconda3/envs/py38r40/lib/python3.8/site-packages/numpy/matrixlib/defmatrix.py in __mul__(self, other) 216 if isinstance(other, (N.ndarray, list, tuple)) : 217 # This promotes 1-D vectors to row vectors --&gt; 218 return N.dot(self, asmatrix(other)) 219 if isscalar(other) or not hasattr(other, &#39;__rmul__&#39;) : 220 return N.dot(self, other) &lt;__array_function__ internals&gt; in dot(*args, **kwargs) ValueError: shapes (2,1) and (2,2) not aligned: 1 (dim 1) != 2 (dim 0) . (3) &#51064;&#45937;&#49905; (&#49836;&#46972;&#51060;&#49905; &#54252;&#54632;) . A=np.array([[11,12,13,14,15],[21,22,23,24,25],[31,32,33,34,35]]) . A . array([[11, 12, 13, 14, 15], [21, 22, 23, 24, 25], [31, 32, 33, 34, 35]]) . [예제1] (3,1)에 접근하여 보자! . (방법1) . A[2] . array([31, 32, 33, 34, 35]) . A[2][0] . 31 . (방법2) . A[2,0] # list와의 차이점 : List에서는 불가능한 문법! . 31 . [예제2] 3행에 접근해보자. . (방법1) . A[2] . array([31, 32, 33, 34, 35]) . (방법2) . A[2,0:5] . array([31, 32, 33, 34, 35]) . (방법3) . A[2,:] . array([31, 32, 33, 34, 35]) . [예제3] 2열에 접근하여 보자. . (방법1) . A[:,1] . array([12, 22, 32]) . (?) 아래가 더 읽기 편하지 않나? . Amat=np.matrix(A) Amat[:,1] . matrix([[12], [22], [32]]) . (방법2) . A.T[1] . array([12, 22, 32]) . [예제4] 1행중에서 1,3,5열에 접근해보자. . (방법1) . A[0,[0,2,4]] . array([11, 13, 15]) . (방법2) . A[0][[0,2,4]] # 가로의 개수를 유지한다고 이해하자 . array([11, 13, 15]) . (방법3) . b=[0,2,4] . A[0][b] . array([11, 13, 15]) . (방법4) . A[0,b] . array([11, 13, 15]) . [예제5] (1,1),(1,2), (2,1),(2,2) 에 접근하자. . (방법1) . A . array([[11, 12, 13, 14, 15], [21, 22, 23, 24, 25], [31, 32, 33, 34, 35]]) . A[0:2,0:2] . array([[11, 12], [21, 22]]) . (방법2) . a=[0,1] b=[0,1] A[a,b] #(0,0), (1,1)이 뽑힌다 . array([11, 22]) . ??? 우리가 원하는게 아니다. . 깨달음! . # A[0,1] # A[1,0] # A[1,1] # * mac : cmd + / # * win : ctrl + / a=[0,0,1,1] b=[0,1,0,1] A[a,b] . array([11, 12, 21, 22]) . (방법3) . a=[0,1] b=[0,1] A[np.ix_(a,b)] . array([[11, 12], [21, 22]]) . np.ix_(a,b) . (array([[0], [1]]), array([[0, 1]])) . [예제6] . 홀수행, 짝수열을 뽑아보자. . 즉 12,32 14,34 가 뽑혀야함 . (방법1) . # A[2,1] # A[0,3] # A[2,3] . a=[0,2,0,2] b=[1,1,3,3] A[a,b] . array([12, 32, 14, 34]) . (방법2) . a=[0,2] # 1,3 행 ==&gt; 홀수행 b=[1,3] # 2,4 열 ==&gt; 짝수열 A[np.ix_(a,b)] . array([[12, 14], [32, 34]]) . [예제7] . 2행의 원소중 23보다 작은 원소만? . (방법1) . b=[0,1] A[1,b] . array([21, 22]) . 하지만 변수가 너무 많을 때는 위와 같이 계산하기당연히 어려움! . (방법2) . 아래를 관찰해보자. . c=np.random.normal(size=100) # np.random.normal(size=100)는 표준정규분포에서 100개의 난수를 생성하는 함수 . c&gt;0 #값이 아닌 T/F 결과를 보임 . array([False, True, True, False, False, True, False, True, True, False, True, False, True, False, True, True, False, True, True, False, True, False, True, True, True, True, False, True, True, False, False, False, True, False, True, False, False, False, False, False, False, False, True, False, False, True, True, False, False, True, False, False, False, True, True, True, True, True, False, False, True, False, True, True, False, True, False, True, False, True, True, True, False, True, True, True, False, False, True, False, False, True, False, True, True, False, True, False, True, True, True, True, False, False, True, False, False, True, True, True]) . c[c&gt;0] #boolIndexing-&gt;boolidx=c&gt;0 . array([0.18334984, 1.77051668, 2.01871979, 0.6618022 , 1.74088515, 0.67924512, 1.70566946, 0.92208578, 0.77595505, 0.30874189, 0.20613993, 0.0989423 , 0.89911795, 1.13985843, 1.21816941, 0.59673282, 0.13421594, 0.55343815, 1.55277558, 0.79995855, 1.43034953, 0.20047832, 1.4323895 , 0.78760893, 0.17690282, 0.75236525, 0.65544468, 1.28156261, 0.89955209, 0.87889443, 0.71509936, 0.12608794, 0.86428365, 0.45614107, 1.26244921, 0.14842187, 0.43357188, 1.03829107, 1.62379303, 0.91060634, 1.72900937, 0.52411524, 1.63818633, 0.34336474, 1.27008304, 0.32455862, 1.13402706, 1.43419411, 1.05120423, 0.02377782, 0.19521262, 1.73405291, 0.39269412]) . 이제 응용해보자. . # c&gt;0 --&gt; A[1]&lt;23 # c[c&gt;0]는 그러면 A[1][A[1]&lt;23] . array([21, 22]) . (방법3) . A[1,:][A[1,:]&lt;23] . array([21, 22]) . [$ ast$] &#51064;&#45937;&#49905;&#51032; &#51333;&#47448; ($ star star star$) . 기본인덱싱: 인덱스, 슬라이싱을 활용 예1: A[1,1] | 예2: A[1,0:2] | . | 팬시인덱싱(응용인덱싱): 인덱스를 정수배열로 전달, np.ix_함수를 활용한 인덱싱, 부울값 인덱싱 예1: A[0,[0,2,4]] , 정수배열 인덱싱 | 예2: A[np.ix_(a,b)] , np.ix함수를 활용한 인덱싱 | 예3: c[c&gt;0] , 부울값인덱싱 | . | (4) numpy&#47484; &#48176;&#50864;&#45716; &#48169;&#48277; . 인터넷+자동완성+contextual help 도움말을 보고 싶으면 ex)np.reshape ? 를 해도 볼 수 있다 . [$ ast$] 자동완성이 안되면 콘다환경에서 아래를 실행해볼것. . pip install &quot;jedi==0.17.2&quot; . a=np.array([1,2,3,2]) . np.amax(a) . 3 . np.reshape(a, [2,2]) # 행렬형태로 변환 가능함 . array([[1, 2], [3, 2]]) . a=np.array([[1,2,3], [4,5,6]]) a . array([[1, 2, 3], [4, 5, 6]]) . np.reshape(a, (3,2)) . array([[1, 2], [3, 4], [5, 6]]) .",
            "url": "https://kimha02.github.io/ham/python/2021/07/16/python-3.html",
            "relUrl": "/python/2021/07/16/python-3.html",
            "date": " • Jul 16, 2021"
        }
        
    
  
    
        ,"post39": {
            "title": "(공부) 파이썬 객체 소개_1차원 자료형",
            "content": "1&#52264;&#50896;&#51088;&#47308;&#54805; . (1) str . a=&#39;hayoung&#39; . a . &#39;hayoung&#39; . a=&#39;X&#39; b=&#39;2&#39; #2라는 문자 자체 . a+b #2문자가 합쳐진 모습으로 결과 도출 . &#39;X2&#39; . a-b #str에는 - 타입의 연산이 없음 . TypeError Traceback (most recent call last) &lt;ipython-input-75-a5eca377074f&gt; in &lt;module&gt; -&gt; 1 a-b #str에는 - 타입의 연산이 없음 TypeError: unsupported operand type(s) for -: &#39;str&#39; and &#39;str&#39; . a*b # a랑 b랑 곱해볼까? 곱도 안 된다! . TypeError Traceback (most recent call last) &lt;ipython-input-76-231357718326&gt; in &lt;module&gt; -&gt; 1 a*b # a랑 b랑 곱해볼까? 곱도 안 된다! TypeError: can&#39;t multiply sequence by non-int of type &#39;str&#39; . a*3 # a*3=a+a+a 이니까? . &#39;XXX&#39; . a=&#39;hayoung&#39; . a . &#39;hayoung&#39; . h a y o u n g . 0 | 1 | 2 | 3 | 4 | 5 | 6 | . 0 | -6 | -5 | -4 | -3 | -2 | -1 | . - 위 표를 통해 순서를 확인할 수 있다 . a[0] . &#39;h&#39; . a[0:3] # 0,1,2,3 의 인덱스가 아니라 0,1,2 . &#39;hay&#39; . a[1:3] # index 1부터시작해서 (3-1)개만큼 반환 . &#39;ay&#39; . a[:3] # =a[0:3] . &#39;hay&#39; . a[3:7] # =a[3:] . &#39;oung&#39; . a[1:-4] . &#39;ay&#39; . a[0:-6] . &#39;h&#39; . [$ ast$] 0&#52264;&#50896; vs 1&#52264;&#50896; . a=3.144 . len(a) #Int는 길이가 없음 . TypeError Traceback (most recent call last) &lt;ipython-input-16-d3d2954597f2&gt; in &lt;module&gt; -&gt; 1 len(a) #Int는 길이가 없음 TypeError: object of type &#39;float&#39; has no len() . a=&#39;3.144&#39; . len(a) #.도 포함되네! . 5 . a=&#39;1&#39; . len(a) . 1 . a=1 . len(a) . TypeError Traceback (most recent call last) &lt;ipython-input-121-1a2e6ec5f1e3&gt; in &lt;module&gt; -&gt; 1 len(a) TypeError: object of type &#39;int&#39; has no len() . a=&#39;hayoung&#39; . len(a) . 7 . . (2) list . - 자료를 추가 및 삭제할 때 편리함 . a=[11,22] . a . [11, 22] . b=[12,13] . $a=(11,12)$ . $b=(12,13)$ . $a+b=(23,25)$ . a+b . [11, 22, 12, 13] . a-b #연산 불가 . TypeError Traceback (most recent call last) &lt;ipython-input-129-5ae0619f8fe1&gt; in &lt;module&gt; -&gt; 1 a-b TypeError: unsupported operand type(s) for -: &#39;list&#39; and &#39;list&#39; . 2*a # a+a . [11, 22, 11, 22] . a+[33]+[345] #추가 . [11, 22, 33, 345] . c=[11,222,333] . c[0]+c[1] #c에서 0(1번째), 1(2번째)를 합하라 . 233 . list끼리는 수치적연산이 되지 않지만 list의 원소끼리는 수치연산이 가능할 수도 있음. . c1=11 c2=222 c3=333 . c=[c1,c2,c3] . c1+c2 # c[0]+c[1] . 233 . [$ ast$] list&#51032; &#50896;&#49548;&#45716; &#44845; &#49707;&#51088;&#54805;&#47564; &#44032;&#45733;&#54620; &#44163;&#51060; &#50500;&#45768;&#45796;. . list1=[1,3.14,True,&#39;a&#39;,[1,2],(1,2), {&#39;name&#39;:&#39;guebin&#39;,&#39;age&#39;:38},{1,2,3}] . l0=list1[0] l1=list1[1] l2=list1[2] l3=list1[3] l4=list1[4] l5=list1[5] l6=list1[6] l7=list1[7] . list2=[list1,3.14] . list2 . [[1, 3.14, True, &#39;a&#39;, [1, 2], (1, 2), {&#39;name&#39;: &#39;guebin&#39;, &#39;age&#39;: 38}, {1, 2, 3}], 3.14] . list2[1] . 3.14 . [$ ast$] &#47532;&#49828;&#53944; &#50896;&#49548; &#49688;&#51221; . - 스트링(str)에서는 원소 수정이 잘 되지 않음. . a=&#39;hayoung&#39; . a[0]=&#39;&#39; . TypeError Traceback (most recent call last) &lt;ipython-input-2-5690b0c929d5&gt; in &lt;module&gt; -&gt; 1 a[0]=&#39;&#39; TypeError: &#39;str&#39; object does not support item assignment . - 리스트형은 바꿀 수 있다. . alist=list(a) #각 글자를 원소화 . alist . [&#39;h&#39;, &#39;a&#39;, &#39;y&#39;, &#39;o&#39;, &#39;u&#39;, &#39;n&#39;, &#39;g&#39;] . alist[0] . &#39;h&#39; . alist[0]=&#39;H&#39; . alist . [&#39;H&#39;, &#39;a&#39;, &#39;y&#39;, &#39;o&#39;, &#39;u&#39;, &#39;n&#39;, &#39;g&#39;] . [$ ast$] &#47532;&#49828;&#53944; &#50896;&#49548; &#49325;&#51228; . alist . [&#39;H&#39;, &#39;a&#39;, &#39;y&#39;, &#39;o&#39;, &#39;u&#39;, &#39;n&#39;, &#39;g&#39;] . del alist[0] . alist . [&#39;a&#39;, &#39;y&#39;, &#39;o&#39;, &#39;u&#39;, &#39;n&#39;, &#39;g&#39;] . alist2=list(a) . alist2 . [&#39;h&#39;, &#39;a&#39;, &#39;y&#39;, &#39;o&#39;, &#39;u&#39;, &#39;n&#39;, &#39;g&#39;] . alist2=alist2[1:7] . alist2 . [&#39;a&#39;, &#39;y&#39;, &#39;o&#39;, &#39;u&#39;, &#39;n&#39;, &#39;g&#39;] . [$ ast$] &#47532;&#49828;&#53944; &#50896;&#49548; &#52628;&#44032; . a=[1,2,3] . a.append(4) . a . [1, 2, 3, 4] . a.append([4,5]) . a . [1, 2, 3, 4, [4, 5]] . a+[4,5] . [1, 2, 3, 4, [4, 5], 4, 5] . +연산자로 추가하는것과 .append 메소드로 추가하는 것의 차이점 . a=[1,2,3] . a.append(4) . a . [1, 2, 3, 4] . a1=[1,2,3] . a1+[4] . [1, 2, 3, 4] . a1 . [1, 2, 3] . a.append(4): a를 append하라. $ rightarrow$ a가 변함. . a+[4]: a와 [4]를 add하라. 기존 a는 변화 없음 . [$ ast$] &#47532;&#49828;&#53944;&#52980;&#54532;&#47532;&#54760;&#49496; ($ star star star$) . [예비학습]for문 벼락치기 . 프로그램 안에서 반복해서 무엇인가를 하고싶다? $ rightarrow$ for . for i in [0,1,2,3]: ## 반복실행계획 print(i) ## 반복실행내용 . 0 1 2 3 . i=0 print(i) i=1 print(i) i=2 print(i) i=3 print(i) . 0 1 2 3 . sumi=0 for i in [0,1,2,4]: ## 반복실행계획 sumi=sumi+i . sumi . 7 . sumi=0 i=0 sumi=sumi+i # 0+0 i=1 sumi=sumi+i # 0+1 i=2 sumi=sumi+i # 1+2 i=4 sumi=sumi+i # 3+4 . sumi . 7 . 예비학습 끝! . . [예제] $2^0,2^1,2^2,2^3,2^4,2^5$를 계산해보자. . (풀이1) - 진짜 나쁜코드 : 확장성이 부족함 . x=[2**0,2**1,2**2,2**3,2**4,2**5] . x . [1, 2, 4, 8, 16, 32] . (풀이2) - 그럭저럭 괜찮은 코드; for문을 이용했음. (버전1) . x=[] for i in [0,1,2,3,4,5]: x.append(2**i) . x . [1, 2, 4, 8, 16, 32] . (풀이2) - 그럭저럭 괜찮은 코드; for문을 이용했음. (버전2) . x=[] for i in [0,1,2,3,4,5]: x=x+[2**i] . x . [1, 2, 4, 8, 16, 32] . (풀이2) - 그럭저럭 괜찮은 코드; for문을 이용했음. (버전3) . x=[] for i in [0,1,2,3,4,5]: x+=[2**i] ### 암기법: x=x+[2**i] 에서 중복되는것을 제거하고 순서를 바꾼다... . x . [1, 2, 4, 8, 16, 32] . (풀이3) - 좋은 풀이; 리스트컴프리헨션을 이용 . x=[2**i for i in [0,1,2,3,4,5]] . x . [1, 2, 4, 8, 16, 32] . 문법을 암기하는 방법 . 조건제시법을 연상하라. | $ big {2^0,2^1,2^2,2^3,2^4,2^5 big }= big {2^i: i=0,1, dots, 5 big }$ | . 리스트 컴프리헨션 . 리스트를 매우 효율적으로 만드는 테크닉 | for문에 비하여 가지고 있는 장점: (1) 코드가 간단하다. (2) 빠르다. | . [예제] 리스트 컴프리핸션을 이용하여 아래와 같은 리스트를 만들어라. . [&#39;SSSS&#39;,&#39;PPPP&#39;,&#39;AAAA&#39;,&#39;MMMM&#39;] . [&#39;SSSS&#39;, &#39;PPPP&#39;, &#39;AAAA&#39;, &#39;MMMM&#39;] . (풀이) . [i*4 for i in &#39;SPAM&#39;] . [&#39;SSSS&#39;, &#39;PPPP&#39;, &#39;AAAA&#39;, &#39;MMMM&#39;] . [예제] 리스트 컴프리헨션을 이용하여 아래와 같은 리스트를 만들어라. . [&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;,&#39;Y1&#39;,&#39;Y2&#39;,&#39;Y3&#39;] . [&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;Y1&#39;, &#39;Y2&#39;, &#39;Y3&#39;] . (풀이) . [i+j for i in &#39;XY&#39; for j in &#39;123&#39;] . [&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;Y1&#39;, &#39;Y2&#39;, &#39;Y3&#39;] . for i in [&#39;X&#39;,&#39;Y&#39;]: for j in &#39;123&#39;: print(i+j) . X1 X2 X3 Y1 Y2 Y3 . [$ ast$] &#47532;&#49828;&#53944;&#51032; &#51473;&#52393; ($ star star star$) . a=[[11,12,13], [21,22,23], [31,32,33]] . 0 1 2 . 0 | 11 | 12 | 13 | . 1 | 21 | 22 | 23 | . 2 | 31 | 32 | 33 | . a[0][0] . 11 . a[0][1] #0번열1번행 . 12 . . (3) tuple . - 리스트와 비슷하다. . 차이점1 : [ ] 대신에 ( )를 사용한다. . 차이점2 : 불변형이다. (값을 바꿀 수 없음) . a=(4,6,&quot;pencil&quot;,3.2+4.6j,[3,4]) . a[2] . &#39;pencil&#39; . a[0:3] . (4, 6, &#39;pencil&#39;) . a[2]=&quot;Pencil&quot; . TypeError Traceback (most recent call last) &lt;ipython-input-12-5ea264dc9819&gt; in &lt;module&gt; -&gt; 1 a[2]=&#34;Pencil&#34; TypeError: &#39;tuple&#39; object does not support item assignment . 참고로 리스트는 값이 잘 바뀜 . a=[4,6,&quot;pencil&quot;,3.2+4.6j,[3,4]] #리스트형 . a . [4, 6, &#39;pencil&#39;, (3.2+4.6j), [3, 4]] . a[2]=&quot;PENCIL&quot; . a . [4, 6, &#39;PENCIL&#39;, (3.2+4.6j), [3, 4]] . 차이점3 : 하나의 원소로 이루어진 튜플을 만들때는 쉼표를 붙여야 함. 쉼표를 넣지 않으면 int형으로 인식되어 +(더한) 값이 나온다. . a=[1] . a+[2] . [1, 2] . a=(1,) . a+(2,) . (1, 2) . 차이점4 : (의미가 명확할때) 튜플의 괄호는 생략가능하다. 의미가 명확할때 생략해야 한다! . a=1,2 . a . (1, 2) . 1,2 + 3,4,5 #2+3=5로 생각 . (1, 5, 4, 5) . (1,2) + (3,4,5) . (1, 2, 3, 4, 5) . 의문 튜플은 왜 쓰는가? . 튜플의 특징: 불변성$ rightarrow$ 실수로 값을 변경하지 않도록 방지할 수 있다? . [$ ast$] &#53916;&#54540;&#51008; &#45800;&#49692;&#55176; &#48520;&#48320;&#47532;&#49828;&#53944;&#44032; &#50500;&#45768;&#45796;. ($ star star star$) . [예제1]: 튜플언패킹 . name,age,sex,height,weight = &#39;Tom&#39;,20,&#39;M&#39;,180,70 . name . &#39;Tom&#39; . weight . 70 . [예제2] . coor=(33.9425,-118.408056) . coor . (33.9425, -118.408056) . lat, long = coor . lat . 33.9425 . long . -118.408056 . [예제3]: 임시변수 사용없이 두 변수의 값을 교환 . a=10 b=20 . a,b=b,a #실행순서가 오른쪽 임시 생성-&gt;왼쪽 적용 . a . 20 . b . 10 . [예제4]: 함수의 입력으로 튜플을 넣을때 . [예제4의 예비학습] 함수 벼락치기 . def cal(a,b): # def=함수선언, cal=함수이름 print(str(a) + &#39;+&#39; + str(b) + &#39;=&#39; + str(a+b)) print(str(a) + &#39;-&#39; + str(b) + &#39;=&#39; + str(a-b)) print(str(a) + &#39;*&#39; + str(b) + &#39;=&#39; + str(a*b)) print(str(a) + &#39;/&#39; + str(b) + &#39;=&#39; + str(a/b)) . cal(2,33) . 2+33=35 2-33=-31 2*33=66 2/33=0.06060606060606061 . input=[3,4] cal(input) . TypeError Traceback (most recent call last) &lt;ipython-input-38-da3b95adc570&gt; in &lt;module&gt; 1 ### 우리가 원하는 형태 : 알아서 인수를 분해해 계산해줬으면 좋겠지만... 2 input=[3,4] -&gt; 3 cal(input) TypeError: cal() missing 1 required positional argument: &#39;b&#39; . cal(input[0],input[1]) . 3+4=7 3-4=-1 3*4=12 3/4=0.75 . input=(3,4) . cal(*input) # *를 추가하면 튜플 언패킹 가능! . 3+4=7 3-4=-1 3*4=12 3/4=0.75 . [예제5] 함수의 입력을 튜플로 넣을때 (2) . 두점 사이의 거리를 구하는 함수를 만들어 보자. . $x=(x_1,x_2,x_3)$ . $y=(y_1,y_2,y_3)$ . 의 거리를 구하려면 . $ sqrt{(x_1-y_1)^2+(x_2-y_2)^2+(x_3-y_3)^2}$ . def distance(x1,x2,x3,y1,y2,y3): import math #라이브러리 부르고 d=(x1-y1)**2+(x2-y2)**2+(x3-y3)**2 #루트 아레 식 print(math.sqrt(d)) #math로 루트 계산 . x=(0,0,0) y=(0,1,1) distance(*x,*y) . 1.4142135623730951 . def distance(x,y): import math x1,x2,x3=x y1,y2,y3=y d=(x1-y1)**2+(x2-y2)**2+(x3-y3)**2 print(math.sqrt(d)) . distance(x,y) . 1.4142135623730951 . !!! &#54632;&#49688;&#47484; &#54840;&#52636;&#54624;&#46412; &#51064;&#49688;&#50526;&#50640; *&#47484; &#48537;&#50668; &#53916;&#54540;&#51012; &#50616;&#54056;&#53433;&#54624; &#49688; &#51080;&#45796;. . [예제6]: 플레이스홀더 . (예비학습) for문 . for i in [1,2,3,4]: print(i) . 1 2 3 4 . i=[1,2,3,4][0] print(i) i=[1,2,3,4][1] print(i) i=[1,2,3,4][2] print(i) i=[1,2,3,4][3] print(i) . 1 2 3 4 . for i in [1,2,3,[1,2,3]]: print(i) . 1 2 3 [1, 2, 3] . i=[1,2,3,[1,2,3]][0] print(i) i=[1,2,3,[1,2,3]][1] print(i) i=[1,2,3,[1,2,3]][2] print(i) i=[1,2,3,[1,2,3]][3] print(i) . 1 2 3 [1, 2, 3] . for i in [[1,22],[1,3],[2,14],[7,23]]: print(i) . [1, 22] [1, 3] [2, 14] [7, 23] . for i,j in [[1,22],[1,3],[2,14],[7,23]]: print(i) . 1 1 2 7 . i,j=[[1,22],[1,3],[2,14],[7,23]][0] print(i) i,j=[[1,22],[1,3],[2,14],[7,23]][1] print(i) i,j=[[1,22],[1,3],[2,14],[7,23]][2] print(i) i,j=[[1,22],[1,3],[2,14],[7,23]][3] print(i) . 1 1 2 7 . 예제시작 . idlist=[(&#39;guebin&#39;, &#39;202112345&#39;,&#39;M&#39;,&#39;Korea&#39;), (&#39;iu&#39;, &#39;202154321&#39;,&#39;F&#39;,&#39;Korea&#39;), (&#39;hodong&#39;, &#39;201812321&#39;,&#39;M&#39;,&#39;Korea&#39;)] . for i in idlist: print(i) . (&#39;guebin&#39;, &#39;202112345&#39;, &#39;M&#39;, &#39;Korea&#39;) (&#39;iu&#39;, &#39;202154321&#39;, &#39;F&#39;, &#39;Korea&#39;) (&#39;hodong&#39;, &#39;201812321&#39;, &#39;M&#39;, &#39;Korea&#39;) . for name,studentid,sex,nat in idlist: print(name) . guebin iu hodong . for name, _, _, _ in idlist: # 관심있는 것만 이름을 지정해주고 싶을 때 언더바 처리 print(name) . guebin iu hodong . &#50836;&#50557; . (1) 스트링, 튜플, 리스트는 모두 시퀀스형이라고 부른다. . (2) 시컨스형의 카테고리 . 컨테이너 시퀀스: list, tuple. | 균일(flat) 시퀀스: str | 가변 시퀀스: list | 불면 시퀀스: tuple, str | . 컨테이너 시퀀스 flat 시퀀스 . 가변 시퀀스 | list | - | . 불변 시퀀스 | tuple | str | . (3) 시퀀스형은 모두 인덱싱과 슬라이싱이 가능함. . a=1,2,3,4 . a . (1, 2, 3, 4) . a[0:3] . (1, 2, 3) . . (4) set . A={&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;} #집합 . A . {&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;} . B={&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;} . A.union(B) # union : 합집합, 중복원소는 제거 . {&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;} . A|B # 요것도 합집합 . {&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;} . A+B # 리스트처럼 +로 합집합이 되지 않음 . TypeError Traceback (most recent call last) &lt;ipython-input-62-f9b5070b2bad&gt; in &lt;module&gt; -&gt; 1 A+B # +로 합집합이 되지 않음 TypeError: unsupported operand type(s) for +: &#39;set&#39; and &#39;set&#39; . A.intersection(B) #교집합 . {&#39;c&#39;, &#39;d&#39;} . A*B # *로 교집합이 되지 않음 . TypeError Traceback (most recent call last) &lt;ipython-input-8-47896efed660&gt; in &lt;module&gt; -&gt; 1 A*B TypeError: unsupported operand type(s) for *: &#39;set&#39; and &#39;set&#39; . A &amp; B # 요것도 교집합 가능 . {&#39;c&#39;, &#39;d&#39;} . A.difference(B) # 차집합 . {&#39;a&#39;, &#39;b&#39;} . A-B # 리스트에서 가능하지 않았던 - 로 차집합 가능 . {&#39;a&#39;, &#39;b&#39;} . a=set(&#39;hello&#39;) . a . {&#39;e&#39;, &#39;h&#39;, &#39;l&#39;, &#39;o&#39;} . for i in a: print(i) . e h l o . 순서가 좀 이상하다 $ to$ 집합은 원래 순서가 없다. $ to$ 인덱싱이 불가능하다. $ to$ 슬라이싱도 불가능 . a[0] . TypeError Traceback (most recent call last) &lt;ipython-input-72-6a1284577a36&gt; in &lt;module&gt; -&gt; 1 a[0] TypeError: &#39;set&#39; object is not subscriptable . 집합 컴프리헨션 . C={2**x for x in [1,2,3,4]} #2^1, 2^2... . C . {2, 4, 8, 16} . . (5) dict . 사전 . boy: 소년 | girl: 소녀 | . girl 을 찾음 $ to$ 소녀 . mydict={&#39;a&#39;:[1,2,3],&#39;b&#39;:[3,4,5]} #집합형으로 선언 . mydict[&#39;a&#39;] . [1, 2, 3] . mylist=[[1,2,3],[3,4,5]] . mylist[0] . [1, 2, 3] . mylist[1] . [3, 4, 5] . mydict[&#39;a&#39;] # index가 아닌 내가 설정한 key로 집합을 찾는다! . [1, 2, 3] . mydict[&#39;b&#39;] . [3, 4, 5] . mylist[0]+mylist[1] . [1, 2, 3, 3, 4, 5] . mydict[&#39;a&#39;]+mydict[&#39;b&#39;] . [1, 2, 3, 3, 4, 5] . mydict . {&#39;a&#39;: [1, 2, 3], &#39;b&#39;: [3, 4, 5]} . mydict[0] . KeyError Traceback (most recent call last) &lt;ipython-input-48-1529edbf7ad5&gt; in &lt;module&gt; -&gt; 1 mydict[0] KeyError: 0 . mydict[&#39;a&#39;:&#39;b&#39;] . TypeError Traceback (most recent call last) &lt;ipython-input-49-0cfefbf5c1da&gt; in &lt;module&gt; -&gt; 1 mydict[&#39;a&#39;:&#39;b&#39;] TypeError: unhashable type: &#39;slice&#39; . {&#39;a&#39;:(1,2,3),&#39;b&#39;:(3,4,5)} . {&#39;a&#39;: (1, 2, 3), &#39;b&#39;: (3, 4, 5)} . dict(([&#39;a&#39;,[1,2,3]],[&#39;b&#39;,[3,4,5]])) . {&#39;a&#39;: [1, 2, 3], &#39;b&#39;: [3, 4, 5]} . 딕셔너리 컴프리핸션 . X={x:x**2 for x in (1,2,3,4)} . X . {1: 1, 2: 4, 3: 9, 4: 16} . X[4] . 16 . 이거 인덱싱아니야? . 인덱싱은 아님 (하지만 마치 인덱싱처럼 보이기는 함) . X[-1] . KeyError Traceback (most recent call last) &lt;ipython-input-76-5864bf9e7d00&gt; in &lt;module&gt; -&gt; 1 X[-1] KeyError: -1 . X[2:5] . TypeError Traceback (most recent call last) &lt;ipython-input-77-14e849fefbc5&gt; in &lt;module&gt; -&gt; 1 X[2:5] TypeError: unhashable type: &#39;slice&#39; . mylist . [[1, 2, 3], [3, 4, 5]] . mylist=[1,2,3,4,5] . mylist[-2] . 4 . X[-1] . KeyError Traceback (most recent call last) &lt;ipython-input-85-5864bf9e7d00&gt; in &lt;module&gt; -&gt; 1 X[-1] KeyError: -1 .",
            "url": "https://kimha02.github.io/ham/python/2021/07/15/python-2.html",
            "relUrl": "/python/2021/07/15/python-2.html",
            "date": " • Jul 15, 2021"
        }
        
    
  
    
        ,"post40": {
            "title": "(노트) 우분투 포맷 및 개발용 서버 셋팅",
            "content": "[참고] 교수님께서 공유해주신 자료를 본인이 이해하기 쉽도록 (약간) 수정한 자료임. . About this doc . - 우분투에서 여러가지 개발환경을 설정하는 방법을 포스팅 하겠다. . - 이 포스트는 우분투를 메인OS(사무용+연구용)로 사용하고 싶은 사람, 우분투를 활용하여 개발용 서버를 구축하고 싶은 사람에게 모두 유용한다. . - 이 포스트는 2080 이상의 GPU를 활용한 학습을 원하는 사람에게 유용하다. . - 이 포스트는 R과 파이썬을 동시에 쓰는 사람에게 유용하다. . - 이 포스트는 Rstudio, Jupyter Lab을 동시에 쓰는 사람에게 유용하다. . - 매년 조금씩 셋팅방법이 다른것 같다. (버전 업데이트 시 유의하여 노트를 참고할 것!) . &#54620;&#44544;&#49444;&#51221; (&#44060;&#48156;&#50857; &#49436;&#48260;&#51068; &#44221;&#50864; &#49373;&#47029; &#44032;&#45733;) . - 아래와 같이 커맨드에 친다. . ibus-setup . 이걸 치면 IBus Preferences 라는 창이 나오는데. 여기에서 (1) Input Method 탭 클릭 (2) Add 버튼 클릭 (3) Korean 선택 (4) Hangul 선택을 한다. - 위의 단계에서 Korean이 안보이면 Language Support로 가서 한국어팩을 설치하고 리부팅 하면 된다. (보통 실행하자마자 알아서 설치되더라.. 설치가 안되면 Install / Remove Languages... 이라는 탭을 클릭해서 설치하자) 리부팅을 꼭 해야한다는 것에 주의하자. - 이제 Region &amp; Language로 가서 설정하면 된다. . &#44536;&#47000;&#54589;&#52852;&#46300; &#46300;&#46972;&#51060;&#48260;&#49444;&#52824; . - 전체적인 내용은 여기를 참고하자. . - 우선 gedit를 열고 아래를 복사해서 붙여넣는다. . blacklist nouveau options nouveau modeset=0 . - 파일이름을 blacklist-nouveau.conf로 home에 저장한다. 그 다음 ctrl+alt+F3을 눌러서 까만화면으로 간다. 아래입력한다. . sudo -i . (sudo는 window의 관리자권한 쯤으로 이해하면 편하다!) . - 아이디와 비밀번호를 입력하고 루트권한을 얻는다. 아래를 입력한다. . sudo cp /home/cgb2/blacklist-nouveau.conf /etc/modprobe.d sudo update-initramfs -u exit . - 재부팅을한다. . - 커맨드에서 아래를 실행하자. . sudo apt install gcc sudo apt install build-essential . - 그리고 드라이버 설치파일을 다운받는다. 앤비디아공식홈페이지에서 다운받자. OS를 리눅스 64-bit으로 선택하고 검색을 누르면 다운받아진다. 다운받은뒤에는 파일이 있는 폴더로 이동하여 . chmod +x NVIDIA-Linux-x86_64-410.78.run . 를 실행하자. 보통 NVI까지치고 적당히 탭을 누르면 알아서 뒷부분이 완성된다. 이 과정은 추후에 드라이버를 실행할수 있도록 권한을 풀어두는 것이다. . - 그리고 아래를 실행한다. . sudo ./NVIDIA-Linux-x86_64-410.78.run . - 그 다음 드라이버가 잘 설치되었는지 확인한다. . nvidia-smi . 표가 나온다면 정상적으로 드라이버가 설치되었다는 것이다! . &#50500;&#45208;&#53080;&#45796; . - (아나콘다 설치) 아나콘다를 다운받은 폴더로 가서 아래와 같이 실행한다. . bash Anaconda3-2019.03-Linux-x86_64.sh . 대충 bash Ana 정도까지만 치고 tab을 누르면 알아서 완성된다. . - (환경만들기) 커맨드를 키고 아래를 실행한다. . (base) conda create -n py38r40 python=3.8 (base) conda create --name py38r40 python=3.8 . 둘 중 아무거나 실행해도 된다. 파이썬 환경이 너무 높으면 나중에 conda tensorflow-gpu가 먹히지 않으니 환경을 만들때 파이썬버전을 3.8.x로 하자. (현시점 2021년 2월25일기준 3.9.x이면 conda tensorflow-gpu 가 동작하지 않음.) . ssh&#50672;&#44208; . - 처음에 ssh를 연결하기위해서는 연결당하는 컴퓨터에 가서 아래를 실행해야 한다. . sudo apt install openssh-server . &#51452;&#54588;&#53552; &#50896;&#44201;&#51228;&#50612; . 1&#45800;&#44228;: &#51452;&#54588;&#53552;&#47017;&#49444;&#52824; . - 콘다 가상환경에서 주피터랩을 설치한다. . (py38r40) conda install -c conda-forge jupyterlab . . Note: 사실 위에서 주피터랩을 따로 설치안해도 주피터랩이 잘만 실행된다. 하지만 이렇게하니까 나중에 R커널을 만들기위해 IRkernel::installspec()을 실행할때 에러가 난다. . 2&#45800;&#44228;: &#54056;&#49828;&#50892;&#46300; &#49444;&#51221; . - 주피터랩은 보통 로칼로 접속하는데 이를 원격으로 접속할 수 있게 만들어보자. 우선 커맨드에서 아래를 실행하자. . (py38r40) jupyter lab --generate-config (py38r40) jupyter lab password . 3&#45800;&#44228;: jupyter lab &#54872;&#44221;&#49444;&#51221; . - 이제 /home/cgb/.jupyter/jupyter_lab_config.py 파일을 연다. . - 아이피주소를 바꾼다. (port는 선택) . c.ServerApp.ip = &#39;192.168.0.4&#39; c.ServerApp.port = 1306 . 여기에서 192.168.0.4 는 내부아이피다. 고정아이피가 있다면 고정아이피 주소를 쓰면 된다. . CUDA, cuDNN, tensorflow, pytorch . - 콘다환경으로 가서아래를 실행한다. . (py38r40) conda install -c conda-forge tensorflow-gpu (py38r40) conda install -c conda-forge pytorch-gpu . . Note: conda에서 가장 오류가 적은 것을 찾아 설치한다 -&gt; conda-forge에서 가장 오류가 적은 것을 찾아 설치한다 (?) - 그러면 알아서 CUDA, cuDNN, tensorflow, pytorch 가 설치된다. . Note: 예전에는 CUDA, cuDNN을 따로 설치해야 했는데 세상이 좋아졌다. . &#51452;&#54588;&#53552;&#50752; R&#52964;&#45328; &#50672;&#44208; . - 콘다환경으로 가서 아래를 실행한다. . (py38r40) conda install -c conda-forge r-essentials=4.0 . 이러면 콘다환경에는 R이 깔리고 base에는 R이 깔리지 않는다. 그리고 콘다환경에서 R을 실행한다. Rstudio가 아니라 커맨드에서 R을 실행해야한다. - 그리고 IRkernel을 설치한다. . install.packages(&quot;IRkernel&quot;) . - 그리고 아래를 실행하면 주피터랩과 R환경이 연결된다. . IRkernel::installspec() . - 이제 주피터랩에서 R kernel을 사용할 수 있다. . Rstudio server . - 이제 Rstudio server를 설치하는 방법을 다룬다. . Warning: 보통은 (base)에 R을 깔고 그 R과 Rstudio를 연결한다. 즉 아나콘다 기본환경에 R을 설치하고 그것을 Rstudio와 연결한다. 하지만 아나콘다 기본환경에 R을 설치하면 가상환경에서 설치된 R과 호환이 되지 않아 여러가지로 복잡한 문제가 생긴다. (근본적으로 주피터에서 접속하는 R과 Rstudio에서 접속하는 R이 서로 달라지게 된다.) 이러한 문제를 방지하기 위해서 본 포스트에서는 아나콘다 가상환경에 직접 R을 설치하는 방법을 다루겠다. . - 먼저 Rstudio를 설치한다. 참고로 Rstudio server 설치하는법은 여기를 참고하라. 요약하면 터미널에서 아래3줄을 입력하기만 하면된다. . (py38r40) sudo apt-get install gdebi-core (py38r40) wget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.2.5033-amd64.deb (py38r40) sudo gdebi rstudio-server-1.2.5033-amd64.deb . . Warning: Rstudio 1.3x 이상을 설치하지말고 1.2x를 설치해야 한다. 이상하게 1.3x이상은 후에 서술할 Gregor Strurm가 그의 깃허브에서 제안하는 방식이 잘 동작하지 않았다. 이는 알려진 문제였고 이를 해결하는 해결책을 서술한 스레드가 있어보이긴 했지만 나는 그냥 Rstudio 1.2x를 설치하고 쓰는 것을 선택했다. . - 이제 Rstudio 설치가 끝났다. 설치된 Rstudio를 아나콘다 가상환경에 설치된 R과 연결해보자. 우선 아래를 실행한다. . (py38r40) sudo apt install uuid (py38r40) sudo apt install git (py38r40) git clone https://github.com/grst/rstudio-server-conda.git . 위에 두줄은 Gregor Sturm가 만든 어떤 프로그램을 쓰기 위한 사전준비작업이다. 마지막줄을 실행하면 Gregor Sturm가 만든 프로그램이 다운받아진다. 이게 프로그램 설치가 완료된것이다. 이제 컴퓨터 껐다 킬때마다 아래를 실행한다. . (py38r40) ./rstudio-server-conda/local/start_rstudio_server.sh 8787 # use any free port number here. . 이제 192.168.0.4:8787 따위의 주소로 접속하면 Rstudio를 쓸 수 있다. 참고로 system-wide Rstudio server를 죽여야 할 때가 있다. 그럴땐 아래 명령을 치면 된다. . (py38r40) sudo systemctl disable rstudio-server.service (py38r40) sudo systemctl stop rstudio-server.service . sublime text and TeX (&#44060;&#48156;&#50857; &#49436;&#48260;&#51068; &#44221;&#50864; &#49373;&#47029; &#44032;&#45733;) . - &#39;Ubuntu Software&#39;에 가서 &#39;sublime Text&#39;를 치면 다운받을 수 있다. 다운받은뒤에 &#39;file&#39; -&gt; &#39;open folder&#39;를 활용하여 깃허브의 로칼저장소를 열어두면 편리하다. . - 아래를 실행하여 TeX을 깐다. . sudo apt install texlive-full . - 이제 sublime과 latex을 연결하여보자. 여기를 참고하자. (1) sublime을 키고 &#39;Ctrl+Shift+p&#39;를 눌러 &#39;Install Package Control&#39; 선택 (2) 다시 &#39;Ctrl+Shift+p&#39; 를 눌러 &#39;Package Control: Install Package&#39;를 실행 (3) 그러면 바로 검색창이 나오는데 거기서 &#39;LaTeXTools&#39;를 입력해서 실행 (4) 다시 &#39;Ctrl+Shift+p&#39;를 누르고 &#39;LaTeXTools: Check system&#39; 선택. 모두 &#39;available&#39;이 나오면 잘 설치된 것이다. . - *.tex파일을 열고 &#39;Ctrl+b&#39;를 누르자. 처음이면 어떤 메뉴들이 보일텐데 그냥 &#39;Latex&#39;을 선택하자. 그러면 코딩결과가 pdf로 나온다. . - (수식미리보기) &#39;Perferences&#39; &gt; &#39;Packages Setting&#39; &gt; &#39;LaTeXTools&#39; &gt; &#39;Settings-User&#39;를 선택한다. &#39;93번째라인&#39;에 &#39;preview_math_mode&#39;를 &quot;all&quot;로 바꾼다. 그러면 수식들이 미리 출력된다. 그 외에도 자유롭게 셋팅을 조정할 수 있다. 원래 셋팅은 &#39;Perferences&#39; &gt; &#39;Packages Setting&#39; &gt; &#39;LaTeXTools&#39; &gt; &#39;Settings-Defaults&#39; 에 있다. .",
            "url": "https://kimha02.github.io/ham/%EC%9A%B0%EB%B6%84%ED%88%AC/2021/07/06/%EC%9A%B0%EB%B6%84%ED%88%AC-%ED%8F%AC%EB%A7%B7-%EB%B0%8F-%EA%B0%9C%EB%B0%9C%EC%9A%A9-%EC%84%9C%EB%B2%84-%EC%85%8B%ED%8C%85.html",
            "relUrl": "/%EC%9A%B0%EB%B6%84%ED%88%AC/2021/07/06/%EC%9A%B0%EB%B6%84%ED%88%AC-%ED%8F%AC%EB%A7%B7-%EB%B0%8F-%EA%B0%9C%EB%B0%9C%EC%9A%A9-%EC%84%9C%EB%B2%84-%EC%85%8B%ED%8C%85.html",
            "date": " • Jul 6, 2021"
        }
        
    
  
    
        ,"post41": {
            "title": "(공부) 파이썬 객체 소개_0차원 자료형",
            "content": "객체? . 본질적으로는 객체는 메모리 조각이다. | 파이썬에서는 모든것이 객체이다. (값, 연산, 함수, 클래스, 컴파일된 코드) 예를들면 숫자(99)도 객체이며, 파이썬이 제공하는 연산들(더하기, 빼기)도 객체이다. | . | 내장객체의 타입을 알아보자. | . 0&#52264;&#50896; &#51088;&#47308;&#54805; . (1) int&#54805; . a=333 . a . 333 . (2) float&#54805; . a=1.2*3 a . 3.5999999999999996 . (3) complex&#54805; . a=1+2j b=2-2j c=a+b . (4) bool&#54805; . a=True ## a=1로 생각해도 .. b=False ## b=0으로 생각해도 .. . [$ ast$] &#54805;&#53468;&#48320;&#54872; . a=3.6234 #float . b=int(a) #float-&gt;int 형태로 변환 . b . 3 . a=3 . a . 3 . float(a) #int-&gt;float 형태로 변환 . 3.0 . int(True) #bool-&gt;int 형태로 변환 . 1 . float(False) #bool-&gt;float 형태로 변환 . 0.0 . float(3+0j) #complex-&gt;float 불가 . TypeError Traceback (most recent call last) &lt;ipython-input-41-262acd6bef5b&gt; in &lt;module&gt; -&gt; 1 float(3+0j) #complex-&gt;float 불가 TypeError: can&#39;t convert complex to float . [$ ast$] math . pi #우리가 아는 파이(원주율)가 바로 나올까? A:안 나온다. . NameError Traceback (most recent call last) &lt;ipython-input-45-604074d5eb00&gt; in &lt;module&gt; -&gt; 1 pi #우리가 아는 파이(원주율)가 바로 나올까? A:안 나온다. NameError: name &#39;pi&#39; is not defined . import math math.pi #math패키지를 사용하면 바로 파이가 나온다. . 3.141592653589793 . math.e . 2.718281828459045 . math.sin(math.pi/2) #삼각함수 . 1.0 . math.sqrt(2) . 1.4142135623730951 . dir(math) #math 안에 있는 함수 확인 . math.??의 사용법을 아는 방법? | . math.sqrt . &lt;function math.sqrt(x, /)&gt; . (의문) math.에서 .을 왜 항상 붙이는가? . (요구) . 을 안붙이는 방법은 없을까? . from math import pi . pi . 3.141592653589793 . math.sin(pi/2) . 1.0 . from math import sin . sin(pi/2) . 1.0 . abs(1+1j) . 1.4142135623730951 . math.sqrt(2) . 1.4142135623730951 . [$ ast$] &#54028;&#51060;&#50028; &#48716;&#53944;&#51064;&#54632;&#49688; . 빌트인함수의 종류에 어떤것이 있는지 확인하는 방법? . https://docs.python.org/3.8/library/functions.html | . import builtins . .",
            "url": "https://kimha02.github.io/ham/python/2021/07/06/python-1.html",
            "relUrl": "/python/2021/07/06/python-1.html",
            "date": " • Jul 6, 2021"
        }
        
    
  
    
        ,"post42": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://kimha02.github.io/ham/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post43": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://kimha02.github.io/ham/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "## **Kimha02 Blog (2021~)** #### **Languages**&nbsp;&nbsp;&nbsp;&nbsp;&lt;/a&gt;&nbsp;&lt;/a&gt;&nbsp; #### 개인적인 공부 블로그! 👍 #### 자주자주 업데이트 하기! 👍 ![image](https://user-images.githubusercontent.com/88223302/153760239-99e4fbb3-ce1f-4404-9459-98ee529a54df.png)",
          "url": "https://kimha02.github.io/ham/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kimha02.github.io/ham/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}